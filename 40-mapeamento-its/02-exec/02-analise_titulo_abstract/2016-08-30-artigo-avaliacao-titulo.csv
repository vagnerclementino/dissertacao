data_hora_revisao;cite_key;titulo_artigo;ano_artigo;resumo_artigo;situacao_artigo;observacoes
2016/06/09 19:38:23;Aggarwal:2014:MIT:2593801.2593810;MINING ISSUE TRACKING SYSTEMS USING TOPIC MODELS FOR TREND ANALYSIS, CORPUS EXPLORATION, AND UNDERSTANDING EVOLUTION;2014;Issue Tracking systems (ITS) such as Google Code Hosting and Bugzilla facilitate software maintenance activities through bug reporting, archiving and fixing. The large number of bug reports and their unstructured text makes it impractical for developers to manually extract actionable intelligence to expedite bug fixing. In this paper, we present an application of mining bug report description and threaded discussion comments using Latent Dirichlet Allocation (LDA) which is a topic modeling technique. We apply LDA on the Chromium Browser Project bug archives (open-source) to extract topics (discovery of semantically related terms) and the latent semantic relationship between documents (bug reports) and extracted topics for corpus exploration, trend analysis and understanding evolution in maintenance domain. We conduct a series of experiments to uncover latent topics potentially useful for developers and testers based on the bug meta-data such as time, priority, type, category and status. The analysis of reopened and duplicate bugs in particular, has important inferences for the developers and can help in applications such as expertise modeling, resource allocation and knowledge management.;Incluído;
2016/06/09 19:40:12;Ahmadi2015;SMALL DIM OBJECT TRACKING USING A MULTI OBJECTIVE PARTICLE SWARM OPTIMISATION TECHNIQUE;2015;Dim object tracking in a heavy clutter environment is a theoretical and technological challenge in the field of image processing. For a small dim object, conventional tracking methods fail for the lack of geometrical information. Multiple hypotheses testing (MHT) is one of the generally accepted methods in target tracking systems. However, processing a tree structure with a significant number of branches in MHT has been a challenging issue. Tracking high-speed objects with traditional MHT requires some presumptions which limit the capabilities of these methods. This study presents a hierarchal tracking system in two levels to solve this problem. For each point in the lower-level, a multi objective particle swarm optimisation technique is applied to a group of consecutive frames to reduce the number of branches in each tracking tree. Thus, an optimum track for each moving object is obtained in a group of frames. In the upper-level, an iterative process is used to connect the matching optimum tracks of the consecutive frames based on the spatial information and fitness values. The experimental results show that the proposed method has a superior performance in relation to some common dim object tracking methods over different image sequence data sets.;Removido;
2016/06/09 19:46:09;Alipour:2013:CAT:2487085.2487123;A CONTEXTUAL APPROACH TOWARDS MORE ACCURATE DUPLICATE BUG REPORT DETECTION;2013;Bug-tracking and issue-tracking systems tend to be populated with bugs, issues, or tickets written by a wide variety of bug reporters, with different levels of training and knowledge about the system being discussed. Many bug reporters lack the skills, vocabulary, knowledge, or time to efficiently search the issue tracker for similar issues. As a result, issue trackers are often full of duplicate issues and bugs, and bug triaging is time consuming and error prone. Many researchers have approached the bug-deduplication problem using off-the-shelf information-retrieval tools, such as BM25F used by Sun et al. In our work, we extend the state of the art by investigating how contextual information, relying on our prior knowledge of software quality, software architecture, and system-development (LDA) topics, can be exploited to improve bug-deduplication. We demonstrate the effectiveness of our contextual bug-deduplication method on the bug repository of the Android ecosystem. Based on this experience, we conclude that researchers should not ignore the context of software engineering when using IR tools for deduplication;Incluído;
2016/06/09 19:52:35;An2014;SUPPLEMENTARY BUG FIXES VS. RE-OPENED BUGS;2014;"  typical  bug  fixing  cycle  involves  the  reporting  of
a bug, the triaging of the report, the production and verification
of a fix, and the closing of the bug. However, previous work has
studied  two  phenomena  where  more  than  one  fix  are  associated
with  the  same  bug  report.  The  first  one  is  the  case  where
developers  re-open  a  previously  fixed  bug  in  the  bug  repository
(sometimes  even  multiple  times)  to  provide  a  new  bug  fix  that
replace a previous fix, whereas the second one is the case where
multiple commits in the version control system contribute to the
same bug report (“supplementary bug fixes”). Even though both
phenomena seem related, they have never been studied together,
i.e.,  are  supplementary  fixes  a  subset  of  re-opened  bugs  or  the
other way around? This paper investigates the interplay between
both  phenomena  in  five  open  source  software  projects:  Mozilla,
Netbeans, Eclipse JDT Core, Eclipse Platform SWT, and WebKit.
We  found  that  re-opened  bugs  account  for  between  21.6%  and
33.8% of all supplementary fixes. However, 33% to 57.5% of re-
opened bugs had only one commit associated, which means that
the  original  bug  report  was  prematurely  closed  instead  of  fixed
incorrectly.  Furthermore,  we  constructed  predictive  models  for
re-opened bugs using historical information about supplementary
bug  fixes  with  a  precision  between  72.2%  and  97%,  as  well
as  a  recall  between  47.7%  and  65.3%.  Software  researchers
and  practitioners  who  are  mining  data  repositories  can  use  our
approach to identify potential failures of their bug fixes and the
re-opening  of  bug  reports";incluído para Revisão em Pares;"Apesar de artigo tratar principalmente do problema do ""supplementary bug fixes"" aparentemente foi proposta uma ferramenta para minimizar o problema"
2016/06/09 19:55:26;Antoniol2005;Towards the Integration of Versioning Systems, Bug Reports and Source Code Meta-Models;2005;"Versioning system repositories and bug tracking systems are valuable sources of information to study the evolution of large open source software systems. However, being conceived for specific purposes, i.e., to support the development or trigger maintenance activities, they do neither allow an easy information browsing nor support the study of software evolution. For example, queries such as locating and browsing the faultiest methods are not provided.
This paper addresses such issues and proposes an approach and a framework to consistently merge information extracted from source code, versioning repositories and bug reports. Our information representation exploits the property concepts of the FAMIX information exchange meta-model, allowing to represent, browse, and query, at different level of abstractions, the concept of interest. This allows the user to navigate back and forth from versioning system modification reports to bug reports and to source code. This paper presents the analysis framework and approaches to populate it, tools developed and under development for it, as well as lessons learned while analyzing several releases of Mozilla.";incluído para Revisão em Pares;
2016/06/09 19:57:39;Anvik:2005:COB:1117696.1117704;COPING WITH AN OPEN BUG REPOSITORY;2005;Most open source software development projects include an open bug repository---one to which users of the software can gain full access---that is used to report and track problems with, and potential enhancements to, the software system. There are several potential advantages to the use of an open bug repository: more problems with the system might be identified because of the relative ease of reporting bugs, more problems might be fixed because more developers might engage in problem solving, and developers and users can engage in focused conversations about the bugs, allowing users input into the direction of the system. However, there are also some potential disadvantages such as the possibility that developers must process irrelevant bugs that reduce their productivity. Despite the rise in use of open bug repositories, there is little data about what is stored inside these repositories and how they are used. In this paper, we provide an initial characterization of two open bug repositories from the Eclipse and Firefox projects, describe the duplicate bug and bug triage problems that arise with these open bug repositories, and discuss how we are applying machine learning technology to help automate these processes.;Incluído;
2016/06/09 19:59:32;Anvik:2007:DIE:1260984.1261303;DETERMINING IMPLEMENTATION EXPERTISE FROM BUG REPORTS;2007;"As developers work on a software product they accumulate expertise, including expertise about the code base of the software product. We call this type of expertise ""implementation expertise'. Knowing the set of developers who have implementation expertise for a software product has many important uses. This paper presents an empirical evaluation of two approaches to determining implementation expertise from the data in source and bug repositories. The expertise sets created by the approaches are compared to those provided by experts and evaluated using the measures of precision and recall. We found that both approaches are good at finding all of the appropriate developers, although they vary in how many false positives are returned.";Incluído;
2016/06/09 20:01:01;Anvik2008;TASK ARTICULATION IN SOFTWARE MAINTENANCE: INTEGRATING SOURCE CODE ANNOTATIONS WITH AN ISSUE TRACKING SYSTEM;2008;Managing and articulating development tasks is an important aspect of software maintenance. Developers already have a variety of specialty tools to support task management, for example, issue tracking and configuration management software, but they also make use of other tools within their software engineering environments to support software task management. An example of one such mechanism is the appropriation of source code comments to document finer grained details of formally specified tasks. In this research, we propose and present a tool that integrates these source code annotations with an issue tracking management system. We describe how this tool addresses deficiencies that occur in task management and propose future research to improve task management;Incluído;
2016/06/09 20:02:51;Atwood2010;COLLABORATIVE SOFTWARE DEVELOPMENT OF SCALABLE DOD COMPUTATIONAL ENGINEERING;2010;The Computational Research and Engineering Acquisition Tools and Environments (CREATE) Program is charged with positively impacting the US Department of Defense (DoD) Acquisition Process via Computational Engineering for capability gaps identified by the CREATE Boards of Directors. These prioritized requirements have been characterized and are annually reconciled in terms of gaps associated with required analysis cycle-times, physical accuracy, and necessary analysis capabilities. Furthermore, the Office of the Secretary of Defense(OSD) Overarching Integrated Product Team (OIPT) has provided goals which drive the usage of CREATE software by DoD Acquisition Programs. In order to achieve these usage targets, the CREATE Program has established a governance model and thence a hosted set of services to enhance collaboration among the developer teams and the targeted Acquisition Program (AP) subject matter experts. The goals of these collaboration services are to: 1) scale and speed the feedback amongst the CREATE and AP teams, while 2) minimizing interruption to developer and user workflows. Towards these goals, the community services have been architected as discussion forums, issue tracking, and documentation. Such services are now common place in the enterprise and open-source software projects, and efficiently scale with the user community by enabling a searchable knowledge base. In addition, owing to the key capabilities of this DoD software, CREATE requires authenticated and authorized access for each member of the community. This paper summarizes the governance model and process by which the services were selected, the architecture implemented, and the challenges going forward;Removido;
2016/06/09 20:04:32;Azarbakht2014;TEMPORAL VISUALIZATION OF COLLABORATIVE SOFTWARE DEVELOPMENT IN FOSS FORKS;2014;Software development in free and open source (FOSS) projects is a collective human activity. Software developers in these projects collaborate via FOSS informalisms, i.e. mailing list, bug repository and code repository. Analysing the human collaborative work of these software developers over a time period, e.g. five years, sheds light on the underlying structure and dynamics of how the software is being developed, how the project is led, who the influencers are, and how to achieve a state of sustainability. In this paper, we propose to use temporal social network analysis with temporal visualization to study the evolution and social dynamics of FOSS communities. With these techniques we aim to identify measures associated with unhealthy group dynamics, e.g. a simmering conflict, as well as early indicators of major events in the lifespan of a community. One dynamic we are especially interested in, are those of forked FOSS projects. We used the results of a study of forked FOSS projects by [Robles and Gonzalez-Barahona 2012] as the starting platform for our study, and tried to gain a better understanding of the evolution of these communities.;Removido;
2016/06/09 20:06:17;Bacchelli:2010:PCM:2128562.2128570;ARE POPULAR CLASSES MORE DEFECT PRONE?;2010;"

Traces of the evolution of software systems are left in a number of different repositories, such as configuration management systems, bug tracking systems, and mailing lists. Developers use e-mails to discuss issues ranging from low-level concerns (bug fixes, refactorings) to high-level resolutions (future planning, design decisions). Thus, e-mail archives constitute a valuable asset for understanding the evolutionary dynamics of a system.

We introduce metrics that measure the “popularity” of source code artifacts, i.e. the amount of discussion they generate in e-mail archives, and investigate whether the information contained in e-mail archives is correlated to the defects found in the system. Our hypothesis is that developers discuss problematic entities more than unproblematic ones. We also study whether the precision of existing techniques for defect prediction can be improved using our popularity metrics.
";Removido;
2016/06/09 20:09:13;Banerjee2015;ON THE COST OF MINING VERY LARGE OPEN SOURCE REPOSITORIES;2015;"Open source bug tracking systems provide a rich information suite that is actively used by software engineering researchers to design solutions to triaging, duplicate classification and developer assignment problems. Today, open repositories often contain in excess of 100,000 reports, and in cases of RedHat and Mozilla, over a million. Obtaining and analyzing the contents of such datasets are both time and resource consuming. By summarizing the related work we demonstrate that researchers often focused on smaller subsets of the data, and seldom embrace the ""big-dataism"". With the emergence of cloud based computation systems such as Amazon EC2, one expects it to be easier to perform large scale analyses. However, our detailed time and cost analysis indicates that significant challenges still remain. Acquiring the open source data can be time intensive, and prone to being misinterpreted as Denial of Service attacks. Generating similarity scores for all prior reports, for example, is a polynomial time problem. In this paper, we present actual costs that we incurred when analyzing the complete repositories from Eclipse, Firefox and Open Office. In our approach, we relied on computing clusters to process the data in an attempt to reduce the cost of analyzing large datasets on the cloud. We present estimated costs for a researcher attempting to analyze complete datasets from Eclipse, Mozilla, Novell and RedHat using the best possible resources. In an ideal situation, with no bottlenecks, a researcher investing just over $40,000 and 2 weeks of non stop computing time would be able to measure similarity of problem reports within all four datasets.";Removido;
2016/06/09 20:10:24;Banerjee:2012:ADB:2417496.2417520;AUTOMATED DUPLICATE BUG REPORT CLASSIFICATION USING SUBSEQUENCE MATCHING;2012;The use of open bug tracking repositories like Bugzilla is common in many software applications. They allow developers, testers and users the ability to report problems associated with the system and track resolution status. Open and democratic reporting tools, however, face one major challenge: users can, and often do, submit reports describing the same problem. Research in duplicate report detection has primarily focused on word frequency based similarity measures paying little regard to the context or structure of the reporting language. Thus, in large repositories, reports describing different issues may be marked as duplicates due to the frequent use of common words. In this paper, we present Factor LCS, a methodology which utilizes common sequence matching for duplicate report detection. We demonstrate the approach by analyzing the complete Fire fox bug repository up until March 2012 as well as a smaller subset of Eclipse dataset from January 1, 2008 to December 31, 2008. We achieve a duplicate recall rate above 70% with Fire fox, which exceeds the results reported on smaller subsets of the same repository.;Incluído;
2016/06/09 20:13:30;Banerjee2015a;ECLIPSE VS. MOZILLA: A COMPARISON OF TWO LARGE-SCALE OPEN SOURCE PROBLEM REPORT REPOSITORIES;2015;"Bug tracking systems play an important role in the development and maintenance of large-scale software systems. Having access to open source bug tracking systems has allowed researchers to take advantage of rich datasets and propose solutions to manage duplicate report classification, developer assignment and quality assessment. In spite of research advances, our understanding of the content of these repositories remains limited, primarily because of their size. In many cases, researchers analyze small portions of datasets thus limiting the understanding of the dynamics of problem reporting. The objective of this study is to explore the properties of two large-scale open source problem report repositories. The Eclipse dataset, at the time of download, consisted of 363; 770 reports spanning 11+ years, whereas Mozilla contained 699; 085 reports spanning 14+ years.Our research examines the evolution of datasets over time by analyzing the changes in the repository and the profiles of users who submit problem reports. We provide quantitative evidence on how submitter's maturity reduces the propensity to submit poor quality, insignificant or duplicate reports. We show that a diverse user base, characteristic of Mozilla, creates challenges for the development team as they spend more time triaging, rather than fixing, issues. Finally, we provide the research community with a series of observations and suggestions on how to study large-scale problem repositories.";Removido;
2016/06/09 20:16:43;Bangcharoensap:2012:LSC:2419061.2419428;LOCATING SOURCE CODE TO BE FIXED BASED ON INITIAL BUG REPORTS - A CASE STUDY ON THE ECLIPSE PROJECT;2012;In most software development, a Bug Tracking System is used to improve software quality. Based on bug reports managed by the bug tracking system, triagers who assign a bug to fixers and fixers need to pinpoint buggy files that should be fixed. However if triagers do not know the details of the buggy file, it is difficult to select an appropriate fixer. If fixers can identify the buggy files, they can fix the bug in a short time. In this paper, we propose a method to quickly locate the buggy file in a source code repository using 3 approaches, text mining, code mining, and change history mining to rank files that may be causing bugs. (1) The text mining approach ranks files based on the textual similarity between a bug report and source code. (2) The code mining approach ranks files based on prediction of the fault-prone module using source code product metrics. (3) The change history mining approach ranks files based on prediction of the fault-prone module using change process metrics. Using Eclipse platform project data, our proposed model gains around 20% in TOP1 prediction. This result means that the buggy files are ranked first in 20% of bug reports. Furthermore, bug reports that consist of a short description and many specific words easily identify and locate the buggy file.;Incluído;
2016/06/09 20:19:56;Banitaan2013;DECOBA: UTILIZING DEVELOPERS COMMUNITIES IN BUG ASSIGNMENT;2013;Bug Tracking System (BTS) is public ally accessible which enables geographically distributed developers to follow the work of each other and contribute in bug fixing. Developer interactions through commenting on bug reports generate a developer social network that can be used to improve software development and maintenance activities. In large scale complex software projects, software maintenance requires larger groups to participate in its activities. Most previous bug assignments approaches assign only one developer to new bugs. However, bug fixing is a collaborative effort between several developers (i.e., many developers contribute their experience in fixing a bug report). In this work, we build developers social networks based on developers comments on bug reports and detect developers communities. We also assign a relevant community to each newly committed bug report. Moreover, we rank developers in each community based on their experience. An experimental evaluation is conducted on three open source projects namely Net Beans, Free desktop, and Mandriva. The results show that the detected communities are significantly connected with high density. They also show that the proposed approach achieves feasible accuracy of bug assignment.;Incluído;
2016/06/09 20:22:01;Baysal:2013:SAP:2486788.2486957;SITUATIONAL AWARENESS: PERSONALIZING ISSUE TRACKING SYSTEMS;2013;"Issue tracking systems play a central role in ongoing software development; they are used by developers to support collaborative bug fixing and the implementation of new features, but they are also used by other stakeholders including managers, QA, and end-users for tasks such as project management, communication and discussion, code reviews, and history tracking. Most such systems are designed around the central metaphor of the ""issue"" (bug, defect, ticket, feature, etc.), yet increasingly this model seems ill fitted to the practical needs of growing software projects; for example, our analysis of interviews with 20 Mozilla developers who use Bugzilla heavily revealed that developers face challenges maintaining a global understanding of the issues they are involved with, and that they desire improved support for situational awareness that is difficult to achieve with current issue management systems. In this paper we motivate the need for personalized issue tracking that is centered around the information needs of individual developers together with improved logistical support for the tasks they perform. We also describe an initial approach to implement such a system — extending Bugzilla — that enhances a developer's situational awareness of their working context by providing views that are tailored to specific tasks they frequently perform; we are actively improving this prototype with input from Mozilla developers";Incluído;
2016/06/09 20:25:26;Baysal2012;REVISITING BUG TRIAGE AND RESOLUTION PRACTICES;2012;"Bug triaging is an error-prone, tedious and time-
consuming  task.  However,  little  qualitative  research  has  been
done on the actual use of bug tracking systems, bug triage, and
resolution processes. We are planning to conduct a qualitative
study  to  understand  the  dynamics  of  bug  triage  and  fixing
process,  as  well  as  bug  reassignments  and  reopens.  We  will
study  interviews  conducted  with  Mozilla  Core  and  Firefox
developers to get insights into the primary obstacles developers
face during the bug fixing process. Is the triage process flawed?
Does   bug   review   slow   things   down?   Does   approval   takes
too  long?  We  will  also  categorize  the  main  reasons  for  bug
reassignments and reopens. We will then combine results with
a quantitative study of Firefox bug reports, focusing on factors
related  to  bug  report  edits  and  number  of  people  involved  in
handling  the  bug.";Removido;
2016/06/09 20:27:20;Baysal2013;THE INFLUENCE OF NON-TECHNICAL FACTORS ON CODE REVIEW;2013;"When  submitting  a  patch,  the  primary  concerns  of
individual  developers  are  “How  can  I  maximize  the  chances
of  my  patch  being  approved,  and  minimize  the  time  it  takes
for  this  to  happen?”  In  principle,  code  review  is  a  transparent
process   that   aims   to   assess   qualities   of   the   patch   by   their
technical  merits  and  in  a  timely  manner;  however,  in  practice
the  execution  of  this  process  can  be  affected  by  a  variety  of
factors,  some  of  which  are  external  to  the  technical  content  of
the  patch  itself.  In  this  paper,  we  describe  an  empirical  study
of  the  code  review  process  for  WebKit,  a  large,  open  source
project;  we  replicate  the  impact  of  previously  studied  factors
—   such   as   patch   size,   priority,   and   component   and   extend
these  studies  by  investigating  organizational  (the  company)  and
personal  dimensions  (reviewer  load  and  activity,  patch  writer
experience)  on  code  review  response  time  and  outcome.  Our
approach uses a reverse engineered model of the patch submission
process  and  extracts  key  information  from  the  issue  tracking
and  code  review  systems.  Our  findings  suggest  that  these  non-
technical factors  can significantly impact code  review outcomes.";Removido;
2016/06/09 20:29:15;Bettenburg2008a;WHAT MAKES A GOOD BUG REPORT?;2010;"In software development, bug reports provide crucial information to developers. However, these reports widely differ in their quality. We conducted a survey among developers and users of APACHE, ECLIPSE, and MOZILLA to find out what makes a good bug report. The analysis of the 466 responses revealed an information mismatch between what developers need and what users supply. Most developers consider steps to reproduce, stack traces, and test cases as helpful, which are, at the same time, most difficult to provide for users. Such insight is helpful for designing new bug tracking tools that guide users at collecting and providing more helpful information. Our CUEZILLA prototype is such a tool and measures the quality of new bug reports; it also recommends which elements should be added to improve the quality. We trained CUEZILLA on a sample of 289 bug reports, rated by developers as part of the survey. The participants of our survey also provided 175 comments on hurdles in reporting and resolving bugs. Based on these comments, we discuss several recommendations for better bug tracking systems, which should focus on engaging bug reporters, better tool support, and improved handling of bug duplicate";Incluído;
2016/06/09 20:31:11;Beck2015;RETHINKING USER INTERFACES FOR FEATURE LOCATION;2015;Locating features in large software systems is a fundamental maintenance task for developers when fixing bugs and extending software. We introduce In Situ Impact Insight (I3), a novel user interface to support feature location. In addition to a list of search results, I3 provides support for developers during browsing and inspecting the retrieved code entities. In situ visualizations augment results and source code with additional information relevant for further exploration. Developers are able to retrieve details on the textual similarity of a source code entity to the search query and to other entities, as well as the information on co-changed entities from a project's history. Execution traces recorded during program runs can be used as filters to further refine the search results. We implemented I3 as an Eclipse plug-in and tested it in a user study involving 18 students and professional developers that were asked to perform three feature location tasks chosen from the issue tracking system of jEdit. The results of our study suggest that I3's user interface is intuitive and unobtrusively supports developers with the required information when and where they need it.;Incluído;
2016/06/09 20:32:24;Beckhaus2010;THE IMPACT OF COLLABORATION NETWORK STRUCTURE ON ISSUE TRACKING'S PROCESS EFFICIENCY AT A LARGE BUSINESS SOFTWARE VENDOR;2010;Researchers in the IS domain have addressed communication structure and its effect on performance. While early research focused on small networks and utilized sociometric surveys, recent works have concentrated on electronic data sources provided by open source software repositories. Surprisingly, software vendors have less frequently been studied despite their need for continuous enhancement of organizational design. In this study, we analyze a global business software vendor by utilizing existing data sources. We investigate the association of both collaboration network centrality and communication with process efficiency. Despite coping with complex, interweaved processes and social networks, we find that communication, centrality in the large case-study-wide network, and communication pattern homogeneity are positively associated with process efficiency. However, centrality in small work groups slows the analyzed issue tracking process down, possibly due to increased overhead and bottleneck effects that become visible when looking at single issues qualitatively.;Removido;
2016/06/09 20:33:14;Behl2014;A BUG MINING TOOL TO IDENTIFY AND ANALYZE SECURITY BUGS USING NAIVE BAYES AND TF-IDF: A COMPARATIVE ANALYSIS;2014;Bug report contains a vital role during software development, However bug reports belongs to different categories such as performance, usability, security etc. This paper focuses on security bug and presents a bug mining system for the identification of security and non-security bugs using the term frequency-inverse document frequency (TF-IDF) weights and naïve bayes. We performed experiments on bug report repositories of bug tracking systems such as bugzilla and debugger. In the proposed approach we apply text mining methodology and TF-IDF on the existing historic bug report database based on the bug s description to predict the nature of the bug and to train a statistical model for manually mislabeled bug reports present in the database. The tool helps in deciding the priorities of the incoming bugs depending on the category of the bugs i.e. whether it is a security bug report or a non-security bug report, using naïve bayes. Our evaluation shows that our tool using TF-IDF is giving better results than the naïve bayes method.;Incluído;
2016/06/09 20:34:40;Bettenburg:2007:QBR:1328279.1328284;QUALITY OF BUG REPORTS IN ECLIPSE;2007;The information in bug reports influences the speed at which bugs are fixed. However, bug reports differ in their quality of information. We conducted a survey among ECLIPSE developers to determine the information in reports that they widely used and the problems frequently encountered. Our results show that steps to reproduce and stack traces are most sought after by developers, while inaccurate steps to reproduce and incomplete information pose the largest hurdles. Surprisingly, developers are indifferent to bug duplicates. Such insight is useful to design new bug tracking tools that guide reporters at providing more helpful information. We also present a prototype of a quality-meter tool that measures the quality of bug reports by scanning its content.;Incluído;
2016/06/09 20:36:08;Bhattacharya:2011:BTP:1985441.1985472;BUG-FIX TIME PREDICTION MODELS: CAN WE DO BETTER?;2011;Predicting bug-fix time is useful in several areas of software evolution, such as predicting software quality or coordinating development effort during bug triaging. Prior work has proposed bug-fix time prediction models that use various bug report attributes (e.g., number of developers who participated in fixing the bug, bug severity, number of patches, bug-opener's reputation) for estimating the time it will take to fix a newly-reported bug. In this paper we take a step towards constructing more accurate and more general bug-fix time prediction models by showing how existing models fail to validate on large projects widely-used in bug studies. In particular, we used multivariate and univariate regression testing to test the prediction significance of existing models on 512,474 bug reports from five open source projects: Eclipse, Chrome and three products from the Mozilla project (Firefox, Seamonkey and Thunderbird). The results of our regression testing indicate that the predictive power of existing models is between 30% and 49% and that there is a need for more independent variables (attributes) when constructing a prediction model. Additionally, we found that, unlike in prior recent studies on commercial software, in the projects we examined there is no correlation between bug-fix likelihood, bug-opener's reputation and the time it takes to fix a bug. These findings indicate three open research problems: (1) assessing whether prioritizing bugs using bug-opener's reputation is beneficial, (2) identifying attributes which are effective in predicting bug-fix time, and (3) constructing bug-fix time prediction models which can be validated on multiple projects;Incluído;
2016/06/09 20:37:59;Bissyande:2013:OSP:2549855.2549894;ORION: A SOFTWARE PROJECT SEARCH ENGINE WITH INTEGRATED DIVERSE SOFTWARE ARTIFACTS;2013;"What projects contain more than 10,000 lines of code
developed by less than 10 people and are still actively maintained
with a high bug-fixing rate? To address the challenges for
answering such enquiries, we develop an integrated search engine
architecture that combines information from different types of
software repositories from multiple sources. Our search engine
facilitates the construction and execution of complex search
queries using a uniform interface that transparently correlates
different artifacts of project development and maintenance, such
as source code information, version control systems metadata,
bug tracking systems elements, and metadata on developer
activities and interactions extracted from hosting platforms.
We have built an extensible system with an initial capability of
over 100,000 projects collected from the web, featuring various
software development artifacts. Using scenarios, we illustrate the
benefits of such a search engine for different kinds of project
seekers.";Removido;
2016/06/09 20:40:12;Bissyande2013;EMPIRICAL EVALUATION OF BUG LINKING;2013;"

To collect software bugs found by users, development teams often set up bug trackers using systems such as Bugzilla. Developers would then fix some of the bugs and commit corresponding code changes into version control systems such as svn or git. Unfortunately, the links between bug reports and code changes are missing for many software projects as the bug tracking and version control systems are often maintained separately. Yet, linking bug reports to fix commits is important as it could shed light into the nature of bug fixing processes and expose patterns in software management. Bug linking solutions, such as ReLink, have been proposed. The demonstration of their effectiveness however faces a number of issues, including a reliability issue with their ground truth datasets as well as the extent of their measurements. We propose in this study a benchmark for evaluating bug linking solutions. This benchmark includes a dataset of about 12,000 bug links from 10 programs. These true links between bug reports and their fixes have been provided during bug fixing processes. We designed a number of research questions, to assess both quantitatively and qualitatively the effectiveness of a bug linking tool. Finally, we apply this benchmark on ReLink to report the strengths and limitations of this bug linking tool.
";incluído para Revisão em Pares;
2016/06/09 20:42:36;Boisselle2015;THE IMPACT OF CROSS-DISTRIBUTION BUG DUPLICATES, EMPIRICAL STUDY ON DEBIAN AND UBUNTU;2015;Although open source distributions like Debian and Ubuntu are closely related, sometimes a bug reported in the Debian bug repository is reported independently in the Ubuntu repository as well, without the Ubuntu users nor developers being aware. Such cases of undetected cross-distribution bug duplicates can cause developers and users to lose precious time working on a fix that already exists or to work individually instead of collaborating to find a fix faster. We perform a case study on Ubuntu and Debian bug repositories to measure the amount of cross-distribution bug duplicates and estimate the amount of time lost. By adapting an existing within-project duplicate detection approach (achieving a similar recall of 60%), we find 821 cross-duplicates. The early detection of such duplicates could reduce the time lost by users waiting for a fix by a median of 38 days. Furthermore, we estimate that developers from the different distributions lose a median of 47 days in which they could have collaborated together, had they been aware of duplicates. These results show the need to detect and monitor cross-distribution duplicates.;Incluído;
2016/06/09 20:43:39;Bortis:2011:TCB:1984642.1984659;TEAMBUGS: A COLLABORATIVE BUG TRACKING TOOL;2011;Bug trackers are considered to be one of the primary coordination tools in software development. Interactions with the bug tracker occur throughout the development process, in different settings, from the meeting room to the developer's desk. In this paper, we look at previous field studies of bug trackers and identify the key challenges in supporting coordination. We then describe through several scenarios TeamBugs, a new bug tracker tool. We conclude by raising several research questions for future work.;Incluído;
2016/06/09 20:44:47;Bougie2010;A COMPARATIVE EXPLORATION OF FREEBSD BUG LIFETIMES;2010;In this paper, we explore the viability of mining the basic data provided in bug repositories to predict bug lifetimes. We follow the method of Lucas D. Panjer as described in his paper, Predicting Eclipse Bug Lifetimes. However, in place of Eclipse data, the FreeBSD bug repository is used. We compare the predictive accuracy of five different classification algorithms applied to the two data sets. In addition, we propose future work on whether there is a more informative way of classifying bugs than is considered by current bug tracking systems.;Incluído;
2016/06/09 20:45:48;Breu:2010:INB:1718918.1718973;INFORMATION NEEDS IN BUG REPORTS: IMPROVING COOPERATION BETWEEN DEVELOPERS AND USERS;2010;For many software projects, bug tracking systems play a central role in supporting collaboration between the developers and the users of the software. To better understand this collaboration and how tool support can be improved, we have quantitatively and qualitatively analysed the questions asked in a sample of 600 bug reports from the MOZILLA and ECLIPSE projects. We categorised the questions and analysed response rates and times by category and project. Our results show that the role of users goes beyond simply reporting bugs: their active and ongoing participation is important for making progress on the bugs they report. Based on the results, we suggest four ways in which bug tracking systems can be improved.;Incluído;
2016/06/09 20:47:46;Caglayan:2012:FCR:2365324.2365327;FACTORS CHARACTERIZING REOPENED ISSUES: A CASE STUDY;2012;"

Background: Reopened issues may cause problems in managing software maintenance effort. In order to take actions that will reduce the likelihood of issue reopening the possible causes of bug reopens should be analysed.

Aims: In this paper, we investigate potential factors that may cause issue reopening.

Method: We have extracted issue activity data from a large release of an enterprise software product. We consider four dimensions, namely developer activity, issue proximity network, static code metrics of the source code changed to fix an issue, issue reports and fixes as possible factors that may cause issue reopening. We have done exploratory analysis on data. We build logistic regression models on data in order to identify key factors leading issue reopening. We have also conducted a survey regarding these factors with the QA Team of the product and interpreted the results.

Results: Our results indicate that centrality in the issue proximity network and developer activity are important factors in issue reopening. We have also interpreted our results with the QA Team to point out potential implications for practitioners.

Conclusions: Quantitative findings of our study suggest that issue complexity and developers workload play an important role in triggering issue reopening.
";Incluído;
2016/06/09 20:49:55;Callahan1998;WEB-BASED ISSUE TRACKING FOR LARGE SOFTWARE PROJECTS;1998;Many problems are found and fixed during the development of a software system. The Project Issue Tracking System toolkit, a Web-based issue-management tool, can be used to organize issue reports during development and to communicate with different project teams around the world. The Project Issue Tracking System (PITS) is a tool that supports the IV&V effort for two major NASA projects: the Earth Observation System Data and Information System (EOSDIS) and the Earth Science Data and Information System (ESDIS). The EOSDIS IV&V effort teams several companies and organizations at several sites with Intermetrics, Inc, serving as the lead contractor. We examine the PITS Web-based mechanisms for tracking issue reports;Removido;Pelo ano do artigo e não havia versão para download.
2016/06/09 20:51:57;Canfora:2005:IAM:1090955.1092169;IMPACT ANALYSIS BY MINING SOFTWARE AND CHANGE REQUEST REPOSITORIES;2005;Impact analysis is the identification of the work products affected by a proposed change request, either a bug fix or a new feature request. In many open-source projects, such as KDE, Gnome, Mozilla, Openoffice, change requests, and related data, are stored in a bug tracking system such as Bugzilla. These data, together with the data stored in a versioning system, such as CVS, are a valuable source of information on which useful analyses can be performed. In this paper we propose a method to derive the set of source files impacted by a proposed change request. The method exploits information retrieval algorithms to link the change request description and the set of historical source file revisions impacted by similar past change requests. The method is evaluated by applying it on four open-source projects2;Incluído;
2016/06/09 20:54:05;Canfora2009;TRACKING YOUR CHANGES: A LANGUAGE-INDEPENDENT APPROACH;2009;Versioning and bug-tracking systems are invaluable assets for large software projects that involve developers spread worldwide and numerous users reporting bugs and proposing enhancements. In addition to supporting development, versioning systems are a precious source of information for studying or monitoring a software system's evolution.;incluído para Revisão em Pares;
2016/06/09 20:58:14;Cavalcanti:2013:TUS:2460999.2461028;TOWARDS UNDERSTANDING SOFTWARE CHANGE REQUEST ASSIGNMENT: A SURVEY WITH PRACTITIONERS;2013;"Context: Change Request (CR) repositories play an important role in the software maintenance and evolution process. Through a CR repository, software changes are reported and assigned to developers. Finding the appropriate developer to a CR is crucial for obtaining the lowest, economically feasible, fixing time. Nevertheless, assigning CRs is a labor-intensive and time consuming task. Although many work have proposed automated approaches for CR assignment, they have been implemented without investigating the fundamental aspects which characterize the task itself. Objective: This paper investigates the effort that is taken to assign CR to appropriate developers and identifies the fundamental aspects that characterize it, such as the strategies to perform the assignments and the complexity involved in them. Such investigation improves the current knowledge on the topic, providing researchers and practitioners with useful information towards developing effective solutions. Method: A survey was performed with software developers to understand CR assignment in the Brazilian Federal Organization for Data Processing. The questionnaire was composed of 38 questions, being them both open-ended and closed-ended. We analyzed the answers of 36 respondents. Results: We find that: there is a significant amount of time being spent on assignments (e.g., assigning 20 CRs can take up to 3.3 hours); there are many strategies used to assign CRs, which are complementary to those used in current automated solutions; and CR assignment is very complexity due to a process that requires cognitive abilities for information seeking, communication, and memorization. Conclusion: CR repositories are fundamental to software maintenance, however assigning CRs to developers is an expensive activity. Although we understand that fully and totally accurate automation of assignments is unlikely, further improvements on this direction are feasible and necessary to reduce costs. This way, this paper brings relevant findings to guide new research on automated CR assignment.";Removido;
2016/06/09 20:59:17;Cavalcanti2010;AN INITIAL STUDY ON THE BUG REPORT DUPLICATION PROBLEM;2010;According to recent work, duplicate bug report entries in bug tracking systems impact negatively on software maintenance and evolution productivity due to, among other factors, the increased time spent on report analysis and validation, what in some cases take over 20 minutes. Therefore, a considerable amount of time is lost mainly with duplicate bug report analysis. This work presents an initial characterization study using data from bug trackers from private and open source projects, in order to understand the possible factors that cause bug report duplication and its impact on software development;incluído para Revisão em Pares;
2016/06/09 21:27:07;Cavalcanti2014;CHALLENGES AND OPPORTUNITIES FOR SOFTWARE CHANGE REQUEST REPOSITORIES: A SYSTEMATIC MAPPING STUDY;2014;Software maintenance starts as soon as the first artifacts are delivered and is essential for the success of the software. However, keeping maintenance activities and their related artifacts on track comes at a high cost. In this respect, change request (CR) repositories are fundamental in software maintenance. They facilitate the management of CRs and are also the central point to coordinate activities and communication among stakeholders. However, the benefits of CR repositories do not come without issues, and commonly occurring ones should be dealt with, such as the following: duplicate CRs, the large number of CRs to assign, or poorly described CRs. Such issues have led researchers to an increased interest in investigating CR repositories, by considering different aspects of software development and CR management. In this paper, we performed a systematic mapping study to characterize this research field. We analyzed 142 studies, which we classified in two ways. First, we classified the studies into different topics and grouped them into two dimensions: challenges and opportunities. Second, the challenge topics were classified in accordance with an existing taxonomy for information retrieval models. In addition, we investigated tools and services for CR management, to understand whether and how they addressed the topics identified.;incluído para Revisão em Pares;
2016/06/09 21:29:30;Gupta:2014:NMB:2590748.2590749;NIRIKSHAN: MINING BUG REPORT HISTORY FOR DISCOVERING PROCESS MAPS, INEFFICIENCIES AND INCONSISTENCIES;2014;Issue tracking systems such as Bugzilla, Mantis and JIRA are Process Aware Information Systems to support business process of issue (defect and feature enhancement) reporting and resolution. The process of issue reporting to resolution consists of several steps or activities performed by various roles (bug reporter, bug triager, bug fixer, developers, and quality assurance manager) within the software maintenance team. Project teams define a workflow or a business process (design time process model and guidelines) to streamline and structure the issue management activities. However, the runtime process (reality) may not conform to the design time model and can have imperfections or inefficiencies. We apply business process mining tools and techniques to analyze the event log data (bug report history) generated by an issue tracking system with the objective of discovering runtime process maps, inefficiencies and inconsistencies. We conduct a case-study on data extracted from Bugzilla issue tracking system of the popular open-source Firefox browser project. We present and implement a process mining framework, Nirikshan, consisting of various steps: data extraction, data transformation, process discovery, performance analysis and conformance checking. We conduct a series of process mining experiments to study self-loops, back-and-forth, issue reopen, unique traces, event frequency, activity frequency, bottlenecks and present an algorithm and metrics to compute the degree of conformance between the design time and the runtime process.;Incluído;
2016/06/09 21:33:16;Cerulo2006;ON THE USE OF PROCESS TRAILS TO UNDERSTAND SOFTWARE DEVELOPMENT;2006;Software repositories, such as version control systems (CVS) and bug-tracking systems (Bugzilla), provide useful information about software process trails left by developers during the evolution of a software project. Mining these repositories provides a way to understand software development, to support predictions about software development, and to plan various aspects of software projects. We introduce three cases in the areas of impact analysis, change request assignment, and crosscutting concern mining, that takes benefit from historical information and show that the combination of different type of analyses can improve the performance of these software engineering models;incluído para Revisão em Pares;
2016/06/13 23:16:17;Chandrasekaran2007;AEGIS: A PROACTIVE METHODOLOGY TO SHIELD AGAINST ZERO-DAY EXPLOITS;2007;"Given the large number of vulnerability instances disclosed in various bug-tracking communities, system administrators face an up-hill task of protecting their system/ network against zero-day exploits. In order to safeguard against such exploits, the present challenges come in two-fold: (i) there exists a compelling need to assimilate configuration specific vulnerability information from various bug-tracking diaspora; also (ii) there is a need to proactively generate policy specific signatures which act as a first line of defense. In this paper we propose an automated approach for determining vulnerabilities pertinent to the current network/ system configuration using the information aggregated from different bug tracking communities. Such vulnerability assessment and indication mechanisms significantly alleviate the system administratorÂ¿s burden of manual content digging for vulnerabilities in his own configuration context. Furthermore, we propose an Extensible Defense Oriented Representation Schema (EDORS) for vulnerability representation, which is subsequently used by the policy engine to generate appropriate signatures. As a result, the generated signatures can be viewed as a preventive interim security measure against recently published threats until its patch is released. We have also evaluated our framework through a series of experiments.";incluído para Revisão em Pares;
2016/06/13 23:18:31;Chaturvedi2012;AN EMPIRICAL COMPARISON OF MACHINE LEARNING TECHNIQUES IN PREDICTING THE BUG SEVERITY OF OPEN AND CLOSED SOURCE PROJECTS;2012;Bug severity is the degree of impact that a defect has on the development or operation of a component or system, and can be classified into different levels based on their impact on the system. Identification of severity level can be useful for bug triager in allocating the bug to the concerned bug fixer. Various researchers have attempted text mining techniques in predicting the severity of bugs, detection of duplicate bug reports and assignment of bugs to suitable fixer for its fix. In this paper, an attempt has been made to compare the performance of different machine learning techniques namely Support vector machine SVM, probability based Naïve Bayes NB, Decision Tree based J48 A Java implementation of C4.5, rule based Repeated Incremental Pruning to Produce Error Reduction RIPPER and Random Forests RF learners in predicting the severity level 1 to 5 of a reported bug by analyzing the summary or short description of the bug reports. The bug report data has been taken from NASA's PITS Projects and Issue Tracking System datasets as closed source and components of Eclipse, Mozilla & GNOME datasets as open source projects. The analysis has been carried out in RapidMiner and STATISTICA data mining tools. The authors measured the performance of different machine learning techniques by considering i the value of accuracy and F-Measure for all severity level and ii number of best cases at different threshold level of accuracy and F-Measure;Incluído;
2016/06/13 23:20:34;Hu:2014:EBT:2707683.2708297;EFFECTIVE BUG TRIAGE BASED ON HISTORICAL BUG-FIX INFORMATION;2014;"For complex and popular software, project teams could receive a large number of bug reports. It is often tedious and costly to manually assign these bug reports to developers who have the expertise to fix the bugs. Many bug triage techniques have been proposed to automate this process. In this paper, we describe our study on applying conventional bug triage techniques to projects of different sizes. We find that the effectiveness of a bug triage technique largely depends on the size of a project team (measured in terms of the number of developers). The conventional bug triage methods become less effective when the number of developers increases. To further improve the effectiveness of bug triage for large projects, we propose a novel recommendation method called Bug Fixer, which recommends developers for a new bug report based on historical bug-fix information. Bug Fixer constructs a Developer-Component-Bug (DCB) network, which models the relationship between developers and source code components, as well as the relationship between the components and their associated bugs. A DCB network captures the knowledge of ""who fixed what, where"". For a new bug report, Bug Fixer uses a DCB network to recommend to triager a list of suitable developers who could fix this bug. We evaluate Bug Fixer on three large-scale open source projects and two smaller industrial projects. The experimental results show that the proposed method outperforms the existing methods for large projects and achieves comparable performance for small projects.";Incluído;
2016/06/13 23:22:48;Chawla:2015:AAB:2723742.2723751;AN AUTOMATED APPROACH FOR BUG CATEGORIZATION USING FUZZY LOGIC;2015;"

Various automated techniques built to benefit software developers, bug triagers, stakeholders and users in open source systems, utilize information placed in issue tracking systems. The success of these techniques depends largely on the quality of information present in the issue reports. Assigning correct label to issue reports is one of the quality concerns. Previous empirical studies conducted on the issue reports show that most issues are either mislabeled or are not labeled at all. Thus, in order to enhance quality of issue reports, there is a strong need to propose an automated and accurate bug labeling approach. A label can be a bug, feature enhancement or other request.

In this paper, we propose an automated approach to label an issue either as bug or other request based on fuzzy set theory. Experiments are conducted on issue repository of three open source software systems: HTTPClient, Jackrabbit and Lucene. We have achieved an accuracy of 87%, 83.5% and 90.8% and F-Measure score of 0.83, 0.79 and 0.84 respectively. This is a considerable improvement as compared to the earlier reported work on these three datasets using topic modeling approach.
";Incluído;
2016/06/13 23:23:42;Chawla2013;PERFORMANCE EVALUATION OF VSM AND LSI MODELS TO DETERMINE BUG REPORTS SIMILARITY;2013;Bug reports of open source software systems are increasing exponentially. One reason for growing bug reports is that bug reporters do not browse the bug repository before submitting a bug report. There may be some similar bugs already reported: one, which are exactly similar or duplicate and other, which are semantically similar means they may belong to the same software component or files. The information contained in the previously reported similar bugs can be helpful in fixing and resolving the newly reported bugs. In this paper, we applied and compared performance of two information retrieval (IR) models: Vector Space Model (VSM) and Latent Semantic Indexing (LSI), in extracting existing similar bug reports. The performance of these two models have been evaluated based on the Top Ten results retrieved by them for relevant bug reports. Experiments have been conducted on 106 bug reports of three components from Google chrome, browser. Result shows that LSI performs better in most cases in comparison to VSM.;Incluído;
2016/06/13 23:24:37;Clarke2010;A COMMON COMPUTATIONAL SCIENCE ENVIRONMENT FOR HIGH PERFORMANCE COMPUTING CENTERS;2010;"The Computational Sciences Environment (CSE) was developed to provide a standard development platform for data analysis, visualization, and software testing and evaluation. The Classified Data Analysis and Assessment Center (CDAAC), in conjunction with the Computational Sciences and Engineering Branch (CSEB) of the Army Research Laboratory, assembled a set of open source data analysis tools and applications, software management and testing tools, and libraries necessary to run the tools; and made them available as a package called CSE. CSE also provides experimental software builds for users who might need newer features than what is currently available in the release package. The CSE team provides support for developers, the end-user, and distributed development teams. Tests are regularly run on the software, both current and release, and the results are submitted to quality dashboards for review using CTest. CTest is part of an open-source software building tool called CMake. Developers can use CSE as a template and can customize it to meet their specific project goals. CSE provides developers with a common tool set to assist in developing portable high performance computing (HPC) Applications. Development of CSE has been managed through an open-source project management application that provides Software Configuration Management (SCM) integration of the CSE repository, informational wikis, bug tracking, and feature requests. To support distributed development teams, CSE provides project management tools, software repositories, SCM, and online software quality dashboards.";Removido;
2016/06/13 23:25:18;Corley2011;RECOVERING TRACEABILITY LINKS BETWEEN SOURCE CODE AND FIXED BUGS VIA PATCH ANALYSIS;2011;Traceability links can be recovered using data mined from a revision control system, such as CVS, and an issue tracking system, such as Bugzilla. Existing approaches to recover links between a bug and the methods changed to fix the bug rely on the presence of the bug's identifier in a CVS log message. In this paper we present an approach that relies instead on the presence of a patch in the issue report for the bug. That is, rather than analyzing deltas retrieved from CVS to recover links, our approach analyzes patches retrieved from Bugzilla. We use BugTrace, the tool implementing our approach, to conduct a case study in which we compare the links recovered by our approach to links recovered by manual inspection. The results of the case study support the efficacy of our approach. After describing the limitations of our case study, we conclude by reviewing closely related work and suggesting possible future work. © 2011 ACM.;Incluído;
2016/06/13 23:26:14;Correa2013b;SAMEKANA: A BROWSER EXTENSION FOR INCLUDING RELEVANT WEB LINKS IN ISSUE TRACKING SYSTEM DISCUSSION FORUM;2013;Several widely used Issue tracking systems (such as Google Issue Tracker and Bugzilla) contains an integrated threaded discussion forum to facilitate discussion between the development and maintenance team (bug reporters, bug triagers, bug fixers and quality assurance managers). We observe that several comments (and even bug report descriptions) posted to issue tracing system contains links to external websites as references to knowledge sources relevant to the discussion. We conduct a survey (and present the results of the survey) of Google Chromium Developers on the importance and usefulness of web references in issue tracking system comments and the need of a web-browser extension which facilitates easy organization and inclusion of web-links in the post. We conduct a characterization study on an experimental dataset from Google Chromium Issue Tracking system and present results on the distribution of number of links in the dataset, categorization of links into predefined classes (such as blogs, community based Q&A websites, developer discussion forums, version control system), correlation of number and types of links with various bug report types (such as security, crash, regression and clean-up) and relation between presence of links and bug resolution time. Survey results and data characterization study motivate the need of building a developer productivity tool to facilitate web-link (as references) organization and inclusion in issue tracking system comments. We present a Google ChromiumWeb Browser Extension called as Samekana and publish the extension on Google Chromium Web Store which can be freely downloaded by users worldwide. The extension contains features such as annotating (using tags, title and description) and saving web references pertaining to multiple bug reports and tasks and then posting it as bibliography (for easy citation and reference) in issue tracking system comments. © 2013 IEEE.;Incluído;
2016/06/13 23:27:58;Lazar:2014:GDB:2597073.2597128;GENERATING DUPLICATE BUG DATASETS;2014;Automatic identification of duplicate bug reports is an important research problem in the mining software repositories field. This paper presents a collection of bug datasets collected, cleaned and preprocessed for the duplicate bug report identification problem. The datasets were extracted from open-source systems that use Bugzilla as their bug tracking component and contain all the bugs ever submitted. The systems used are Eclipse, Open Office, NetBeans and Mozilla. For each dataset, we store both the initial data and the cleaned data in separate collections in a mongoDB document-oriented database. For each dataset, in addition to the bug data collections downloaded from bug repositories, the database includes a set of all pairs of duplicate bugs together with randomly selected pairs of non-duplicate bugs. Such a dataset is useful as input for classification models and forms a good base to support replications and comparisons by other researchers. We used a subset of this data to predict duplicate bug reports but the same data set may also be used to predict bug priorities and severity.;Removido;
2016/06/13 23:29:43;Lerch:2013:FDY:2495256.2495763;FINDING DUPLICATES OF YOUR YET UNWRITTEN BUG REPORT;2013;Software projects often use bug-tracking tools to keep track of reported bugs and to provide a communication platform to discuss possible solutions or ways to reproduce failures. The goal is to reduce testing efforts for the development team. However, often, multiple bug reports are committed for the same bug, which, if not recognized as duplicates, can result in work done multiple times by the development team. Duplicate recognition is, in turn, tedious, requiring to examine large amounts of bug reports. Previous work addresses this problem by employing natural-language processing and text similarity measures to automate bug-report duplicate detection. The downside of these techniques is that, to be applicable, they require a reporting user to go through the time-consuming process of describing the problem, just to get informed that the bug is already known. To address this problem, we propose an approach that only uses stack traces and their structure as input to machine-learning algorithms for detecting bug-report duplicates. The key advantage is that stack traces are available without a written bug report. Experiments on bug reports from the Eclipse project show that our approach performs as good as state-of-the-art techniques, but without requiring the whole text corpus of a bug report to be available;Incluído;
2016/06/13 23:30:44;Cosentino2015;GITANA: A SQL-BASED GIT REPOSITORY INSPECTOR;2015;Software development projects are notoriously complex and difficult to deal with. Several support tools such as issue tracking, code review and Source Control Management (SCM) systems have been introduced in the past decades to ease development activities. While such tools efficiently track the evolution of a given aspect of the project (e.g., bug reports), they provide just a partial view of the project and often lack of advanced querying mechanisms limiting themselves to command line or simple GUI support. This is particularly true for projects that rely on Git, the most popular SCM system today. In this paper, we propose a conceptual schema for Git and an approach that, given a Git repository, exports its data to a relational database in order to (1) promote data integration with other existing SCM tools and (2) enable writing queries on Git data using standard SQL syntax. To ensure efficiency, our approach comes with an incremental propagation mechanism that refreshes the database content with the latest modifications. We have implemented our approach in Gitana, an open-source tool available on GitHub. © Springer International Publishing Switzerland 2015.;Removido;
2016/06/13 23:32:32;DAmbros2008;SUPPORTING SOFTWARE EVOLUTION ANALYSIS WITH HISTORICAL DEPENDENCIES AND DEFECT INFORMATION;2008;More than 90% of the cost of software is due to maintenance and evolution. Understanding the evolution of large software systems is a complex problem, which requires the use of various techniques and the support of tools. Several software evolution approaches put the emphasis on structural entities such as packages, classes and structural relationships. However, software evolution is not only about the history of software artifacts, but it also includes other types of data such as problem reports, mailing list archives etc. We propose an approach which focuses on historical dependencies and defects. We claim that they play an important role in software evolution and they are complementary to techniques based on structural information. We use historical dependencies and defect information to learn about a software system and detect potential problems in the source code. Moreover, based on design flaws detected in the source code, we predict the location of future bugs to focus maintenance activities on the buggy parts of the system. We validated our defect prediction by comparing it with the actual defects reported in the bug tracking system.;Removido;
2016/06/13 23:33:21;DAmbros2008a;A FLEXIBLE FRAMEWORK TO SUPPORT COLLABORATIVE SOFTWARE EVOLUTION ANALYSIS;2008;To understand the evolution of software, researchers have developed a plethora of tools to parse, model, and analyze the history of systems. Despite their usefulness, a common downside of such tools is that their use comes with many strings attached, such as installation, data formats, usability, etc. The result is that many tools are only used by their creators, which is detrimental to cross-fertilization of research ideas and collaborative analysis. In this paper we present the Churrasco framework, which supports software evolution modeling, visualization and analysis through a web interface. The user provides only the URL of the Subversion repository to be analyzed and, if available, of the corresponding bug tracking system. Churrasco processes the given data and automatically creates and stores an evolutionary model in a centralized database. This database, called Meta-base is connected to Churrasco through object-relational persistence. The persistency mechanism is meta-described in terms of the EMOF meta-meta- model and automatically generated based on any given evolutionary meta-model. In case the meta-model changes, the persistency mechanism is automatically updated. After providing a detailed description of Churrasco, we provide evidence, by means of an example scenario, that it allows for collaborative software evolution analysis, based on visualizations available on our analysis web portal.;Removido;
2016/06/13 23:34:43;DAmbros2007;"
""A Bug's Life"" Visualizing a Bug Database";2007;Visualization has long been accepted as a viable means to comprehend large amounts of information. Especially in the context of software evolution a well-designed visualization is crucial to be able to cope with the sheer data that needs to be analyzed. Many approaches have been investigated to visualize evolving systems, but most of them focus on structural data and are useful to answer questions about the structural evolution of a system. In this paper we consider an often neglected type of information, namely the one provided by bug tracking systems, which store data about the problems that various people, from developers to end users, detected and reported. We first briefly introduce the context by reporting on the particularities of the present data, and then propose two visualizations to render bugs as first-level entities.;Incluído;
2016/06/13 23:35:16;Damiani:2006:OSS:1137827;OPEN SOURCE SYSTEMS: IFIP WORKING GROUP 2.13 FOUNDATION CONFERENCE ON OPEN SOURCE SOFTWARE, JUNE 8-10, 2006, COMO, ITALY (IFIP INTERNATIONAL FEDERATION FOR INFORMATION PROCESSING);2005;OPEN SOURCE SYSTEMS: IFIP WORKING GROUP 2.13 FOUNDATION CONFERENCE ON OPEN SOURCE SOFTWARE, JUNE 8-10, 2006, COMO, ITALY (IFIP INTERNATIONAL FEDERATION FOR INFORMATION PROCESSING);Removido;
2016/06/13 23:36:52;Davies:2014:WBR:2652524.2652541;WHAT'S IN A BUG REPORT?;2014;"

Context: Bug reports are the primary means by which users of a system are able to communicate a problem to the developers, and their contents are important - not only to support developers in maintaining the system, but also as the basis of automated tools to assist in the challenging tasks of finding and fixing bugs.

Goal: This paper aims to investigate how users report bugs in systems: what information is provided, how frequently, and the consequences of this.

Method: The study examined the quality and quantity of information provided in 1600 bugs reports drawn from four open-source projects (Eclipse, Firefox, Apache HTTP, and Facebook API), recorded what information users actually provide, how and when users provide the information, and how this affects the outcome of the bug.

Results: Of the recorded sources of information, only observed behaviour and expected results appeared in more than 50% of reports. Those sources deemed highly useful by developers and tools such as stack traces and test cases appeared very infrequently. However, no strong relationship was observed between the provided information and the outcome of the bug.

Conclusions: The paper demonstrates a clear mismatch between the information that developers would wish to appear in a bug report, and the information that actually appears. Furthermore, the quality of bug reports has an important impact on research which might rely on extracting this information automatically.
";Removido;
2016/06/13 23:37:29;Davies2014a;COMPARING TEXT-BASED AND DEPENDENCE-BASED APPROACHES FOR DETERMINING THE ORIGINS OF BUGS;2014;Identifying bug origins - the point where erroneous code was introduced - is crucial for many software engineering activities, from identifying process weaknesses to gathering data to support bug detection tools. Unfortunately, this information is not usually recorded when fixing bugs, and recovering it later is challenging. Recently, the text approach and the dependence approach have been developed to tackle this problem. Respectively, they examine textual and dependence-related changes that occurred prior to a bug fix. However, only limited evaluation has been carried out, partially because of a lack of available implementations and of datasets linking bugs to origins. To address this, origins of 174 bugs in three projects were manually identified and compared to a simulation of the approaches. Both approaches were partially successful across a variety of bugs - achieving 29-79% precision and 40-70% recall. Results suggested the precise definition of program dependence could affect performance, as could whether the approaches identified a single or multiple origins. Some potential improvements are explored in detail and identify pragmatic strategies for combining techniques along with simple modifications. Even after adopting these improvements, there remain many challenges: large commits, unrelated changes and long periods between origins and fixes all reduce effectiveness. Copyright © 2013 John Wiley & Sons, Ltd.;Incluído;
2016/06/13 23:38:28;DeCastroNetto2016;AN AUTOMATED APPROACH FOR SCHEDULING BUG FIX TASKS;2016;Software projects usually maintain bug repositories where both developers and end users can report and track the resolution of software defects. These defects should be fixed and new versions of the software incorporating the patches that solve them must be released. The project manager must schedule a set of error correction tasks with different priorities in order to minimize the time required to accomplish these tasks and guarantee that the more important issues have been fixed. This problem is recurrent for most software organizations and, given the enormous number of potential schedules, a tool that searches for good schedules may be helpful to project managers. In this work we propose a genetic algorithm using information captured from bug repositories to find near optimal schedules. We evaluated our approach using a subset of the Eclipse bug repository and the results suggested better schedules than the schedule followed by the developers and schedules proposed by a simpler search procedure. © 2016 World Scientific Publishing Company.;Incluído;
2016/06/13 23:39:07;Ding2012;HEALING ONLINE SERVICE SYSTEMS VIA MINING HISTORICAL ISSUE REPOSITORIES;2012;Online service systems have been increasingly popular and important nowadays, with an increasing demand on the availability of services provided by these systems, while significant efforts have been made to strive for keeping services up continuously. Therefore, reducing the MTTR (Mean Time to Restore) of a service remains the most important step to assure the user-perceived availability of the service. To reduce the MTTR, a common practice is to restore the service by identifying and applying an appropriate healing action (i.e., a temporary workaround action such as rebooting a SQL machine). However, manually identifying an appropriate healing action for a given new issue (such as service down) is typically time consuming and error prone. To address this challenge, in this paper, we present an automated mining-based approach for suggesting an appropriate healing action for a given new issue. Our approach generates signatures of an issue from its corresponding transaction logs and then retrieves historical issues from a historical issue repository. Finally, our approach suggests an appropriate healing action by adapting healing actions for the retrieved historical issues. We have implemented a healing suggestion system for our approach and applied it to a real-world product online service that serves millions of online customers globally. The studies on 77 incidents (severe issues) over 3 months showed that our approach can effectively provide appropriate healing actions to reduce the MTTR of the service.;Removido;
2016/06/13 23:41:20;DucAnh:2011:EVH:2020390.2020403;EMPIRICAL VALIDATION OF HUMAN FACTORS IN PREDICTING ISSUE LEAD TIME IN OPEN SOURCE PROJECTS;2011;[Context] Software developers often spend a significant portion of their resources resolving submitted evolution issue reports. Classification or prediction of issue lead time is useful for prioritizing evolution issues and supporting human resources allocation in software maintenance. However, the predictability of issue lead time is still a research gap that calls for more empirical investigation. [Aim] In this paper, we empirically assess different types of issue lead time prediction models using human factor measures collected from issue tracking systems. [Method] We conduct an empirical investigation of three active open source projects. A machine learning based classification and statistical univariate and multivariate analyses are performed. [Results] The accuracy of classification models in ten-fold cross-validation varies from 75.56% to 91%. The R2 value of linear multivariate regression models ranges from 0.29 to 0.60. Correlation analysis confirms the effectiveness of collaboration measures, such as the number of stakeholders and number of comments, in prediction models. The measures of assignee past performance are also an effective indicator of issue lead time. [Conclusions] The results indicate that the number of stakeholders and average past issue lead time are important variables in constructing prediction models of issue lead time. However, more variables should be explored to achieve better prediction performance.;Removido;
2016/06/13 23:42:52;Ebert:2015:ESE:2794082.2794106;AN EXPLORATORY STUDY ON EXCEPTION HANDLING BUGS IN JAVA PROGRAMS;2015;"Most mainstream programming languages provide constructs to throw and to handle exceptions. However, several studies argue that exception handling code is usually of poor quality and that it is commonly neglected by developers. Moreover, it is said to be the least understood, documented, and tested part of the implementation of a system. Nevertheless, there are very few studies that analyze the actual exception handling bugs that occur in real software systems or that attempt to understand developers’ perceptions of these bugs. In this work we present an exploratory study on exception handling bugs that employs two complementary approaches: a survey of 154 developers and an analysis of 220 exception handling bugs from the repositories of Eclipse and Tomcat.

Only 27% of the respondents claimed that policies and standards for the implementation of error handling are part of the culture of their organizations. Moreover, in 70% of the organizations there are no specific tests for the exception handling code. Also, 61% of the respondents stated that no to little importance is given to the documentation of exception handling in the design phase of the projects with which they are involved. In addition, about 40% of the respondents consider the quality of exception handling code to be either good or very good and only 14% of the respondents consider it to be bad or very bad. Furthermore, the repository analysis has shown (with statistical significance) that exception handling bugs are ignored by developers less often than other bugs. We have also observed that while overly general catch blocks are a well-known bad smell related to exceptions, bugs stemming from these catch blocks are rare, even though many overly general catch blocks occur in the code. Furthermore, while developers often mention empty catch blocks as causes of bugs they have fixed in the past, we found very few bug reports caused by them. On top of that, empty catch blocks are frequently used as part of bug fixes, including fixes for exception handling bugs.

Based on our findings, we propose a classification of exception handling bugs and their causes. The proposed classification can be used to assist in the design and implementation of test suites, to guide code inspections, or as a basis for static analysis tools.";Removido;
2016/06/13 23:43:40;Garcia2013;THE ROLE OF EMOTIONS IN CONTRIBUTORS ACTIVITY: A CASE STUDY ON THE GENTOO COMMUNITY;2013;We analyze the relation between the emotions and the activity of contributors in the Open Source Software project GENTOO. Our case study builds on extensive data sets from the project's bug tracking platform BUGZILLA, to quantify the activity of contributors, and its mail archives, to quantify the emotions of contributors by means of sentiment analysis. The GENTOO project is known for a period of centralization within its bug triaging community. This was followed by considerable changes in community organization and performance after the sudden retirement of the central contributor. We analyze how this event correlates with the negative emotions, both in bilateral email discussions with the central contributor, and at the level of the whole community of contributors. We then extend our study to consider the activity patterns of GENTOO contributors in general. We find that contributors are more likely to become inactive when they express strong positive or negative emotions in the bug tracker, or when they deviate from the expected value of emotions in the mailing list. We use these insights to develop a Bayesian classifier that detects the risk of contributors leaving the project. Our analysis opens new perspectives for measuring online contributor motivation by means of sentiment analysis and for real-time predictions of contributor turnover in Open Source Software projects.;Removido;
2016/06/13 23:44:55;Felderer2015;USING DEFECT TAXONOMIES FOR TESTING REQUIREMENTS;2015;Systematic defect management based on bug-tracking systems such as Bugzilla is well established and has been successfully used in many software organizations. Defect management weights the failures observed during test execution according to their severity and forms the basis for effective defect taxonomies. In practice, most defect taxonomies are used only for the a posteriori allocation of testing resources to prioritize failures for debugging. Thus, these taxonomies' full potential to control and improve all the steps of testing has remained unexploited. This is especially the case for testing a system's user requirements. System-level defect taxonomies can improve the design of requirements-based tests, the tracing of defects to requirements, the quality assessment of requirements, and the control of the relevant defect management. So, we developed requirements-based testing with defect taxonomies (RTDT). This approach is aligned with the standard test process and uses defect taxonomies to support all phases of testing requirements. To illustrate this approach and its benefits, we use an example project (which we call Project A) from a public health insurance institution.;Removido;
2016/06/13 23:45:35;Feng2013;PRACTICAL DUPLICATE BUG REPORTS DETECTION IN A LARGE WEB-BASED DEVELOPMENT COMMUNITY;2013;Most of large web-based development communities require a bug tracking system to keep track of various bug reports. However, duplicate bug reports tend to result in waste of resources, and may cause potential conflicts. There have been two types of works focusing on this problem: relevant bug report retrieval [8][11][10][13] and duplicate bug report identification [5][12]. The former methods can achieve high accuracy (82%) in the top 10 results in some dataset, but they do not really reduce the workload of developers. The latter methods still need further improvement on the performance. In this paper, we propose a practical duplicate bug reports detection method, which aims to help project team to reduce their workload by combining existing two categories of methods. We also propose some new features extracted from comments, user profiles and query feedback, which are useful for improving the detection performance. Experiments on real dataset show that our method improves the accuracy rate by 23% compared to state-of-the-art work in duplicate bug report identification, and improves the recall rate by up to 8% in relevant bug report retrieval. © 2013 Springer-Verlag.;Incluído;
2016/06/13 23:47:00;Fischer2003;POPULATING A RELEASE HISTORY DATABASE FROM VERSION CONTROL AND BUG TRACKING SYSTEMS;2003;Version control and bug tracking systems contain large amounts of historical information that can give deep insight into the evolution of a software project. Unfortunately, these systems provide only insufficient support for a detailed analysis of software evolution aspects. We address this problem and introduce an approach for populating a release history database that combines version data with bug tracking data and adds missing data not covered by version control systems such as merge points. Then simple queries can be applied to the structured data to obtain meaningful views showing the evolution of a software project. Such views enable more accurate reasoning of evolutionary aspects and facilitate the anticipation of software evolution. We demonstrate our approach on the large open source project Mozilla that offers great opportunities to compare results and validate our approach.;incluído para Revisão em Pares;
2016/06/13 23:49:04;Guo:2011:MBO:1958824.1958887;"""Not my bug!"" and other reasons for software bug report reassignments";2011;"

Bug reporting/fixing is an important social part of the soft-ware development process. The bug-fixing process inher-ently has strong inter-personal dynamics at play, especially in how to find the optimal person to handle a bug report. Bug report reassignments, which are a common part of the bug-fixing process, have rarely been studied.

In this paper, we present a large-scale quantitative and qualitative analysis of the bug reassignment process in the Microsoft Windows Vista operating system project. We quantify social interactions in terms of both useful and harmful reassignments. For instance, we found that reassignments are useful to determine the best person to fix a bug, contrary to the popular opinion that reassignments are always harmful. We categorized five primary reasons for reassignments: finding the root cause, determining ownership, poor bug report quality, hard to determine proper fix, and workload balancing. We then use these findings to make recommendations for the design of more socially-aware bug tracking systems that can overcome some of the inefficiencies we observed in our study.
";Removido;
2016/06/13 23:49:44;Gegick2010;IDENTIFYING SECURITY BUG REPORTS VIA TEXT MINING: AN INDUSTRIAL CASE STUDY;2010;A bug-tracking system such as Bugzilla contains bug reports (BRs) collected from various sources such as development teams, testing teams, and end users. When bug reporters submit bug reports to a bug-tracking system, the bug reporters need to label the bug reports as security bug reports (SBRs) or not, to indicate whether the involved bugs are security problems. These SBRs generally deserve higher priority in bug fixing than not-security bug reports (NSBRs). However, in the bug-reporting process, bug reporters often mislabel SBRs as NSBRs partly due to lack of security domain knowledge. This mislabeling could cause serious damage to software-system stakeholders due to the induced delay of identifying and fixing the involved security bugs. To address this important issue, we developed a new approach that applies text mining on natural-language descriptions of BRs to train a statistical model on already manually-labeled BRs to identify SBRs that are manually-mislabeled as NSBRs. Security engineers can use the model to automate the classification of BRs from large bug databases to reduce the time that they spend on searching for SBRs. We evaluated the model's predictions on a large Cisco software system with over ten million source lines of code. Among a sample of BRs that Cisco bug reporters manually labeled as NSBRs in bug reporting, our model successfully classified a high percentage (78%) of the SBRs as verified by Cisco security engineers, and predicted their classification as SBRs with a probability of at least 0.98.;Incluído;
2016/06/13 23:50:31;Ghezzi2011a;SOFAS: A LIGHTWEIGHT ARCHITECTURE FOR SOFTWARE ANALYSIS AS A SERVICE;2011;Access to data stored in software repositories by systems such as version control, bug and issue tracking, or mailing lists is essential for assessing the quality of a software system. A myriad of analyses exploiting that data have been proposed throughout the years: source code analysis, code duplication analysis, co-change analysis, bug prediction, or detection of bug fixing patterns. However, easy and straight forward synergies between these analyses rarely exist. To tackle this problem we have developed SOFA S, a distributed and collaborative software analysis platform to enable a seamless interoperation of such analyses. In particular, software analyses are offered as RESTful web services that can be accessed and composed over the Internet. SOFA S services are accessible through a software analysis catalog where any project stakeholder can, depending on the needs or interests, pick specific analyses, combine them, let them run remotely and then fetch the final results. That way, software developers, testers, architects, or quality assurance experts are given access to quality analysis services. They are shielded from many peculiarities of tool installations and configurations, but SOFA S offers them sophisticated and easy-to-use analyses. This paper describes in detail our SOFAS architecture, its considerations and implementation aspects, and the current set of implemented and offered RESTful analysis services. © 2011 IEEE.;Removido;
2016/06/13 23:51:35;Gonzalez-Barahona:2013:UCI:2553372.2553381;UNDERSTANDING HOW COMPANIES INTERACT WITH FREE SOFTWARE COMMUNITIES;2013;When free, open source software development communities work with companies that use their output, it's especially important for both parties to understand how this collaboration is performing. The use of data analytics techniques on software development repositories can improve factual knowledge about performance metrics.;Removido;
2016/06/13 23:52:27;Gonzalez-Barahona2015;THE METRICSGRIMOIRE DATABASE COLLECTION;2015;The Metrics Grimoire system is composed by a set of tools designed to retrieve data from repositories related to software development. Their aim is to produce organized databases suitable for easy querying with research and industrial purposes. The data in those databases have a similar structure, to easy cross-database studies, and can be enriched with information such as linkage of the multiple identities of actors, or their affiliation. This paper presents the general structure of those databases, and a collection of up-to-date database dumps that are publicly available. They correspond to two well-known projects, Open Stack, and Eclipse, including data from source code management repositories, issue tracking systems, mailing lists, and code review systems.;Removido;
2016/06/13 23:53:46;Gunderloy2005;PAINLESS PROJECT MANAGEMENT WITH FOGBUGZ;2005;A very well put together manual about how and why things work the way they do within FogBugz 4.0. - Matt Hawley, eWorld.UI This book is an almost perfect introduction and end user manual for FogBugz version 4. - Dean Wilson, London.pm I recommend this book if you do plan to use FogBugz. - Greg Robinson's Blog & well written and easy to get through & - .farshid sedghi Blog I quickly realized that FogBugz could single-handedly manage my support requests, sales requests, bug tracking and project management for CodeSmith. I bought my copy about a week ago and I could not be more happy with my purchase! - Eric J. Smith's Weblog Many programs purport to help a development team manage a projectbut most of them aren't very good. Enter FogBugz. This dynamic tool is based on keeping track of a database of cases. At any given time, cases are assigned to one person, who must resolve or forward them to someone else. With FogBugz, cases can be prioritized, documented, sorted, discussed, edited, assigned, estimated, searched, and tracked. And because FogBugz is web-based, everyone on a development team has access to the whole picture, at any given moment. That picture may include everything from customer feature requests, to high-level design discussions, to tiny bug fix details. This book (written under the guidance of the entire FogBugz team) completely describes the ins and outs of the latest version of FogBugz. Copyright © 2005 by Mike Gunderloy. All rights reserved.;Removido;
2016/06/13 23:56:48;Gupta:2014:PMM:2597073.2597081;PROCESS MINING MULTIPLE REPOSITORIES FOR SOFTWARE DEFECT RESOLUTION FROM CONTROL AND ORGANIZATIONAL PERSPECTIVE;2014;Issue reporting and resolution is a software engineering process supported by tools such as Issue Tracking System (ITS), Peer Code Review (PCR) system and Version Control System (VCS). Several open source software projects such as Google Chromium and Android follow process in which a defect or feature enhancement request is reported to an issue tracker followed by source-code change or patch review and patch commit using a version control system. We present an application of process mining three software repositories (ITS, PCR and VCS) from control flow and organizational perspective for effective process management. ITS, PCR and VCS are not explicitly linked so we implement regular expression based heuristics to integrate data from three repositories for Google Chromium project. We define activities such as bug reporting, bug fixing, bug verification, patch submission, patch review, and source code commit and create an event log of the bug resolution process. The extracted event log contains audit trail data such as caseID, timestamp, activity name and performer. We discover runtime process model for bug resolution process spanning three repositories using process mining tool, Disco, and conduct process performance and efficiency analysis. We identify bottlenecks, define and detect basic and composite anti-patterns. In addition to control flow analysis, we mine event log to perform organizational analysis and discover metrics such as handover of work, subcontracting, joint cases and joint activities. ;Incluído;
2016/06/14 07:28:31;Guzzi2013;COMMUNICATION IN OPEN SOURCE SOFTWARE DEVELOPMENT MAILING LISTS;2013;Open source software (OSS) development teams use electronic means, such as emails, instant messaging, or forums, to conduct open and public discussions. Researchers investigated mailing lists considering them as a hub for project communication. Prior work focused on specific aspects of emails, for example the handling of patches, traceability concerns, or social networks. This led to insights pertaining to the investigated aspects, but not to a comprehensive view of what developers communicate about. Our objective is to increase the understanding of development mailing lists communication. We quantitatively and qualitatively analyzed a sample of 506 email threads from the development mailing list of a major OSS project, Lucene. Our investigation reveals that implementation details are discussed only in about 35% of the threads, and that a range of other topics is discussed. Moreover, core developers participate in less than 75% of the threads. We observed that the development mailing list is not the main player in OSS project communication, as it also includes other channels such as the issue repository.;Removido;
2016/06/14 08:28:03;Gyimesi2015;CHARACTERIZATION OF SOURCE CODE DEFECTS BY DATA MINING CONDUCTED ON GITHUB;2015;In software systems the coding errors are unavoidable due to the frequent source changes, the tight deadlines and the inaccurate specifications. Therefore, it is important to have tools that help us in finding these errors. One way of supporting bug prediction is to analyze the characteristics of the previous errors and identify the unknown ones based on these characteristics. This paper aims to characterize the known coding errors. Nowadays, the popularity of the source code hosting services like GitHub are increasing rapidly. They provide a variety of services, among which the most important ones are the version and bug tracking systems. Version control systems store all versions of the source code, and bug tracking systems provide a unified interface for reporting errors. Bug reports can be used to identify the wrong and the previously fixed source code parts, thus the bugs can be characterized by static source code metrics or by other quantitatively measured properties using the gathered data. We chose GitHub for the base of data collection and we selected 13 Java projects for analysis. As a result, a database was constructed, which characterizes the bugs of the examined projects, thus can be used, inter alia, to improve the automatic detection of software defects. © Springer International Publishing Switzerland 2015.;Removido;
2016/06/14 08:31:16;Habayeb2015;THE FIREFOX TEMPORAL DEFECT DATASET;2015;The bug tracking repositories of software projects capture initial defect (bug) reports and the history of interactions among developers, testers, and customers. Extracting and mining information from these repositories is time consuming and daunting. Researchers have focused mostly on analyzing the frequency of the occurrence of defects and their attributes (e.g., The number of comments and lines of code changed, count of developers). However, the counting process eliminates information about the temporal alignment of events leading to changes in the attributes count. Software quality teams could plan and prioritize their work more efficiently if they were aware of these temporal sequences and knew their frequency of occurrence. In this paper, we introduce a novel dataset mined from the Fire fox bug repository (Bugzilla) which contains information about the temporal alignment of developer interactions. Our dataset covers eight years of data from the Fire fox project on activities throughout the project's lifecycle. Some of these activities have not been reported in frequency-based or other temporal datasets. The dataset we mined from the Fire fox project contains new activities, such as reporter experience, file exchange events, code-review process activities, and setting of milestones. We believe that this new dataset will improve analysis of bug reports and enable mining of temporal relationships so that practitioners can enhance their bug-fixing process.;Removido;
2016/06/14 09:22:23;Hamlaoui2014;HETEROGENEOUS MODELS MATCHING FOR CONSISTENCY MANAGEMENT;2014;This work is situated in the context of the application of Model Driven Engineering to complex systems view-based modelling. In fact, view-based models - called also partial models - are manipulated by different actors (designers), and are thus generally heterogeneous, that is, described with different DSLs (Domain Specific Languages). Instead of building a single global model, which is not realistic, we propose to organize the different partial models as a network of related models, which provides a global view of the system through a correspondence model. As models are modelled separately by different designers, they also evolve separately that induces a problem of consistency. To solve it, we propose a semi-automatic process based on the correspondence model allowing detecting changes, calculating their impacts, and proposing modifications to maintain the consistency among them. The approach is supported by a tool chain and illustrated by the example of a Bug Tracking System.;Removido;
2016/06/14 09:24:57;Hanmer:2014:MNP:2893559.2893568;MINING NEW PATTERNS BY LEARNING FROM THE TRENCHES;2014;Pattern Mining is a scientific and experimental process where methods of knowledge discovery are used to find established ways of software analysis, design, implementation, and maintenance, and then describe such findings in as reusable knowledge for a given context. Over years, several traditional pattern mining techniques have been used in the community to collect tactic and specific design knowledge across different projects and organizations and present them in explicit and generic form of software patterns. This paper introduces a new dimension to the practice of pattern mining, where a set of design analysis tools and automated design discovery and knowledge mining techniques are used to mine large scale software repositories, publicly available bug reports in issue tracking software and the open information presented on the web to extract new patterns. The collective knowledge gleaned from this effort can be used to define new patterns or pattern prototypes for improving software productivity. This paper presents a set of such patterns and illustrates anecdotal examples of the new patterns discovered through these techniques. Furthermore, this paper discusses the challenges faced by the pattern community in order to continue discovering, maintaining and organizing patterns in a systematic and usable way.;Removido;
2016/06/14 09:40:42;Hindle2016;A CONTEXTUAL APPROACH TOWARDS MORE ACCURATE DUPLICATE BUG REPORT DETECTION AND RANKING;2016;The issue-tracking systems used by software projects contain issues, bugs, or tickets written by a wide variety of bug reporters, with different levels of training and knowledge about the system under development. Typically, reporters lack the skills and/or time to search the issue-tracking system for similar issues already reported. As a result, many reports end up referring to the same issue, which effectively makes the bug-report triaging process time consuming and error prone. Many researchers have approached the bug-deduplication problem using off-the-shelf information-retrieval (IR) tools. In this work, we extend the state of the art by investigating how contextual information about software-quality attributes, software-architecture terms, and system-development topics can be exploited to improve bug deduplication. We demonstrate the effectiveness of our contextual bug-deduplication method at ranking duplicates on the bug repositories of the Android, Eclipse, Mozilla, and OpenOffice software systems. Based on this experience, we conclude that taking into account domain-specific context can improve IR methods for bug deduplication. © 2015, Springer Science+Business Media New York.;Incluído;
2016/06/14 09:42:31;Hora2012;BUG MAPS: A TOOL FOR THE VISUAL EXPLORATION AND ANALYSIS OF BUGS;2012;To harness the complexity of big legacy software, software engineering tools need more and more information on these systems. This information may come from analysis of the source code, study of execution traces, computing of metrics, etc. One source of information received less attention than source code: the bugs on the system. Little is known about the evolutionary behavior, lifetime, distribution, and stability of bugs. In this paper, we propose to consider bugs as first class entities and a useful source of information that can answer such topics. Such analysis is inherently complex, because bugs are intangible, invisible, and difficult to be traced. Therefore, our tool extracts information about bugs from bug tracking systems, link this information to other software artifacts, and explore interactive visualizations of bugs that we call bug maps.;Incluído;
2016/06/14 12:28:17;Hosseini:2012:MBA:2191744.2192559;A MARKET-BASED BUG ALLOCATION MECHANISM USING PREDICTIVE BUG LIFETIMES;2012;Bug assignment in large software projects is typically a time-consuming and tedious task, effective assignment requires that bug triagers hold significant contextual information about both the reported bugs and the pool of available developers. In this paper, we propose an auction-based multiagent mechanism for assigning bugs to developers that is intended to minimize backlogs and overall bug lifetime. In this approach, developers and triagers are both modeled as intelligent software agents working on behalf of individuals in a multiagent environment. Upon receiving a bug report, triager agents auction off the bug and collect the requests. Developer agents compute their bids as a function of the developer's profile, preferences, current schedule of assigned bugs, and estimated time-to-fix of the bug. This value is then sent to the triager agent for the final decision. We use the Eclipse and Fire fox bug repositories to validate our approach, our studies suggest that the proposed auction-based multiagent mechanism can improve the bug assignment process compared to currently practised methods. In particular, we found a 16% improvement in the number of fixed bugs compared to the historic data, based on a sample size of 213,000 bug reports over a period of 6 years.;Incluído;
2016/06/14 13:05:49;Izquierdo2015;GILA: GITHUB LABEL ANALYZER;2015;Reporting bugs, asking for new features and in general giving any kind of feedback is a common way to contribute to an Open-Source Software (OSS) project. In GitHub, the largest code hosting service for OSS, this feedback is typically expressed as new issues for the project managed by an issue-tracking system available in each new project repository. Among other features, the issue tracker allows creating and assigning labels to issues with the goal of helping the project community to better classify and manage those issues (e.g., facilitating the identification of issues for top priority components or candidate developers that could solve them). Nevertheless, as the project grows a manual browsing of the project issues is no longer feasible. In this paper we present GiLA, a tool which generates a set of visualizations to facilitate the analysis of issues in a project depending on their label-based categorization. We believe our visualizations are useful to see the most popular labels (and their relationships) in a project, identify the most active community members for those labels and compare the typical issue evolution for each label category.;Incluído;
2016/06/14 13:09:27;Jalbert2008a;AUTOMATED DUPLICATE DETECTION FOR BUG TRACKING SYSTEMS;2008;Bug tracking systems are important tools that guide the maintenance activities of software developers. The utility of these systems is hampered by an excessive number of duplicate bug reports-in some projects as many as a quarter of all reports are duplicates. Developers must manually identify duplicate bug reports, but this identification process is time-consuming and exacerbates the already high cost of software maintenance. We propose a system that automatically classifies duplicate bug reports as they arrive to save developer time. This system uses surface features, textual semantics, and graph clustering to predict duplicate status. Using a dataset of 29,000 bug reports from the Mozilla project, we perform experiments that include a simulation of a real-time bug reporting environment. Our system is able to reduce development cost by filtering out 8% of duplicate bug reports while allowing at least one report for each real defect to reach developers. © 2008 IEEE.;Incluído;
2016/06/14 23:56:52;Jeong:2009:IBT:1595696.1595715;IMPROVING BUG TRIAGE WITH BUG TOSSING GRAPHS;2009;"bug report is typically assigned to a single developer who is then responsible for fixing the bug. In Mozilla and Eclipse, between 37%-44% of bug reports are ""tossed"" (reassigned) to other developers, for example because the bug has been assigned by accident or another developer with additional expertise is needed. In any case, tossing increases the time-to-correction for a bug. In this paper, we introduce a graph model based on Markov chains, which captures bug tossing history. This model has several desirable qualities. First, it reveals developer networks which can be used to discover team structures and to find suitable experts for a new task. Second, it helps to better assign developers to bug reports. In our experiments with 445,000 bug reports, our model reduced tossing events, by up to 72%. In addition, the model increased the prediction accuracy by up to 23 percentage points compared to traditional bug triaging approaches.
";incluído;
2016/06/14 23:56:52;Johnson2003;ISSUE TRACKING;2003;"All programming projects have one thing in common: there is always more to do. Some things that need doing are bug fixes; others are enhancements such as cleaning up and refactorlng existing code, adding tests, and writing documentation. but before your office wall becomes a collage of sticky-note reminders, you might want to try an issue tracker instead. In this article, we describe two open-source issue-tracking software packages: Roundup, an implementation of the winning design in Los Alamos National Laboratory's Software Carpentry contest and Bugzilla (from the GNU project).";Removido;
2016/06/14 23:56:52;Just2008;TOWARDS THE NEXT GENERATION OF BUG TRACKING SYSTEMS;2008;Developers typically rely on the information submitted by end-users to resolve bugs. We conducted a survey on information needs and commonly faced problems with bug reporting among several hundred developers and users of the APACHE, ECLIPSE and MOZILLA projects. In this paper, we present the results of a card sort on the 175 comments sent back to us by the responders of the survey. The card sort revealed several hurdles involved in reporting and resolving bugs, which we present in a collection of recommendations for the design of new bug tracking systems. Such systems could provide contextual assistance, reminders to add information, and most important, assistance to collect and report crucial information to developers.;Removido;
2016/06/14 23:56:52;Lin2009;AN EMPIRICAL STUDY ON BUG ASSIGNMENT AUTOMATION USING CHINESE BUG DATA;2009;Bug assignment is an important step in bug life-cycle management. In large projects, this task would consume a substantial amount of human effort. To compare with the previous studies on automatic bug assignment in FOSS (free/open source software) projects, we conduct a case study on a proprietary software project in China. Our study consists of two experiments of automatic bug assignment, using Chinese text and the other non-text information of bug data respectively. Based on text data of the bug repository, the first experiment uses SVM to predict bug assignments and achieve accuracy close to that by human triagers. The second one explores the usefulness of non-text data in making such prediction. The main results from our study includes that text data are most useful data in the bug tracking system to triage bugs, and automation based on text data could effectively reduce the manual effort.;Incluído;
2016/06/14 23:56:52;Kaushik2012;A COMPARATIVE STUDY OF THE PERFORMANCE OF IR MODELS ON DUPLICATE BUG DETECTION;2012;Open source projects incorporate bug triagers to help with the task of bug report assignment to developers. One of the tasks of a triager is to identify whether an incoming bug report is a duplicate of a pre-existing report. In order to detect duplicate bug reports, a triager either relies on his memory and experience or on the search capabilities of the bug repository. Both these approaches can be time consuming for the triager and may also lead to the misidentification of duplicates. In the literature, several approaches to automate duplicate bug report detection have been proposed. However, there has not been an exhaustive comparison of the performance of different IR models, especially with topic-based ones such as LSI and LDA. In this paper, we compare the performance of the traditional vector space model (using different weighting schemes) with that of topic based models, leveraging heuristics that incorporate exception stack frames, surface features, summary and long description from the free-form text in the bug report. We perform experiments on subsets of bug reports from Eclipse and Firefox and achieve a recall rate of 60% and 58% respectively. We find that word-based models, in particular a Log-Entropy based weighting scheme, outperform topic based ones such as LSI, LDA and Random Projections. Our findings also suggests that for the problem of duplicate bug detection, it is important to consider a project's domain and characteristics to devise a set of heuristics to achieve optimal results.;Removido;
2016/06/14 23:56:52;Keivanloo2012;A LINKED DATA PLATFORM FOR MINING SOFTWARE REPOSITORIES;2012;The mining of software repositories involves the extraction of both basic and value-added information from existing software repositories. The repositories will be mined to extract facts by different stakeholders (e.g. researchers, managers) and for various purposes. To avoid unnecessary pre-processing and analysis steps, sharing and integration of both basic and value-added facts are needed. In this research, we introduce SeCold, an open and collaborative platform for sharing software datasets. SeCold provides the first online software ecosystem Linked Data platform that supports data extraction and on-the-fly inter-dataset integration from major version control, issue tracking, and quality evaluation systems. In its first release, the dataset contains about two billion facts, such as source code statements, software licenses, and code clones from 18 000 software projects. In its second release the SeCold project will contain additional facts mined from issue trackers and versioning systems. Our approach is based on the same fundamental principle as Wikipedia: researchers and tool developers share analysis results obtained from their tools by publishing them as part of the SeCold portal and therefore make them an integrated part of the global knowledge domain. The SeCold project is an official member of the Linked Data dataset cloud and is currently the eighth largest online dataset available on the Web.;Removido;
2016/06/14 23:56:52;Ki2009;AN OPEN SOURCE-BASED APPROACH TO SOFTWARE DEVELOPMENT INFRASTRUCTURES;2009;As software systems become larger and more complex, automated software engineering tools play a crucial role for effective software development management, which is a key factor to lead quality software systems. In this work, we present TRICA, an open source-based software development infrastructure. The name of TRICA represents its features such as Traceability, Relationship, Informativeness, Cost-effectiveness, and Automation. Essentially, in TRICA, a continuous integration tool is coupled with a software configuration management tool and an issue tracking tool. We provisioned a mechanism to connect the open source tools in TRICA so that project members use the collaborated information to solve various issues and implementation problems efficiently, and easily share forthcoming issues during the course of the project. We show that TRICA can help to decentralize risks throughout the software development cycle and achieve successful software development.;Removido;
2016/06/14 23:56:52;Klein:2014:NFD:2597073.2597090;NEW FEATURES FOR DUPLICATE BUG DETECTION;2014;"Issue tracking software of large software projects receive a large volume of issue reports each day. Each of these issues is typically triaged by hand, a time consuming and error prone task. Additionally, issue reporters lack the necessary understanding to know whether their issue has previously been reported. This leads to issue trackers containing a lot of duplicate reports, adding complexity to the triaging task.Duplicate bug report detection is designed to aid developers by automatically grouping bug reports concerning identical issues. Previous work by Alipour et al. has shown that the textual, categorical, and contextual information of an issue report are effective measures in duplicate bug report detection. In our work, we extend previous work by introducing a range of metrics based on the topic distribution of the issue reports, relying only on data taken directly from bug reports. In particular, we introduce a novel metric that measures the first shared topic between two topic-document distributions. This paper details the evaluation of this group of pair-based metrics with a range of machine learning classifiers, using the same issues used by Alipour et al. We demonstrate that the proposed metrics show a significant improvement over previous work, and conclude that the simple metrics we propose should be considered in future studies on bug report deduplication, as well as for more general natural language processing applications.
";Incluído;
2016/06/14 23:56:52;Knab2009;INTERACTIVE VIEWS FOR ANALYZING PROBLEM REPORTS;2009;Issue tracking repositories contain a wealth of information for reasoning about various aspects of software development processes. In this paper, we focus on bug triaging and provide visual means to explore the effort estimation quality and the bug life-cycle of reported problems. Our approach follows the micro/macro reading technique and uses a combination of graphical views to investigate details of individual problem reports while maintaining the context provided by the surrounding data population. This enables the detection and detailed analysis of hidden patterns and facilitates the analysis of problem report outliers. In an industrial study, we use our approach in various problem report analysis scenarios and answer questions related to effort estimation and resource planning.;Incluído;
2016/06/14 23:56:52;Knab:2009:SVA:1595696.1595746;SMART VIEWS FOR ANALYZING PROBLEM REPORTS: TOOL DEMO;2009;;Removido;
2016/06/14 23:56:52;Knauss2012;DETECTING AND CLASSIFYING PATTERNS OF REQUIREMENTS CLARIFICATIONS;2012;In current project environments, requirements often evolve throughout the project and are worked on by stakeholders in large and distributed teams. Such teams often use online tools such as mailing lists, bug tracking systems or online discussion forums to communicate, clarify or coordinate work on requirements. In this kind of environment, the expected evolution from initial idea, through clarification, to a stable requirement, often stagnates. When project managers are not aware of underlying problems, development may proceed before requirements are fully understood and stabilized, leading to numerous implementation issues and often resulting in the need for early redesign and modification. In this paper, we present an approach to analyzing online requirements communication and a method for the detection and classification of clarification events in requirement discussions. We used our approach to analyze online requirements communication in the IBM® Rational Team Concert® (RTC) project and identified a set of six clarification patterns. Since a predominant amount of clarifications through the lifetime of a requirement is often indicative of problematic requirements, our approach lends support to project managers to assess, in real-time, the state of discussions around a requirement and promptly react to requirements problems.;Removido;
2016/06/14 23:56:52;Kochhar:2014:AFI:2680613.2680809;AUTOMATIC FINE-GRAINED ISSUE REPORT RECLASSIFICATION;2014;Issue tracking systems are valuable resources during software maintenance activities. These systems contain different categories of issue reports such as bug, request for improvement (RFE), documentation, refactoring, task etc. While logging issue reports into a tracking system, reporters can indicate the category of the reports. Herzig et al. Recently reported that more than 40% of issue reports are given wrong categories in issue tracking systems. Among issue reports that are marked as bugs, more than 30% of them are not bug reports. The misclassification of issue reports can adversely affects developers as they then need to manually identify the categories of various issue reports. To address this problem, in this paper we propose an automated technique that reclassifies an issue report into an appropriate category. Our approach extracts various feature values from a bug report and predicts if a bug report needs to be reclassified and its reclassified category. We have evaluated our approach to reclassify more than 7,000 bug reports from HTTP Client, Jackrabbit, Lucene-Java, Rhino, and Tomcat 5 into 1 out of 13 categories. Our experiments show that we can achieve a weighted precision, recall, and F1 (F-measure) score in the ranges of 0.58-0.71, 0.61-0.72, and 0.57-0.71 respectively. In terms of F1, which is the harmonic mean of precision and recall, our approach can substantially outperform several baselines by 28.88%-416.66%.;incluído;
2016/06/14 23:56:52;Kochhar:2014:PBB:2642937.2642997;POTENTIAL BIASES IN BUG LOCALIZATION: DO THEY MATTER?;2014;Issue tracking systems are valuable resources during software maintenance activities and contain information about the issues faced during the development of a project as well as after its release. Many projects receive many reports of bugs and it is challenging for developers to manually debug and fix them. To mitigate this problem, past studies have proposed information retrieval (IR)-based bug localization techniques, which takes as input a textual description of a bug stored in an issue tracking system, and returns a list of potentially buggy source code files.These studies often evaluate their effectiveness on issue reports marked as bugs in issue tracking systems, using as ground truth the set of files that are modified in commits that fix each bug. However, there are a number of potential biases that can impact the validity of the results reported in these studies. First, issue reports marked as bugs might not be reports of bugs due to error in the reporting and classification process. Many issue reports are about documentation update, request for improvement, refactoring, code cleanups, etc. Second, bug reports might already explicitly specify the buggy program files and for these reports bug localization techniques are not needed. Third, files that get modified in commits that fix the bugs might not contain the bug. This study investigates the extent these potential biases affect the results of a bug localization technique and whether bug localization researchers need to consider these potential biases when evaluating their solutions. In this paper, we analyse issue reports from three different projects: HTTPClient, Jackrabbit, and Lucene-Java to examine the impact of above three biases on bug localization. Our results show that one of these biases significantly and substantially impacts bug localization results, while the other two biases have negligible or minor impact.;incluído;
2016/06/14 23:56:52;Koopaei:2015:CAD:2886444.2886474;CRASHAUTOMATA: AN APPROACH FOR THE DETECTION OF DUPLICATE CRASH REPORTS BASED ON GENERALIZABLE AUTOMATA;2015;"Crash reporting systems are useful tools that allow users to report system failures, subsequently contacting the appropriate support group for resolution. As a software system grows and becomes more versatile, the number of crashes increases. A large software company receives typically thousands of crashes a day, which make it difficult for software engineers to address these reports in a timely manner. Fortunately, not all reports are new; many of them are duplicates of previously reported crashes. Research has shown that early detection of duplicate reports can reduce the effort and time it takes to handle crash reports. In this paper, we propose a new approach for detecting duplicate crash reports, called CrashAutomata. CrashAutomata builds a model from historical crash reports (more precisely their stack traces) that is used to classify an incoming report. The model is based on varied-length n-grams and automata. Unlike existing techniques, CrashAutomata takes advantage of the generalization aspect of automata, making it possible to build a representative model of crash reports, reducing the number of false positives. When applied to crash reports of the Firefox system, CrashAutomata results in very high precision and recall. It also outperforms CrashGraph, a leading technique in the detection of duplicate crash reports.";incluído;
2016/06/14 23:56:52;Koponen:2006:EFO:1193212.1193822;EVALUATION FRAMEWORK FOR OPEN SOURCE SOFTWARE MAINTENANCE;2006;Open Source Software is becoming evermore important and widespread these days, so its maintenance has become important issue. In this paper, we presented an evaluation framework for Open Source Software maintenance. The framework was evaluated with five well known case studies. The results showed that our framework was suitable for evaluating scale of the project and activity, efficiency, traceability and quickness of the defect management and maintenance processes. The case studies showed that quality of the defect reports was low and therefore many of them were ignored as duplicate or invalid. In addition, most of the software changes were not connected to defects, which may express lack of management.;Removido;
2016/06/14 23:56:52;Kshirsagar:2015:ITS:2818567.2818575;ISSUE TRACKING SYSTEM WITH DUPLICATE ISSUE DETECTION;2015;Software quality is very important. There are many software development organizations of different sizes. Quality Assurance System (QAS) is a software application that is designed to help testing team and software developers to keep track of whatever the bugs present in the work. It is also called as Bug Tracking System/Issue tracking system (ITS).Complete and proper information in the bug report helps developers to quickly and easily solve the bug. Analysis of the existing ITS is done to find out limitations. Numbers of ITS are focusing only on large organizations. Small organizations where single resource may have many role and constantly changing number of resources per project. Implemented system is focusing on small as well as big organizations. Implemented system tries to find out facilities which are absent in existing systems and adding feature as duplicate issue detection effectively and calculate developers performance. The system is able to store all the details of project starting phase to its completion. In the system, total time required to complete the given task is calculated so that it is able to find out software developers performance or track duration required to complete any project. As employees performance is calculated through the system, employee can easily find out where he/she lags behind. So that employee can improve their performance to get appraisal. Ultimately, it helps to increase productivity, reduce downtime. To get appraisal, employee can work efficiently, the project get completed within a given time. So, it will definitely increase client satisfaction;Incluído;
2016/06/14 23:56:52;Kulkarni2014;SORTINGHAT: A FRAMEWORK FOR DEEP MATCHING BETWEEN CLASSES OF ENTITIES;2014;This paper addresses the problem of “deep matching” - or matching different classes of entities based on latent underlying semantics, rather than just their visible attributes. An example of this is the “automatic task assignment” problem where several tasks have to be assigned to people with varied skill-sets and experiences. Datasets showing types of entities (tasks and people) along with their involvement of other concepts, are used as the basis for deep matching. This paper describes a work in progress, of a deep matching application called SortingHat. We analyze issue tracking data of a large corporation containing task descriptions and assignments to people that were computed manually. We identify several entities and concepts from the dataset and build a co-occurrence graph as the basic data structure for computing deep matches. We then propose a set of query primitives that can establish several forms of semantic matching across different classes of entities.;Removido;
2016/06/14 23:56:52;Lal2012;COMPARISON OF SEVEN BUG REPORT TYPES: A CASE-STUDY OF GOOGLE CHROME BROWSER PROJECT;2012;Bug reports submitted to an issue tracking system can belong to different categories such as crash, regression, security, cleanup, polish, performance and usability. A deeper understanding of the properties and features of various categories of bug reports can have implications in improving software maintenance processes, tools and practices. We identify several metrics and characteristics serving as dimensions on which various types of bug reports can be compared. We perform a case-study on Google Chromium Browser open-source project and conduct a series of experiments to calculate various metrics. We present a characterization study comparing different types of bug reports on metrics such as: statistics on close-time, number of stars, number of comments, discriminatory and frequent words for each class, entropy across reporters, entropy across component, opening and closing trend, continuity and debugging efficiency performance characteristics. The calculated metrics shows the similarities and differences on various dimensions for seven different types of bug reports.;Removido;
2016/06/14 23:56:52;Liu2005;USING ISSUE TRACKING TOOLS TO FACILITATE STUDENT LEARNING OF COMMUNICATION SKILLS IN SOFTWARE ENGINEERING COURSES;2005;When teaching communication and teamwork skills in software engineering courses, it is often difficult to relate the theories of communication as presented in communication textbooks to actual student interactions and team activities because the majority of student interactions and team activities take place outside the classroom. Through our experience in teaching communication theories in CS456/556, a software engineering course at Ohio University, we observed that when communication theories are delivered in traditional methods such as lectures without additional exercises designed for students to apply the theories, many students tend to treat them as an independent part of the course and continue to guide their behaviors in team activities with their old habits and preexisting intuitions. We found that issue tracking tools can help facilitate student learning of communication skills by forcing students to explicitly carry out effective steps recommended by communication theories and thus improve communications among students. Moreover, issue tracking tools also improve communications between the students and the instructor, and enable the instructor to be more aware of team status, detect team problems early on, and reply less on time-consuming and often inaccurate in-class team status reports;Removido;
2016/06/14 23:56:52;Liu2014;FACETED BUG REPORT SEARCH WITH TOPIC MODEL;2014;During bug reporting, The same bugs could be repeatedly reported. As a result, extra time could be spent on bug triaging and fixing. In order to reduce redundant effort, it is important to provide bug reporters with the ability to search for previously reported bugs efficiently and accurately. The existing bug tracking systems are using relatively simple ranking functions, which often produce unsatisfactory results. In this paper, we apply Ranking SVM, a Learning to Rank technique to construct a ranking model for accurate bug report search. Based on the search results, a topic model is used to cluster the bug reports into multiple facets. Each facet contains similar bug reports of the same topic. Users and testers can locate relevant bugs more efficiently through a simple query. We perform evaluations on more than 16,340 Eclipse and Mozilla bug reports. The evaluation results show that the proposed approach can achieve better search results than the existing search functions.;Incluído;
2016/06/14 23:56:52;Liu:2012:TBR:2393596.2393628;HAS THIS BUG BEEN REPORTED?;2012;Bug reporting is essentially an uncoordinated process. The same bugs could be repeatedly reported because users or testers are unaware of previously reported bugs. As a result, extra time could be spent on bug triaging and fixing. In order to reduce redundant effort, it is important to provide bug reporters with the ability to search for previously reported bugs. The search functions provided by the existing bug tracking systems are using relatively simple ranking functions, which often produce unsatisfactory results. In this paper, we adopt Ranking SVM, a Learning to Rank technique to construct a ranking model for effective bug report search. We also propose to use the knowledge of Wikipedia to discover the semantic relations among words and documents. Given a user query, the constructed ranking model can search for relevant bug reports in a bug tracking system. Unlike related works on duplicate bug report detection, our approach retrieves existing bug reports based on short user queries, before the complete bug report is submitted. We perform evaluations on more than 16,340 Eclipse and Mozilla bug reports. The evaluation results show that the proposed approach can achieve better search results than the existing search functions provided by Bugzilla and Lucene. We believe our work can help users and testers locate potential relevant bug reports more precisely.;Incluído;
2016/06/14 23:56:52;Lotufo2012;TOWARDS IMPROVING BUG TRACKING SYSTEMS WITH GAME MECHANISMS;2012;Low bug report quality and human conflicts pose challenges to keep bug tracking systems productive. This work proposes to address these issues by applying game mechanisms to bug tracking systems. We investigate the use of game mechanisms in Stack Overflow, an online community organized to resolve computer programming related problems, for which the improvements we seek for bug tracking systems also turn out to be relevant. The results of our Stack Overflow investigation show that its game mechanisms could be used to address these issues by motivating contributors to increase contribution frequency and quality, by filtering useful contributions, and by creating an agile and dependable moderation system. We proceed by mapping these mechanisms to open-source bug tracking systems, and find that most benefits are applicable. Additionally, our results motivate tailoring a reward and reputation system and summarizing bug reports as future directions for increasing the benefits of game mechanisms in bug tracking systems. © 2012 IEEE.;Incluído;
2016/06/14 23:56:52;Zhou2015;WHO WILL STAY IN THE FLOSS COMMUNITY? MODELING PARTICIPANT INITIAL BEHAVIOR;2015;Motivation: To survive and succeed, FLOSS projects need contributors able to accomplish critical project tasks. However, such tasks require extensive project experience of long term contributors (LTCs). Aim: We measure, understand, and predict how the newcomers' involvement and environment in the issue tracking system (ITS) affect their odds of becoming an LTC. Method: ITS data of Mozilla and Gnome, literature, interviews, and online documents were used to design measures of involvement and environment. A logistic regression model was used to explain and predict contributor's odds of becoming an LTC. We also reproduced the results on new data provided by Mozilla. Results: We constructed nine measures of involvement and environment based on events recorded in an ITS. Macro-climate is the overall project environment while micro-climate is person-specific and varies among the participants. Newcomers who are able to get at least one issue reported in the first month to be fixed, doubled their odds of becoming an LTC. The macro-climate with high project popularity and the micro-climate with low attention from peers reduced the odds. The precision of LTC prediction was 38 times higher than for a random predictor. We were able to reproduce the results with new Mozilla data without losing the significance or predictive power of the previously published model. We encountered unexpected changes in some attributes and suggest ways to make analysis of ITS data more reproducible. Conclusions: The findings suggest the importance of initial behaviors and experiences of new participants and outline empirically-based approaches to help the communities with the recruitment of contributors for long-term participation and to help the participants contribute more effectively. To facilitate the reproduction of the study and of the proposed measures in other contexts, we provide the data we retrieved and the scripts we wrote at https://www.passion-lab.org/projects/developerfluency.html.;Removido;
2016/06/14 23:56:52;Malheiros2012;A SOURCE CODE RECOMMENDER SYSTEM TO SUPPORT NEWCOMERS;2012;Newcomers in a software development project often need assistance to complete their first tasks. Then a mentor, an experienced member of the team, usually teaches the newcomers what they need to complete their tasks. But, to allocate an experienced member of a team to teach a newcomer during a long time is neither always possible nor desirable, because the mentor could be more helpful doing more important tasks. During the development the team interacts with a version control system, bug tracking and mailing lists, and all these tools record data creating the project memory. Recommender systems can use the project memory to help newcomers in some tasks answering their questions, thus in some cases the developers do not need a mentor. In this paper we present Mentor, a recommender system to help newcomers to solve change requests. Mentor uses the Prediction by Partial Matching (PPM) algorithm and some heuristics to analyze the change requests, and the version control data, and recommend potentially relevant source code that will help the developer in the change request solution. We did three experiments to compare the PPM algorithm with the Latent Semantic Indexing (LSI). Using PPM we achieved results for recall rate between 37% and 66.8%, and using LSI the results were between 20.3% and 51.6%.;Incluído;
2016/06/14 23:56:52;Mani:2012:AAU:2393596.2393607;AUSUM: APPROACH FOR UNSUPERVISED BUG REPORT SUMMARIZATION;2012;In most software projects, resolved bugs are archived for future reference. These bug reports contain valuable information on the reported problem, investigation and resolution. When bug triaging, developers look for how similar problems were resolved in the past. Search over bug repository gives the developer a set of recommended bugs to look into. However, the developer still needs to manually peruse the contents of the recommended bugs which might vary in size from a couple of lines to thousands. Automatic summarization of bug reports is one way to reduce the amount of data a developer might need to go through. Prior work has presented learning based approaches for bug summarization. These approaches have the disadvantage of requiring large training set and being biased towards the data on which the model was learnt. In fact, maximum efficacy was reported when the model was trained and tested on bug reports from the same project. In this paper, we present the results of applying four unsupervised summarization techniques for bug summarization. Industrial bug reports typically contain a large amount of noise---email dump, chat transcripts, core-dump---useless sentences from the perspective of summarization. These derail the unsupervised approaches, which are optimized to work on more well-formed documents. We present an approach for noise reduction, which helps to improve the precision of summarization over the base technique (4% to 24% across subjects and base techniques). Importantly, by applying noise reduction, two of the unsupervised techniques became scalable for large sized bug reports;Incluído;
2016/06/14 23:56:52;Mani:2013:BRC:2487085.2487124;BUG RESOLUTION CATALYSTS: IDENTIFYING ESSENTIAL NON-COMMITTERS FROM BUG REPOSITORIES;2013;"Bugs are inevitable in software projects. Resolving bugs is the primary activity in software maintenance. Developers, who fix bugs through code changes, are naturally important participants in bug resolution. However, there are other participants in these projects who do not perform any code commits. They can be reporters reporting bugs; people having a deep technical know-how of the software and providing valuable insights on how to solve the bug; bug-tossers who re-assign the bugs to the right set of developers. Even though all of them act on the bugs by tossing and commenting, not all of them may be crucial for bug resolution. In this paper, we formally define essential non-committers and try to identify these bug resolution catalysts. We empirically study 98304 bug reports across 11 open source and 5 commercial software projects for validating the existence of such catalysts. We propose a network analysis based approach to construct a Minimal Essential Graph that identifies such people in a project. Finally, we suggest ways of leveraging this information for bug triaging and bug report summarization";Incluído;
2016/06/14 23:56:52;Masmoudi2013;A CASE STUDY FOR UNDERSTANDING THE ORGANIZATION OF DISTRIBUTED PROBLEM-SOLVING WITHIN THE MOZILLA'S COMMUNITY: POSTER PAPER;2013;There is a little understanding of distributed solving activities in Open Source communities. This study aimed to provide some insights in this way. It was applied to the context of Bugzilla, the bug tracking system of Mozilla community. This study investigated the organizational aspects of this meditated, complex and highly distributed context through a linguistic analysis method. The main finding of this research shows that the organization of distributed problem-solving activities in Bugzilla isn't based only on the hierarchical distribution of the work between core and periphery participants but on their implication in the interactions. This implication varies according to the status of each one participant in the community. That is why we distinguish their roles, as well as, the established modes to manage such activity.;Removido;
2016/06/14 23:56:52;Masmoudi2013a;THE ORGANIZATION OF DISTRIBUTED PROBLEM-SOLVING NETWORKS: EXAMINING HOW CORE AND PERIPHERY INTERACT TOGETHER TO SOLVE PROBLEMS IN MOZILLA'S COMMUNITY;2013;The emerging empirical literature on Open Source communities indicates that a majority of code writing and communication activity is concentrated with a few contributors, the “core” (maintainers). However, these communities allow and encourage participation from anybody, the “periphery”. The focus of this work is on explaining how distributed communities solve software problems through the participation of a large number of participants. In particular, this paper investigates interaction, collaboration and division of labor between the core and periphery in a distributed problem-solving activity. Using a linguistic method of analysis, we study bugs that affected Firefox Internet browser as reflected in the discussions and actions reported in Bugzilla (the Mozilla's bug tracking system). As results, we find various categories in the modes of interaction between the core and periphery participants of the community and suggest that interactions are influenced by their status.;Removido;
2016/06/14 23:56:52;Matsumoto2012;DESIGN OF DEVELOPMENT AS A SERVICE IN THE CLOUD;2012;SaaS (Software as a Service) is software that provides the necessary service only when actually required. On the other hand, PaaS (Platform as a Service) is a platform where integrated software development is executed using the networked environment. SaaS for developers is supported by version control systems or forums. However, these services do not support deployment. Therefore, users need to use other services (like PaaS). We propose a development environment service, in which development and deployment are integrated. In this paper, we propose a development and deployment service in the Educational Cloud. The integrated system is referred to as Development as a Service (DEVaaS), which describes the system. This system currently supports a bug tracking system, continuous integration system, version control system, several well-known programming languages, an editor, and deployment environments in the cloud.;Removido;
2016/06/14 23:56:52;Matsushita2005;COXR: OPEN SOURCE DEVELOPMENT HISTORY SEARCH SYSTEM;2005;In typical open source software development, developers use revision control systems for product management, mailing list systems for human communications, and bug tracking systems for process management. All of these systems store development histories of the products that show significant information of problems during the development. However, it would be a hard job to retrieve useful information related to a current problem faced by developers. In this paper, we describe a software development supporting system CoxR that is capable of crawling the development histories. CoxR creates software development information Web which consists of developers, emails, and program deltas, and provides an interface to search, navigate, browse, and retrieve past development results. Through a case study, we confirmed that CoxR helps developers to solve their problems by making it easier to search development history.;Removido;
2016/06/14 23:56:52;Mausa2014;SOFTWARE DEFECT PREDICTION WITH BUG-CODE ANALYZER - A DATA COLLECTION TOOL DEMO;2014;Empirical software engineering research community aims to accumulate knowledge in software engineering community based on the empirical studies on datasets obtained from the real software projects. Limiting factor to building the theory over thus accumulated knowledge is often related to dataset bias. One solution to this problem is developing a systematic data collection procedure through standard guidelines that would be available to open community and thus enable reducing data collection bias. In this paper we present a tool demonstration that implements a systematic data collection procedure for software defect prediction datasets from the open source bug tracking and the source code management repositories. Main challenging issue that the tool addresses is linking the information related to the same entity (e.g. class file) from these two sources. The tool implements interfaces to bug and source code repositories and even other tools for calculating the software metrics. Finally, it offers the user to create software defect prediction datasets even if he is unaware of all the details behind this complex task.;Removido;
2016/06/14 23:56:52;McLaughlin2004;AUTOMATED BUG TRACKING: THE PROMISE AND THE PITFALLS;2004;"Bug tacking systems give developers a unique and clear view into user's everyday product experiences. Adding some statistical analysis and software teams can efficiently improve product quality. It's hard to tell precisely how well the error reporting system working, but this seems to be a bug weapon that has landed a permanent spot in microsoft's arsenal. Automated bug tracking, combined with statistical reporting, plays a key role for developers at the Mozilla Foundations, best known for its open source Web browser and email software. The sparse, random sampling approach produces enough data for the team to do what it call \""statistical debugging\""-bug detection through statistical analysis.";Incluído;
2016/06/14 23:56:52;Menzies2008;AUTOMATED SEVERITY ASSESSMENT OF SOFTWARE DEFECT REPORTS;2008;In mission critical systems, such as those developed by NASA, it is very important that the test engineers properly recognize the severity of each issue they identify during testing. Proper severity assessment is essential for appropriate resource allocation and planning for fixing activities and additional testing. Severity assessment is strongly influenced by the experience of the test engineers and by the time they spend on each issue. The paper presents a new and automated method named SEVERIS (severity issue assessment), which assists the test engineer in assigning severity levels to defect reports. SEVERIS is based on standard text mining and machine learning techniques applied to existing sets of defect reports. A case study on using SEVERIS with data from NASApsilas Project and Issue Tracking System (PITS) is presented in the paper. The case study results indicate that SEVERIS is a good predictor for issue severity levels, while it is easy to use and efficient.;Incluído;
2016/06/14 23:56:52;Murgia2014;DO DEVELOPERS FEEL EMOTIONS? AN EXPLORATORY ANALYSIS OF EMOTIONS IN SOFTWARE ARTIFACTS;2014;Software development is a collaborative activity in which developers interact to create and maintain a complex software system. Human collaboration inevitably evokes emotions like joy or sadness, which can affect the collaboration either positively or negatively, yet not much is known about the individual emotions and their role for software development stakeholders. In this study, we analyze whether development artifacts like issue reports carry any emotional information about software development. This is a first step towards verifying the feasibility of an automatic tool for emotion mining in software development artifacts: if humans cannot determine any emotion from a software artifact, neither can a tool. Analysis of the Apache Software Foundation issue tracking system shows that developers do express emotions (in particular gratitude, joy and sadness). However, the more context is provided about an issue report, the more human raters start to doubt and nuance their interpretation of emotions. More investigation is needed before building a fully automatic emotion mining tool. Copyright is held by the author/owner(s). Publication rights licensed to ACM.;Removido;
2016/06/14 23:56:52;Merten2012;USING RE KNOWLEDGE TO ASSIST AUTOMATICALLY DURING REQUIREMENT SPECIFICATION;2012;In a two semester software engineering (SE) course at Bonn-Rhine-Sieg University students have the opportunity to actually elicit, analyze and document requirements as well as design and develop a correspondent software product in teams of approximately four. The students have to use an issue tracking software in combination with a Requirements Engineering (RE) tool to document and plan their work. Though the course starts with RE theory from elicitation via documentation and traceability, we found that the students find it difficult to combine different RE artifact types and to develop useful traces between them. In this paper we present an approach to provide feedback and give pro-active advice inside an RE tool, while the specification is created. To derive this feedback we use a knowledge base containing rules and best practices to create a requirements specification. An assistance system applies these rules to guide the user in different situations, beginning with an empty specification up to the implementation of various RE artifact types and traces between them. This paper presents the status of our knowledge-based feedback mechanism and possible extensions. In order to get primary indicators for the value of this approach we did experiments and workshops with eight students who worked with the same tool with and without the feedback system.;Removido;
2016/06/14 23:56:52;Michail2005;HELPING USERS AVOID BUGS IN GUI APPLICATIONS;2005;"In this paper, we propose a method to help users avoid bugs in GUI applications. In particular, users would use the application normally and report bugs that they encounter to prevent anyone - including themselves - from encountering those bugs again. When a user attempts an action that has led to problems in the past, he/she will receive a warning and will be given the opportunity to abort the action thus avoiding the bug altogether and keeping the application stable. Of course, bugs should be fixed eventually by the application developers, but our approach allows application users to collaboratively help each other avoid bugs - thus making the application more usable in the meantime. We demonstrate this approach using our \""Stabilizer\"" prototype. We also include a preliminary evaluation of the Stabilizer's bug prediction. Copyright 2005 ACM.";Removido;
2016/06/14 23:56:52;Mittal:2014:PMS:2591062.2591152;PROCESS MINING SOFTWARE REPOSITORIES FROM STUDENT PROJECTS IN AN UNDERGRADUATE SOFTWARE ENGINEERING COURSE;2014;An undergraduate level Software Engineering courses generally consists of a team-based semester long project and emphasizes on both technical and managerial skills. Software Engineering is a practice-oriented and applied discipline and hence there is an emphasis on hands-on development, process, usage of tools in addition to theory and basic concepts. We present an approach for mining the process data (process mining) from software repositories archiving data generated as a result of constructing software by student teams in an educational setting. We present an application of mining three software repositories: team wiki (used during requirement engineering), version control system (development and maintenance) and issue tracking system (corrective and adaptive maintenance) in the context of an undergraduate Software Engineering course. We propose visualizations, metrics and algorithms to provide an insight into practices and procedures followed during various phases of a software development life-cycle. The proposed visualizations and metrics (learning analytics) provide a multi-faceted view to the instructor serving as a feedback tool on development process and quality by students. We mine the event logs produced by software repositories and derive insights such as degree of individual contributions in a team, quality of commit messages, intensity and consistency of commit activities, bug fixing process trend and quality, component and developer entropy, process compliance and verification. We present our empirical analysis on a software repository dataset consisting of 19 teams of 5 members each and discuss challenges, limitations and recommendation;Removido;
2016/06/14 23:56:52;Moran:2015:EAA:2786805.2807557;ENHANCING ANDROID APPLICATION BUG REPORTING;2015;The modern software development landscape has seen a shift in focus toward mobile applications as smartphones and tablets near ubiquitous adoption. Due to this trend, the complexity of these “apps” has been increasing, making development and maintenance challenging. Current bug tracking systems do not effectively facilitate the creation of bug reports with useful information that will directly lead to a bug’s resolution. To address the need for an improved reporting system, we introduce a novel solution, called Fusion, that helps reporters auto-complete reproduction steps in bug reports for mobile apps by taking advantage of their GUI-centric nature. Fusion links information, that reporters provide, to program artifacts extracted through static and dynamic analysis performed beforehand. This allows our system to facilitate the reporting process for developers and testers, while generating more reproducible bug reports with immediately actionable information.;incluído;
2016/06/14 23:56:52;Moran:2015:ABR:2786805.2786857;AUTO-COMPLETING BUG REPORTS FOR ANDROID APPLICATIONS;2015;The modern software development landscape has seen a shift in focus toward mobile applications as tablets and smartphones near ubiquitous adoption. Due to this trend, the complexity of these “apps” has been increasing, making development and maintenance challenging. Additionally, current bug tracking systems are not able to effectively support construction of reports with actionable information that directly lead to a bug’s resolution. To address the need for an improved reporting system, we introduce a novel solution, called FUSION, that helps users auto-complete reproduction steps in bug reports for mobile apps. FUSION links user-provided information to program artifacts extracted through static and dynamic analysis performed before testing or release. The approach that FUSION employs is generalizable to other current mobile software platforms, and constitutes a new method by which off-device bug reporting can be conducted for mobile software projects. In a study involving 28 participants we applied FUSION to support the maintenance tasks of reporting and reproducing defects from 15 real-world bugs found in 14 open source Android apps while qualitatively and qualitatively measuring the user experience of the system. Our results demonstrate that FUSION both effectively facilitates reporting and allows for more reliable reproduction of bugs from reports compared to traditional issue tracking systems by presenting more detailed contextual app information. ;incluído;
2016/06/14 23:56:52;Morariu2013;MULTI-LAYER QOS MONITORING IN PRIVATE CLOUDS;2013;Cloud computing represents at this point the standard delivery method for the infrastructure and platform of next generation applications. The emergence of a wide range of commercial cloud services have changed not only the way code is written and maintained, but also the way it is executed. Private clouds play an important role in this new service delivery model being designed to provide computing capacity within the organization premises either standalone or in a hybrid model. As resources of the private cloud are limited, QoS assurance becomes an important challenge. This paper presents the design of a monitoring solution that integrates several open source tools and can assure QoS for private clouds. The solution is implemented for IBM CloudBurst 2.1 and IBM TSAM product stack and can monitor a wide range of services, from CPU and memory load to J2EE services and HTTP statistics generate real time alerts and provide integration with a Jira based issue tracking tools. The overall solution provides a closed loop QoS system for private clouds that is able to prevent a large set of issues and provide real time diagnostic data for root cause analysis.;Removido;
2016/06/14 23:56:52;Romo:2015:TAT:2745802.2745833;TOWARDS AN AUTOMATION OF THE TRACEABILITY OF BUGS FROM DEVELOPMENT LOGS: A STUDY BASED ON OPEN SOURCE SOFTWARE;2015;Context: Information and tracking of defects can be severely incomplete in almost every Open Source project, resulting in a reduced traceability of defects into the development logs (i.e., version control commit logs). In particular, defect data often appears not in sync when considering what developers logged as their actions. Synchronizing or completing the missing data of the bug repositories, with the logs detailing the actions of developers, would benefit various branches of empirical software engineering research: prediction of software faults, software reliability, traceability, software quality, effort and cost estimation, bug prediction and bug fixing.Objective: To design a framework that automates the process of synchronizing and filling the gaps of the development logs and bug issue data for open source software projects.Method: We instantiate the framework with a sample of OSS projects from GitHub, and by parsing, linking and filling the gaps found in their bug issue data, and development logs. UML diagrams show the relevant modules that will be used to merge, link and connect the bug issue data with the development data.Results: Analysing a sample of over 300 OSS projects we observed that around 1/2 of bug-related data is present in either development logs or issue tracker logs: the rest of the data is missing from one or the other source. We designed an automated approach that fills the gaps of either source by making use of the available data, and we successfully mapped all the missing data of the analysed projects, when using one heuristics of annotating bugs. Other heuristics need to be investigated and implemented.Conclusion: In this paper a framework to synchronise the development logs and bug data used in empirical software engineering was designed to automatically fill the missing parts of development logs and bugs of issue data.;Incluído;
2016/06/14 23:56:52;Naguib2013;BUG REPORT ASSIGNEE RECOMMENDATION USING ACTIVITY PROFILES;2013;One question which frequently arises within the context of artifacts stored in a bug tracking repository is: “who should work on this bug report?” A number of approaches exist to semi-automatically identify and recommend developers, e.g. using machine learning techniques and social networking analysis. In this work, we propose a new approach for assignee recommendation leveraging user activities in a bug tracking repository. Within the bug tracking repository, an activity profile is created for each user from the history of all his activities (i.e. review, assign, and resolve). This profile, to some extent, indicates the user's role, expertise, and involvement in this project. These activities influence and contribute to the identification and ranking of suitable assignees. In order to evaluate our work, we apply it to bug reports of three different projects. Our results indicate that the proposed approach is able to achieve an average hit ratio of 88%. Comparing this result to the LDA-SVM - based assignee recommendation technique, it was found that the proposed approach performs better.;Incluído;
2016/06/14 23:56:52;Nagwani2012;PREDICTING EXPERT DEVELOPERS FOR NEWLY REPORTED BUGS USING FREQUENT TERMS SIMILARITIES OF BUG ATTRIBUTES;2012;A software bug repository not only contains the data about software bugs, but also contains the information about the contribution of developers, quality engineers (testers), managers and other team members. It contains the information about the efforts of team members involved in resolving the software bugs. This information can be analyzed to identify some useful knowledge patterns. One such pattern is identifying the developers, who can help in resolving the newly reported software bugs. In this paper a new algorithm is proposed to discover experts for resolving the newly assigned software bugs. The purpose of proposed algorithm is two fold. First is to identify the appropriate developers for newly reported bugs. And second is to find the expertise for newly reported bugs that can help other developers to fix these bugs if required. All the important information in software bug reports is of textual data types like bug summary, description etc. The algorithm is designed using the analysis of this textual information. Frequent terms are generated from this textual information and then term similarity is used to identify appropriate experts (developers) for the newly reported software bug.;Incluído;
2016/06/14 23:56:52;Nagwani2010;PREDICTIVE DATA MINING MODEL FOR SOFTWARE BUG ESTIMATION USING AVERAGE WEIGHTED SIMILARITY;2010;Software bug estimation is a very essential activity for effective and proper software project planning. All the software bug related data are kept in software bug repositories. Software bug (defect) repositories contains lot of useful information related to the development of a project. Data mining techniques can be applied on these repositories to discover useful interesting patterns. In this paper a prediction data mining technique is proposed to predict the software bug estimation from a software bug repository. A two step prediction model is proposed In the first step bug for which estimation is required, its summary and description is matched against the summary and description of bugs available in bug repositories. A weighted similarity model is suggested to match the summary and description for a pair of software bugs. In the second step the fix duration of all the similar bugs are calculated and stored and its average is calculated, which indicates the predicted estimation of a bug. The proposed model is implemented using open source technologies and is explained with the help of illustrative example.;Incluído;
2016/06/14 23:56:52;Nagwani2013;GENERATING TAXONOMIC TERMS FOR SOFTWARE BUG CLASSIFICATION BY UTILIZING TOPIC MODELS BASED ON LATENT DIRICHLET ALLOCATION;2013;Discovering categorical (taxonomic) terms in text classification is an important and complex problem. Development of a good text classifier depends on the method of identification and generation of proper taxonomic terms. Software bug indicates improper behavior of the functionalities given during the requirements. These bugs are tracked with the help of bug tracking systems (BTS) where the bug information is presented using several attributes out of which some important attributes are textual for example summary and description. For effective classification of the software bugs a good text classifying mechanism is required for which proper taxonomic terms are required to be identified. In this work a methodology is presented to find the taxonomic terms using Latent Dirichlet Allocation (LDA) for software bug classification.;Incluído;
2016/06/14 23:56:52;Nayrolles2016;BUMPER: A TOOL FOR COPING WITH NATURAL LANGUAGE SEARCHES OF MILLIONS OF BUGS AND FIXES;2016;In recent years, mining bug report (BR) repositories has perhaps been one of the most active software engineering research fields. There exist many open source bug tracking and version control systems thatdevelopers and researchers can use to examine bug reports so as to reasonabout software quality. The issue is that these repositories use different interfaces and ways toaccess and represent data, which hinders productivity and reuse. To address this, we introduce BUMPER (BUg Metarepository for dEvelopersand Researchers), a common infrastructure for developers and researchersinterested in mining data from many (heterogeneous) repositories. BUMPER is an open source web-based environment that extracts informationfrom a variety of BR repositories and version control systems. It is equipped with a powerful search engine to help users rapidly querythe repositories using a single point of access. To demonstrate the effectiveness of BUMPER, we use it to build a largedataset from a variety of repositories. The dataset contains more thanone million bug reports and fixes. Both BUMPER and the dataset are publiclyavailable at https://bumper-app.com.;Removido;
2016/06/14 23:56:52;Nguyen:2012:MAR:2393596.2393671;MULTI-LAYERED APPROACH FOR RECOVERING LINKS BETWEEN BUG REPORTS AND FIXES;2012;The links between the bug reports in an issue-tracking system and the corresponding fixing changes in a version repository are not often recorded by developers. Such linking information is crucial for research in mining software repositories in measuring software defects and maintenance efforts. However, the state-of-the-art bug-to-fix link recovery approaches still rely much on textual matching between bug reports and commit/change logs and cannot handle well the cases where their contents are not textually similar.This paper introduces MLink, a multi-layered approach that takes into account not only textual features but also source code features of the changed code corresponding to the commit logs. It is also capable of learning the association relations between the terms in bug reports and the names of entities/components in the changed source code of the commits from the established bug-to-fix links, and uses them for link recovery between the reports and commits that do not share much similar texts. Our empirical evaluation on real-world projects shows that MLink can improve the state-of-the-art bug-to-fix link recovery methods by 11--18%, 13--17%, and 8--17% in F-score, recall, and precision, respectively.;Incluído;
2016/06/14 23:56:52;Nguyen2010;A CASE STUDY OF BIAS IN BUG-FIX DATASETS;2010;Software quality researchers build software quality models by recovering traceability links between bug reports in issue tracking repositories and source code files. However, all too often the data stored in issue tracking repositories is not explicitly tagged or linked to source code. Researchers have to resort to heuristics to tag the data (e.g., to determine if an issue is a bug report or a work item), or to link a piece of code to a particular issue or bug. Recent studies by Bird et al. and by Antoniol et al. suggest that software models based on imperfect datasets with missing links to the code and incorrect tagging of issues, exhibit biases that compromise the validity and generality of the quality models built on top of the datasets. In this study, we verify the effects of such biases for a commercial project that enforces strict development guidelines and rules on the quality of the data in its issue tracking repository. Our results show that even in such a perfect setting, with a near-ideal dataset, biases do exist - leading us to conjecture that biases are more likely a symptom of the underlying software development process instead of being due to the used heuristics.;Removido;
2016/06/14 23:56:52;Romo:2014:FGD:2641580.2641592;FILLING THE GAPS OF DEVELOPMENT LOGS AND BUG ISSUE DATA;2014;It has been suggested that the data from bug repositories is not always in sync or complete compared to the logs detailing the actions of developers on source code.;Incluído;
2016/06/14 23:56:52;OcarizaJr.2013;AN EMPIRICAL STUDY OF CLIENT-SIDE JAVASCRIPT BUGS;2013;"In this paper, we trace two sources of information relative to software bugs: the change logs of the actions of developers and the issues reported as bugs. The aim is to identify and quantify the discrepancies between the two sources in recording and storing the developer logs relative to bugs.Focussing on the databases produced by two mining software repository tools, CVSAnalY and Bicho, we use part of the SZZ algorithm to identify bugs and to compare how the ""defects-fixing changes"" are recorded in the two databases. We use a working example to show how to do so.The results indicate that there is a significant amount of information, not in sync when tracing bugs in the two databases. We, therefore, propose an automatic approach to re-align the two databases, so that the collected information is mirrored and in sync.";Removido;
2016/06/14 23:56:53;Ortu2015;THE JIRA REPOSITORY DATASET: UNDERSTANDING SOCIAL ASPECTS OF SOFTWARE DEVELOPMENT;2015;"Issue tracking systems store valuable data for testing hypotheses concerning maintenance, building statistical prediction models and recently investigating developers \""affectiveness\"". In particular, the Jira Issue Tracking System is a proprietary tracking system that has gained a tremendous popularity in the last years and offers unique features like the project management system and the Jira agile kanban board. This paper presents a dataset extracted from the Jira ITS of four popular open source ecosystems (as well as the tools and infrastructure used for extraction) the Apache Software Foundation, Spring, JBoss and CodeHaus communities. Our dataset hosts more than 1K projects, containing more than 700K issue reports and more than 2 million issue comments. Using this data, we have been able to deeply study the communication process among developers, and how this aspect affects the development process. Further-more, comments posted by developers contain not only technical information, but also valuable information about sentiments and emotions. Since sentiment analysis and human aspects in software engineering are gaining more and more importance in the last years, with this repository we would like to encourage further studies in this direction. © 2015 ACM.";Removido;
2016/06/14 23:56:53;Otoom2016;SEVERITY PREDICTION OF SOFTWARE BUGS;2016;We target the problem of identifying the severity of a bug report. Our main aim is to develop an intelligent system that is capable of predicting the severity of a newly submitted bug report through a bug tracking system. For this purpose, we build a dataset consisting of 59 features characterizing 163 instances that belong to two classes: severe and non-severe. We combine the proposed feature set with strong classification algorithms to assist in predicting the severity of bugs. Moreover, the proposed algorithms are integrated within a boosting algorithm for an enhanced performance. Our results show that the proposed technique has proved successful with a classification performance accuracy of more than 76% with the AdaBoost algorithm and cross validation test. Moreover, boosting has been effective in enhancing the performance of its base classifiers with improvements of up to 4.9%.;Incluído;
2016/06/14 23:56:53;Prifti2011;DETECTING BUG DUPLICATE REPORTS THROUGH LOCAL REFERENCES;2011;Background: Bug Tracking Repositories, such as Bugzilla, are designed to support fault reporting for developers, testers and users of the system. Allowing anyone to contribute finding and reporting faults has an immediate impact on software quality. However, this benefit comes with at least one side-effect. Users often file reports that describe the same fault. This increases the maintainer's triage time, but important information required to fix the fault is likely contributed by different reports. Aim: The objective of this paper is twofold. First, we want to understand the dynamics of bug report filing for a large, long duration open source project, Firefox. Second, we present a new approach that can reduce the number of duplicate reports. Method: The novel element in the proposed approach is the ability to concentrate the search for duplicates on specific portions of the bug repository. Our system can be deployed as a search tool to help reporters query the repository. Results: When tested as a search tool our system is able to detect up to 53% of duplicate reports. Conclusion: The performance of Information Retrieval techniques can be significantly improved by guiding the search for duplicates. This approach results in higher detection rates and constant classification runtime. Copyright © 2011 ACM.;Incluído;
2016/06/14 23:56:53;Thung:2014:BIT:2635868.2661678;BUGLOCALIZER: INTEGRATED TOOL SUPPORT FOR BUG LOCALIZATION;2014;To manage bugs that appear in a software, developers often make use of a bug tracking system such as Bugzilla. Users can report bugs that they encounter in such a system. Whenever a user reports a new bug report, developers need to read the summary and description of the bug report and manually locate the buggy files based on this information. This manual process is often time consuming and tedious. Thus, a number of past studies have proposed bug localization techniques to automatically recover potentially buggy files from bug reports. Unfortunately, none of these techniques are integrated to bug tracking systems and thus it hinders their adoption by practitioners. To help disseminate research in bug localization to practitioners, we develop a tool named BugLocalizer, which is implemented as a Bugzilla extension and builds upon a recently proposed bug localization technique. Our tool extracts texts from summary and description fields of a bug report and source code files. It then computes similarities of the bug report with source code files to find the buggy files. Developers can use our tool online from a Bugzilla web interface by providing a link to a git source code repository and specifying the version of the repository to be analyzed. We have released our tool publicly in GitHub, which is available at: https://github.com/smagsmu/buglocalizer. We have also provided a demo video, which can be accessed at: http://youtu.be/iWHaLNCUjBY. ;Incluído;
2016/06/14 23:56:53;Rastogi:2013:SMI:2442754.2442757;SAMIKSHA: MINING ISSUE TRACKING SYSTEM FOR CONTRIBUTION AND PERFORMANCE ASSESSMENT;2013;Individual contribution and performance assessment is a standard practice conducted in organizations to measure the value addition by various contributors. Accurate measurement of individual contributions based on pre-defined objectives, roles and Key Performance Indicators (KPIs) is a challenging task. In this paper, we propose a contribution and performance assessment framework (called as Samiksha) in the context of Software Maintenance. The focus of the study presented in this paper is Software Maintenance Activities (such as bug fixing and feature enhancement) performed by bug reporters, bug triagers, bug fixers, software developers, quality assurance and project managers facilitated by an Issue Tracking System. We present the result of a survey that we conducted to understand practitioner's perspective and experience (specifically on the topic of contribution assessment for software maintenance professionals). We propose several performance metrics covering different aspects (such as number of bugs fixed weighted by priority and quality of bugs reported) and various roles (such as bug reporter and bug fixer). We conduct a series of experiments on Google Chromium Project data (extracting data from the issue tracker for Google Chromium Project) and present results demonstrating the effectiveness of our proposed framework.;Removido;
2016/06/14 23:56:53;Rastogi2014;WHAT COMMUNITY CONTRIBUTION PATTERN SAYS ABOUT STABILITY OF SOFTWARE PROJECT?;2014;Free/Libre Open Source Software (FLOSS) community management is an important issue. Contributor churn (joining or leaving a project) causes failure of the majority of software projects. In this paper, we present a framework to characterize stability of the community in software maintenance projects by mining Issue Tracking System (ITS). We identify key stability indicators and propose metrics to measure them. We conduct time series analysis on metrics data to examine the stability of the community. We model community participation patterns and forecast future behavior to help plan and support informed decision making. We present a case study of four years data of Google Chromium Project and investigate the inferential ability of the framework.;Removido;
2016/06/14 23:56:53;Rastogi2013;SAMIKSHAUMBRA: CONTRIBUTION AND PERFORMANCE ASSESSMENT OF SOFTWARE MAINTENANCE PROFESSIONALS BY MINING SOFTWARE REPOSITORIES;2013;Contribution and performance assessment is an established practice in organization with its sphere of influence spanning process, policy, people (client) and personnel (employee). Multiple roles in organization (for e.g. employees, project manager, hr manager etc.) view contribution and performance assessment with different perspectives and objectives. However, despite its ability to ensure growth and affluence of organization existing contribution and performance assessment practices are marred with flaws and imperfections. The objective of this work is to serve wide-ranged requirements of software maintenance professionals (in context of contribution and performance assessment) in organization by application of variegated approaches (tools, techniques, models etc.) on software repositories (Issue Tracking System, Version Control System, Source Code Repositories etc.). We study pain-points of practitioners (in context of contribution and performance assessment) and present solution approach by mining software repositories. We implement the approach on real-world data and gather insights from practitioners to validate and improve our research. In this paper, 'SamikshaUmbra' (research umbrella that circumscribe related research threads) we present approach to meet stated research objectives and viable research directions.;Removido;
2016/06/14 23:56:53;Romano2011;AN APPROACH FOR SEARCH BASED TESTING OF NULL POINTER EXCEPTIONS;2011;Uncaught exceptions, and in particular null pointer exceptions (NPEs), constitute a major cause of crashes for software systems. Although tools for the static identification of potential NPEs exist, there is need for proper approaches able to identify system execution scenarios causing NPEs. This paper proposes a search-based test data generation approach aimed at automatically identify NPEs. The approach consists of two steps: (i) an inter-procedural data and control flow analysis - relying on existing technology - that identifies paths between input parameters and potential NPEs, and (ii) a genetic algorithm that evolves a population of test data with the aim of covering such paths. The algorithm is able to deal with complex inputs containing arbitrary data structures. The approach has been evaluated on to test class clusters from six Java open source systems, where NPE bugs have been artificially introduced. Results show that the approach is, indeed, able to identify the NPE bugs, and it outperforms random testing. Also, we show how the approach is able to identify real NPE bugs some of which are posted in the bug-tracking system of the Apache libraries.;Removido;
2016/06/14 23:56:53;Saha2015;ARE THESE BUGS REALLY 'NORMAL'?;2015;Understanding the severity of reported bugs is important in both research and practice. In particular, a number of recently proposed mining-based software engineering techniques predict bug severity, bug report quality, and bug-fix time, according to this information. Many bug tracking systems provide a field 'severity' offering options such as 'severe', 'normal', and 'minor', with 'normal' as the default. However, there is a widespread perception that for many bug reports the label 'normal' may not reflect the actual severity, because reporters may overlook setting the severity or may not feel confident enough to do so. In many cases, researchers ignore 'normal' bug reports, and thus overlook a large percentage of the reports provided. On the other hand, treating them all together risks mixing reports that have very diverse properties. In this study, we investigate the extent to which 'normal' bug reports actually have the 'normal' severity. We find that many 'normal' bug reports in practice are not normal. Furthermore, this misclassification can have a significant impact on the accuracy of mining-based tools and studies that rely on bug report severity information. © 2015 IEEE.;Incluído;
2016/06/15 23:04:34;Saha:2015:UTF:2791609.2792085;UNDERSTANDING THE TRIAGING AND FIXING PROCESSES OF LONG LIVED BUGS;2015;Context:Bug fixing is an integral part of software development and maintenance. A large number of bugs often indicate poor software quality, since buggy behavior not only causes failures that may be costly but also has a detrimental effect on the user’s overall experience with the software product. The impact of long lived bugs can be even more critical since experiencing the same bug version after version can be particularly frustrating for user. While there are many studies that investigate factors affecting bug fixing time for entire bug repositories, to the best of our knowledge, none of these studies investigates the extent and reasons of long lived bugs.Objective:In this paper, we investigate the triaging and fixing processes of long lived bugs so that we can identify the reasons for delay and improve the overall bug fixing process.Methodology:We mine the bug repositories of popular open source projects, and analyze long lived bugs from five different perspectives: their proportion, severity, assignment, reasons, as well as the nature of fixes.Results:Our study on seven open-source projects shows that there are a considerable number of long lived bugs in each system and over 90% of them adversely affect the user’s experience. The reasons for these long lived bugs are diverse including long assignment time, not understanding their importance in advance, etc. However, many bug-fixes were delayed without any specific reasons. Furthermore, 40% of long lived bugs need only small fixes.Conclusion:Our overall results suggest that a significant number of long lived bugs may be minimized through careful triaging and prioritization if developers could predict their severity, change effort, and change impact in advance. We believe our results will help both developers and researchers better to understand factors behind delays, improve the overall bug fixing process, and investigate analytical approaches for prioritizing bugs based on bug severity as well as expected bug fixing effort.;incluído;
2016/06/15 23:04:34;Sassc2013;A CLOSER LOOK AT BUGS;2013;The evolution of non-trivial software systems is accompanied by unexpected behaviour and side-effects, referred as bugs or defects. These defects are reported to and stored in bug tracking systems, which contain descriptions of the problems that have been encountered. However, bug tracking systems store and present bug reports in textual form, which makes their understanding dispersive and unintuitive. We present an approach to display bug reports through a web-based visual analytics platform, named in*Bug. in*Bug allows users to navigate and inspect the vast information space created by bug tracking systems, with the goal of easing the comprehension of bug reports in detail and also obtain an understanding “in the large” of how bugs are reported with respect to one system or to an entire software ecosystem.;Incluído;
2016/06/15 23:04:34;Sasso:2014:MSD:2705615.2706091;MANAGING SOFTWARE DEFECTS;2014;Developers use bug tracking systems to manage the defects that arise during software development. Those systems allow the users to submit reports that describe the failure and the possible causes that led to the error. Bug trackers have evolved and adapted their interfaces to guide the user through the submission of relevant information. However, despite the refinement of the interfaces and improvements, such as the gathering of metadata describing the runtime context, the description of a defect is still composed of plain text. This representation allows flexibility in describing a defect, but the information included in the report is hard to extract and interpret, thus representing an ineffective and unintuitive method to precisely describe a problem. Our work aims to improve the workflow of developers in dealing with bug reports. This begins with promoting a bug report -- often considered as a side effect of the development process -- to independent entity with specific properties that can be exploited to describe and understand a system. We believe that, by automating the steps that lead to the creation of a bug report, we can generate meaningful information that can be automatically elaborated to produce insightful views on the failure environment, like interactive visualizations or linking with artifacts produced during development, and aid the interpretation of a bug report. Finally, we want to integrate the reporting process with elements from game design theory, to stimulate interaction between developers and people in the community and create fruitful cooperation in software ecosystems.;Incluído;
2016/06/15 23:04:34;Sasso2014;IN * BUG: VISUAL ANALYTICS OF BUG REPOSITORIES;2014;Bug tracking systems are used to track and store the defects reported during the life of software projects. The underlying repositories represent a valuable source of information used for example for defect prediction and program comprehension. However, bug tracking systems present the actual bugs essentially in textual form, which is not only cumbersome to navigate, but also hinders the understanding of the intricate pieces of information that revolve around software bugs. We present in*Bug, a web-based visual analytics platform to navigate and inspect bug repositories. in*Bug provides several interactive views to understand detailed information about the bugs and the people that report them. The tool can be downloaded at http://inbug.inf.usi.ch;Incluído;
2016/06/15 23:04:34;Serrano2005;BUGZILLA, ITRACKER, AND OTHER BUG TRACKERS;2005;Bug-tracking helps the software developers in knowing what the error is, resolving it, and learning from it. Working on a software project includes managing the bugs we find. At first, we might list them on a spreadsheet. But when the number of bugs becomes too large and a lot of people must access and input data on them, we have to give up the spreadsheet and instead use a bug- or issue-tracking system. Many software projects reach this point, especially during testing and deployment when users tend to find an application's bugs. Nowadays we can choose among dozens of bug-tracking systems. This paper looks at two specific open source products and provides useful hints for working with any bug-tracking tool.;incluído para Revisão em Pares;
2016/06/15 23:04:34;Shokripour2012;AUTOMATIC BUG ASSIGNMENT USING INFORMATION EXTRACTION METHODS;2012;The number of reported bugs in large open source projects is high and triaging these bugs is an important issue in software maintenance. As a step in the bug triaging process, assigning a new bug to the most appropriate developer to fix it, is not only a time-consuming and tedious task. The triager, the person who considers a bug and assigns it to a developer, also needs to be aware of developer activities at different parts of the project. It is clear that only a few developers have this ability to carry out this step of bug triaging. The main goal of this paper is to suggest a new approach to the process of performing automatic bug assignment. The information needed to select the best developers to fix a new bug report is extracted from the version control repository of the project. Unlike all the previous suggested approaches which used Machine Learning and Information Retrieval methods, this research employs the Information Extraction (IE) methods to extract the information from the software repositories. The proposed approach does not use the information of the bug repository to make decisions about bugs in order to obtain better results on projects which do not have many fixed bugs. The aim of this research is to recommend the actual fixers of the bugs. Using this approach, we achieved 62%, 43% and 41% accuracies on Eclipse, Mozilla and Gnome projects, respectively.;Incluído;
2016/06/15 23:04:34;Singh2011;BUG TRACKING AND RELIABILITY ASSESSMENT SYSTEM (BTRAS);2011;Tracking of a reported bug for fixing is a fascinating area of research in software engineering. Many open source, free and commercial bug tracking tools have been developed and are currently under development. The industry needs criteria to select the best tool among the available set of tools that will help in fixing and tracking the progress of bug fixes. In this paper, we use BugZilla, Jira, Trac, Mantis, BugTracker.Net, Gnats and Fossil for comparative study. We present a comprehensive classification criteria to review the available tools and propose a new tool named Bug Tracking and Reliability Assessment System (BTRAS) for the bug tracking/reporting and reliability assessment. BTRAS helps in reporting the bug, assigning the bug to the developer for fixing, monitoring the progress of bug fixing by various graphical/charting facility and status updates, providing reliability bug prediction and bug complexity measurements, and distributing fixes to users/developers.;Incluído;
2016/06/15 23:04:34;Singh2010;MEASURING RELIABILITY GROWTH OF OPEN SOURCE SOFTWARE BY APPLYING STOCHASTIC DIFFERENTIAL EQUATIONS;2010;This, paper presents (i) several software reliability, growth models (SRGM) which tries to predict, quantitatively the failure, phenomena, in, an, Open, Source, Software, project over a period of time. Here, it is assumed that the number of failures during testing is dependent upon the number of instructions execution, (ii) in order to cater the, irregular state, of, bug-report, phenomena, on, the, bug tracking system and irregular fluctuation in terms of noise, the reliability models have been proposed by applying an Itô type Stochastic Differential Equations (SDE). We have demonstrated that proposed models can support management in building reliable software systems by predicting remaining bugs. We have also compared our proposed models with several existing models on the basis of different comparison criteria.;Removido;
2016/06/15 23:04:34;Somasundaram:2012:ACB:2134254.2134276;AUTOMATIC CATEGORIZATION OF BUG REPORTS USING LATENT DIRICHLET ALLOCATION;2012;Software developers, particularly in open-source projects, rely on bug repositories to organize their work. On a bug report, the component field is used to indicate to which team of developers a bug should be routed. Researchers have shown that incorrect categorization of newly received bug reports to components can cause potential delays in the resolution of bug reports. Approaches have been developed that consider the use of machine learning approaches, specifically Support Vector Machines (svm), to automatically categorize bug reports into the appropriate component to help streamline the process of solving a bug. One drawback of an SVM-based approach is that the results of categorization can be uneven across various components in the system if some components receive less reports than others. In this paper, we consider broadening the consistency of the recommendations produced by an automatic approach by investigating three approaches to automating bug report categorization: an approach similar to previous ones based on an SVM classifier and Term Frequency Inverse Document Frequency(svm-tf-idf), an approach using Latent Dirichlet Allocation (LDA) with SVM (svm-lda) and an approach using LDA and Kullback Leibler divergence (lda-kl). We found that lda-kl produced recalls similar to those found previously but with better consistency across all components for which bugs must be categorized.;Incluído;
2016/06/15 23:04:34;Song2010a;JDF: DETECTING DUPLICATE BUG REPORTS IN JAZZ;2010;Both developers and users submit bug reports to a bug repository. These reports can help reveal defects and improve software quality. As the number of bug reports in a bug repository increases, the number of the potential duplicate bug reports increases. Detecting duplicate bug reports helps reduce development efforts in fixing defects. However, it is challenging to manually detect all potential duplicates because of the large number of existing bug reports. This paper presents JDF (representing Jazz Duplicate Finder), a tool that helps users to find potential duplicates of bug reports on Jazz, which is a team collaboration platform for software development and process management. JDF finds potential duplicates for a given bug report using natural language and execution information. © 2010 ACM.;Incluído;
2016/06/15 23:04:34;Vahabzadeh2015;AN EMPIRICAL STUDY OF BUGS IN TEST CODE;2015;"Testing aims at detecting (regression) bugs in production code. However, testing code is just as likely to contain bugs as the code it tests. Buggy test cases can silently miss bugs in the production code or loudly ring false alarms when the production code is correct. We present the first empirical study of bugs in test code to characterize their prevalence and root cause categories. We mine the bug repositories and version control systems of 211 Apache Software Foundation (ASF) projects and find 5,556 test-related bug reports. We (1) compare properties of test bugs with production bugs, such as active time and fixing effort needed, and (2) qualitatively study 443 randomly sampled test bug reports in detail and categorize them based on their impact and root causes. Our results show that (1) around half of all the projects had bugs in their test code; (2) the majority of test bugs are false alarms, i.e., test fails while the production code is correct, while a minority of these bugs result in silent horrors, i.e., test passes while the production code is incorrect; (3) incorrect and missing assertions are the dominant root cause of silent horror bugs; (4) semantic (25%), flaky (21%), environment-related (18%) bugs are the dominant root cause categories of false alarms; (5) the majority of false alarm bugs happen in the exercise portion of the tests, and (6) developers contribute more actively to fixing test bugs and test bugs are fixed sooner compared to production bugs. In addition, we evaluate whether existing bug detection tools can detect bugs in test code. © 2015 IEEE.";Removido;
2016/06/15 23:04:34;Squire2014;FORGE++: THE CHANGING LANDSCAPE OF FLOSS DEVELOPMENT;2014;Software forges are centralized online systems that provide useful tools to help distributed development teams work together, especially in free, libre, and open source software (FLOSS). Forge-provided tools may include web space, version control systems, mailing lists and communication forums, bug tracking systems, file downloads, wikis, and the like. Empirical software engineering researchers can mine the artifacts from these tools to better understand how FLOSS is made. As the landscape of distributed software development has grown and changed, the tools needed to make FLOSS have changed as well. There are three newer tools at the center of FLOSS development today: distributed version control based forges (like Github), programmer question-and-answer communities (like Stack Overflow), and paste bin tools (like Gist or Pastebin.com). These tools are extending and changing the toolset used for FLOSS development, and redefining what a software forge looks like. The main contributions of this paper are to describe each of these tools, to identify the data and artifacts available for mining from these tools, and to outline some of the ways researchers can use these artifacts to continue to understand how FLOSS is made.;Removido;
2016/06/15 23:04:34;Stepalin2010;SAAS SUPPORT IN SOFTWARE DOCUMENTATION SYSTEMS;2010;"In recent days more and more software developments tools become distributed by the SaaS (Software-As-A Service) model alongside with ready-to-install products. The developers of task and bug tracking systems now offer their solutions by a monthly fee. For instance, JIRA Studio produced by Atlassian can be connected to a corporative domain by subscription. This scheme allows software companies to reduce costs at the project's start and get scalable resources in future. Software documentation systems can also be purchased by a subscription now. The effectiveness of their usage for various documentation development is interesting. There are four major types of documentation supporting the development process and resulted products: project, technical, code and user documentation. Each of this type claims specific requirements for the documentation tool. The requirement analysis shows that rented documentation systems are the most appropriate for user and technical documentation. There are two major classes of software documentation systems: 1) Wiki, 2) DITA-orientedXML CMS. The following wiki systems have a hosted version: commercial Confluence, Central Desktop, EditMe, Incentive, Netcipia, PBWiki, Wikia, Wikispaces; open source BusinessWiki, Metadot Wiki, MindTouch, Wagn, Wikidot. The richest by the functionality andplugin collection is Confluence produced by Atlassian. The following XML CMS are offered by a SaaS model (all are commercial): Astoria On Demand, DITA Exchange. DocZone. SaaS is optionally supported in Bluestream XDocs, Siberlogic SiberSafe, Trisoft Infoshare, Vasont, X-Hive Docato. As wiki system is a ready integrated environment for creating and publishing documentation, DITA-system consists not only of XML CMS. To deploy a DITA-system, you should have an XML editor, publisher and CMS. The listed CMS can be integrated with top DITA XML editors and provide an API to integrate with other editors. These CMS also have build-in tools to export documents in mu- - ltiple formats. However, the universal component architecture of DITA-systems makes the deployment and configuration more difficult than wiki implementation. Hosted documentation systems are offered by different prices. The offerings of top documentation systems are considered in this paper. Wiki subscription fees range from 4,95$ (EditMe) to 20$ (Confluence) per one user/month. XML CMS subscription price starts from 500$ per month and can reach 12000$ per month. These subscriptions have no fixed price; in each individual case the CMS vendor performs a specific project of a DITA-system implementation. Wiki rental costs approximate to CMS subscriptions' costs for large number of users, 500 and more. The advantages of renting a powerful documentation system for small and large project are the following: 1) Maximal functionality at a low affordable cost, 2) Platform independency and high system accessibility, 3) Document quality improvement at the expense of quality controlling tools application, 4) Higher effectiveness of documentation (content re-use, single source usage, automated tools for localization), 5) Organization of robust and scalable documentation process. As the SaaS business model becomes more popular, small companies get access to powerful software documentation systems, which are too expensive to purchase a standalone license at the startup. However, the system's access security, reliability and information confidentiality issues remain opened and controversial.";Removido;
2016/06/15 23:04:34;Sun2011;TOWARDS MORE ACCURATE RETRIEVAL OF DUPLICATE BUG REPORTS;2011;In a bug tracking system, different testers or users may submit multiple reports on the same bugs, referred to as duplicates, which may cost extra maintenance efforts in triaging and fixing bugs. In order to identify such duplicates accurately, in this paper we propose a retrieval function (REP) to measure the similarity between two bug reports. It fully utilizes the information available in a bug report including not only the similarity of textual content in summary and description fields, but also similarity of non-textual fields such as product, component, version, etc. For more accurate measurement of textual similarity, we extend BM25F - an effective similarity formula in information retrieval community, specially for duplicate report retrieval. Lastly we use a two-round stochastic gradient descent to automatically optimize REP for specific bug repositories in a supervised learning manner. We have validated our technique on three large software bug repositories from Mozilla, Eclipse and OpenOffice. The experiments show 10-27% relative improvement in recall rate@k and 17-23% relative improvement in mean average precision over our previous model. We also applied our technique to a very large dataset consisting of 209,058 reports from Eclipse, resulting in a recall rate@k of 37-71% and mean average precision of 47%.;Incluído;
2016/06/15 23:04:34;Sun:2010:DMA:1806799.1806811;A DISCRIMINATIVE MODEL APPROACH FOR ACCURATE DUPLICATE BUG REPORT RETRIEVAL;2010;" repositories are usually maintained in software projects. Testers or users submit bug reports to identify various issues with systems. Sometimes two or more bug reports correspond to the same defect. To address the problem with duplicate bug reports, a person called a triager needs to manually label these bug reports as duplicates, and link them to their ""master"" reports for subsequent maintenance work. However, in practice there are considerable duplicate bug reports sent daily; requesting triagers to manually label these bugs could be highly time consuming.To address this issue, recently, several techniques have be proposed using various similarity based metrics to detect candidate duplicate bug reports for manual verification. Automating triaging has been proved challenging as two reports of the same bug could be written in various ways. There is still much room for improvement in terms of accuracy of duplicate detection process. In this paper, we leverage recent advances on using discriminative models for information retrieval to detect duplicate bug reports more accurately. We have validated our approach on three large software bug repositories from Firefox, Eclipse, and OpenOffice. We show that our technique could result in 17--31%, 22--26%, and 35--43% relative improvement over state-of-the-art techniques in OpenOffice, Firefox, and Eclipse datasets respectively using commonly available natural language information only.";Incluído;
2016/06/15 23:04:34;Takama2013;APPLICATION OF MONITORING SUPPORT VISUALIZATION TO BUG TRACKING SYSTEMS;2013;This paper proposes to apply information visualization technologies to the support of monitoring bug update information sent from multiple bug tracking systems. Bug update information managed by bug tracking systems (BTS) is one of text stream data, which continuously generates new data. Therefore, it is difficult for users to watch it all the time. In other words, the task of monitoring stream data inevitably involves breaks of the task, which would lose the context of monitoring. However, to the best of our knowledge, interaction design when involving breaks has not been fully studied yet. The proposed system visualizes the dynamic relationship between bugs with animation, and helps a user grasping the context of monitoring by highlighting updated bugs and the replay of animation for part of the last monitoring time. The effectiveness of the system is evaluated through experiments with test participants. Recent growth of the Web has brought us various kinds of text stream data, such as bulletin board systems (BBS), blogs, and social networking services (SNS). As such data is expected to be important resources for human support robots, this paper would contribute to interaction design of such robots.;Incluído;
2016/06/15 23:04:34;Tamura2008;A METHOD OF RELIABILITY ASSESSMENT BASED ON DETERMINISTIC CHAOS THEORY FOR AN OPEN SOURCE SOFTWARE;2008;Open source software which serve as key components of critical infrastructures in the social life are still ever-expanding now. We focus on the quality problems of open source software developed under open source project. In case of considering the effect of the debugging process in the development of a method of reliability assessment for open source project, it is necessary to grasp the deeply-intertwined factors, such as programming path, size of each component, skill of fault reporters, and so on. Considering from a point of view of the software reliability growth model, it is difficult to cover the software fault-report phenomena on the bug tracking system of open source software. We propose a new approach to software reliability assessment based on deterministic chaos theory. Also, we analyze actual software fault count data to show numerical examples of software reliability assessment for the open source software.;Removido;
2016/06/15 23:04:34;Tamura2007;SOFTWARE RELIABILITY GROWTH MODEL BASED ON STOCHASTIC DIFFERENTIAL EQUATIONS FOR OPEN SOURCE SOFTWARE;2007;All over the world people can gain the information at the same time by growing rate of Internet access around the world in recent years. In accordance with such a penetration of the Internet, it is increasing public awareness of the importance of online real-time and interactive functions. Therefore, software development environment has been changing into new development paradigms such as concurrent distributed development environment and the so-called open source project by using network computing technologies. Especially, such OSS (open source software) systems which serve as key components of critical infrastructures in our society are still ever-expanding now. In this paper, we propose a software reliability growth model based on stochastic differential equations in order to consider the active state of the open source project. Especially, we assume that the software failure intensity depends on the time, and the software fault-report phenomena on the bug tracking system keep an irregular state. Also, we analyze actual software fault count data to show numerical examples of software reliability assessment for the OSS. Moreover, we compare our model with the conventional model based on stochastic differential equations in terms of goodness-of-fit for actual data. We show that the proposed model can assist improvement of quality for OSS systems developed under the open source project.;Removido;
2016/06/15 23:04:34;Tappolet2010;SEMANTIC WEB ENABLED SOFTWARE ANALYSIS;2010;One of the most important decisions researchers face when analyzing software systems is the choice of a proper data analysis/exchange format. In this paper, we present EvoOnt, a set of software ontologies and data exchange formats based on OWL. EvoOnt models software design, release history information, and bug-tracking meta-data. Since OWL describes the semantics of the data, EvoOnt (1) is easily extendible, (2) can be processed with many existing tools, and (3) allows to derive assertions through its inherent Description Logic reasoning capabilities. The contribution of this paper is that it introduces a novel software evolution ontology that vastly simplifies typical software evolution analysis tasks. In detail, we show the usefulness of EvoOnt by repeating selected software evolution and analysis experiments from the 2004-2007 Mining Software Repositories Workshops (MSR). We demonstrate that if the data used for analysis were available in EvoOnt then the analyses in 75% of the papers at MSR could be reduced to one or at most two simple queries within off-the-shelf SPARQL tools. In addition, we present how the inherent capabilities of the Semantic Web have the potential of enabling new tasks that have not yet been addressed by software evolution researchers, e.g., due to the complexities of the data integration. © 2010 Elsevier B.V.;Removido;
2016/06/15 23:04:34;Thung2014;DUPFINDER: INTEGRATED TOOL SUPPORT FOR DUPLICATE BUG REPORT DETECTION;2014;To track bugs that appear in a software, developers often make use of a bug tracking system. Users can report bugs that they encounter in such a system. Bug reporting is inherently an uncoordinated distributed process though and thus when a user submits a new bug report, there might be cases when another bug report describing exactly the same problem is already present in the system. Such bug reports are duplicate of each other and these duplicate bug reports need to be identified. A number of past studies have proposed a number of automated approaches to detect duplicate bug reports. However, these approaches are not integrated to existing bug tracking systems. In this paper, we propose a tool named DupFinder, which implements the state-of-theart unsupervised duplicate bug report approach by Runeson et al., as a Bugzilla extension. DupFinder does not require any training data and thus can easily be deployed to any project. DupFinder extracts texts from summary and description fields of a new bug report and recent bug reports present in a bug tracking system, uses vector space model to measure similarity of bug reports, and provides developers with a list of potential duplicate bug reports based on the similarity of these reports with the new bug report. We have released DupFinder as an open source tool in GitHub, which is available at: uhttps://github.com/smagsmu/dupfinder. © 2014 ACM.;Incluído;
2016/06/15 23:04:34;Thung2013;AUTOMATIC RECOVERY OF ROOT CAUSES FROM BUG-FIXING CHANGES;2013;What is the root cause of this failure? This question is often among the first few asked by software debuggers when they try to address issues raised by a bug report. Root cause is the erroneous lines of code that cause a chain of erroneous program states eventually leading to the failure. Bug tracking and source control systems only record the symptoms (e.g., bug reports) and treatments of a bug (e.g., committed changes that fix the bug), but not its root cause. Many treatments contain non-essential changes, which are intermingled with root causes. Reverse engineering the root cause of a bug can help to understand why the bug is introduced and help to detect and prevent other bugs of similar causes. The recovered root causes are also better ground truth for bug detection and localization studies. In this work, we propose a combination of machine learning and code analysis techniques to identify root causes from the changes made to fix bugs. We evaluate the effectiveness of our approach based on a golden set (i.e., ground truth data) of manually recovered root causes of 200 bug reports from three open source projects. Our approach is able to achieve a precision, recall, and F-measure (i.e., the harmonic mean of precision and recall) of 76.42%, 71.88%, and 74.08% respectively. Compared with the work by Kawrykow and Robillard, our approach achieves a 60.83% improvement in F-measure.;Incluído;
2016/06/15 23:04:34;Thung2012;WHEN WOULD THIS BUG GET REPORTED?;2012;"Not all bugs in software would be experienced and reported by end users right away: Some bugs manifest themselves quickly and may be reported by users a few days after they get into the code base; others manifest many months or even years later, and may only be experienced and reported by a small number of users. We refer to the period of time between the time when a bug is introduced into code and the time when it is reported by a user as bug reporting latency. Knowledge of bug reporting latencies has an implication on prioritization of bug fixing activities-bugs with low reporting latencies may be fixed earlier than those with high latencies to shift debugging resources towards bugs highly concerning users. To investigate bug reporting latencies, we analyze bugs from three Java software systems: AspectJ, Rhino, and Lucene. We extract bug reporting data from their version control repositories and bug tracking systems, identify bug locations based on bug fixes, and back-trace bug introducing time based on change histories of the buggy code. Also, we remove non-essential changes, and most importantly, recover root causes of bugs from their treatments/fixes. We then calculate the bug reporting latencies, and find that bugs have diverse reporting latencies. Based on the calculated reporting latencies and features we extract from bugs, we build classification models that can predict whether a bug would be reported early (within 30 days) or later, which may be helpful for prioritizing bug fixing activities. Our evaluation on the three software systems shows that our bug reporting latency prediction models could achieve an AUC (Area Under the Receiving Operating Characteristics Curve) of 70.869%.";Incluído;
2016/06/15 23:04:34;Tian:2013:DPP:2550526.2550574;DRONE: PREDICTING PRIORITY OF REPORTED BUGS BY MULTI-FACTOR ANALYSIS;2013;Bugs are prevalent. To improve software quality, developers often allow users to report bugs that they found using a bug tracking system such as Bugzilla. Users would specify among other things, a description of the bug, the component that is affected by the bug, and the severity of the bug. Based on this information, bug triagers would then assign a priority level to the reported bug. As resources are limited, bug reports would be investigated based on their priority levels. This priority assignment process however is a manual one. Could we do better? In this paper, we propose an automated approach based on machine learning that would recommend a priority level based on information available in bug reports. Our approach considers multiple factors, temporal, textual, author, related-report, severity, and product, that potentially affect the priority level of a bug report. These factors are extracted as features which are then used to train a discriminative model via a new classification algorithm that handles ordinal class labels and imbalanced data. Experiments on more than a hundred thousands bug reports from Eclipse show that we can outperform baseline approaches in terms of average F-measure by a relative improvement of 58.61%.;Incluído;
2016/06/15 23:04:34;Tian:2015:APB:2821954.2821959;AUTOMATED PREDICTION OF BUG REPORT PRIORITY USING MULTI-FACTOR ANALYSIS;2015;Bugs are prevalent. To improve software quality, developers often allow users to report bugs that they found using a bug tracking system such as Bugzilla. Users would specify among other things, a description of the bug, the component that is affected by the bug, and the severity of the bug. Based on this information, bug triagers would then assign a priority level to the reported bug. As resources are limited, bug reports would be investigated based on their priority levels. This priority assignment process however is a manual one. Could we do better? In this paper, we propose an automated approach based on machine learning that would recommend a priority level based on information available in bug reports. Our approach considers multiple factors, temporal, textual, author, related-report, severity, and product, that potentially affect the priority level of a bug report. These factors are extracted as features which are then used to train a discriminative model via a new classification algorithm that handles ordinal class labels and imbalanced data. Experiments on more than a hundred thousands bug reports from Eclipse show that we can outperform baseline approaches in terms of average F-measure by a relative improvement of up to 209 %.;Incluído;
2016/06/15 23:04:34;Tian2012;IMPROVED DUPLICATE BUG REPORT IDENTIFICATION;2012;"Bugs are prevalent in software systems. To improve the reliability of software systems, developers often allow end users to provide feedback on bugs that they encounter. Users could perform this by sending a bug report in a bug report management system like Bugzilla. This process however is uncoordinated and distributed, which means that many users could submit bug reports reporting the same problem. These are referred to as duplicate bug reports. The existence of many duplicate bug reports may cause much unnecessary manual efforts as often a triager would need to manually tag bug reports as being duplicates. Recently, there have been a number of studies that investigate duplicate bug report problem which in effect answer the following question: given a new bug report, retrieve k other similar bug reports. This, however, still requires substantive manual effort which could be reduced further. Jalbert and Weimer are the first to introduce the direct detection of duplicate bug reports; it answers the question: given a new bug report, classify if it as a duplicate bug report or not. In this paper, we extend Jalbert and Weimer's work by improving the accuracy of automated duplicate bug report identification. We experiments with bug reports from Mozilla bug tracking system which were reported between February 2005 to October 2005, and find that we could improve the accuracy of the previous approach by about 160%. © 2012 IEEE.";Incluído;
2016/06/15 23:04:34;ValdiviaGarcia:2014:CPB:2597073.2597099;CHARACTERIZING AND PREDICTING BLOCKING BUGS IN OPEN SOURCE PROJECTS;2014; As software becomes increasingly important, its quality becomes an increasingly important issue. Therefore, prior work focused on software quality and proposed many prediction models to identify the location of software bugs, to estimate their fixing-time, etc. However, one special type of severe bugs is blocking bugs. Blocking bugs are software bugs that prevent other bugs from being fixed. These blocking bugs may increase maintenance costs, reduce overall quality and delay the release of the software systems.In this paper, we study blocking-bugs in six open source projects and propose a model to predict them. Our goal is to help developers identify these blocking bugs early on. We collect the bug reports from the bug tracking systems of the projects, then we obtain 14 different factors related to, for example, the textual description of the bug, the location the bug is found in and the people involved with the bug. Based on these factors we build decision trees for each project to predict whether a bug will be a blocking bug or not. Then, we analyze these decision trees in order to determine which factors best indicate these blocking bugs. Our results show that our prediction models achieve F-measures of 15-42%, which is a two- to four-fold improvement over the baseline random predictors. We also find that the most important factors in determining blocking bugs are the comment text, comment size, the number of developers in the CC list of the bug report and the reporter's experience. Our analysis shows that our models reduce the median time to identify a blocking bug by 3-18 days;Incluído;
2016/06/15 23:04:34;Tomasev2013;EXPLOITING HUBS FOR SELF-ADAPTIVE SECONDARY RE-RANKING IN BUG REPORT DUPLICATE DETECTION;2013;Bug duplicate detection is an integral part of many bug tracking systems. Most bugs are reported multiple times and detecting the duplicates saves time and valuable resources. We propose a novel approach to potential duplicate report query ranking. Our secondary re-ranking procedure is self-adaptive, as it learns from previous report occurrences. It is based on the analysis of temporal evolution of the underlying distribution of influence. The experiments show definite improvements in system performance.;Incluído;
2016/06/15 23:04:34;Tong2015;CHARACTERIZING AND PREDICTING BUG ASSIGNMENT IN OPENSTACK;2015;Open source software is becoming increasingly important in cloud computing. However, many cloud computing systems suffer from software bugs that cause significant dependability issues. Bug assignment and fixing are crucial parts of software maintenance to improve dependability. In this paper, we conduct an empirical study of 42,880 bug reports from OpenStack bug repository. We study the characteristics (e.g., distribution of bugs, distribution of assignees) of bug assignments in OpenStack and find the bug assignment pattern which we call as long tail. The findings can support the follow-up research on improving efficiency of bug assignment, that is, we propose a prediction method based on long tail model, and experimentally evaluate this method by applying it to OpenStack bug assignment.;Incluído;
2016/06/15 23:04:34;Tran2015;FAULT DATA ANALYTICS USING DECISION TREE FOR FAULT DETECTION;2015;Monitoring events on communication and computing systems becomes more and more challenging due to the increasing complexity and diversity of these systems. Several supporting tools have been created to assist system administrators in monitoring an enormous number of events daily. The main function of these tools is to filter as many as possible events and present non-trivial events to the administrators for fault analysis and detection. However, non-trivial events never decrease on large systems, such as cloud computing systems, while investigating events is time consuming. This paper proposes an approach for evaluating the severity level of an event using a classification and regression decision tree. The approach aims to build a decision tree based on the features of old events, then use this tree to decide the severity level of new events. The administrators take advantages of this decision to determine proper actions for the non-trivial events. We have implemented and experimented the approach for software bug datasets obtained from bug tracking systems. The experimental results reveal that the accuracy scores for different decision trees are above 70% and some detailed analyses are provided. © Springer International Publishing Switzerland 2015.;Removido;
2016/06/15 23:04:34;Tu:2014:MQI:2677832.2677844;MEASURING THE QUALITY OF ISSUE TRACKING DATA;2014;Source code and its development history can represent the output and process of developing software. [1] But little attention has been devoted to the data quality. To help researchers and practioners preliminary evaluate the software development data they used in studies, we design a tool, Data Quality Evaluator (DQE), to measure the software development data, especially the data completeness of issue reports in an open source software (OSS) project’s issue tracking system (ITS). It is judged from three metrics -- the coherence of issue reports’ ID, the existence of an issue report’s basic information and activity information, and the completeness of changes on an issue report status. DQE will analyze the data submitted by users, and show users the data quality evaluation chart from three aspects. We had DQE applied to the GNOME community’s issue-tracking data that we collected for research, and we obtained the result of data quality evaluation. Next, we will continue to apply DQE to more software development data, so that we can help researchers and practioners conveniently get an initial evaluation of data quality.;Incluído;
2016/06/15 23:04:34;Zanetti2013;CATEGORIZING BUGS WITH SOCIAL NETWORKS: A CASE STUDY ON FOUR OPEN SOURCE SOFTWARE COMMUNITIES;2013;Efficient bug triaging procedures are an important precondition for successful collaborative software engineering projects. Triaging bugs can become a laborious task particularly in open source software (OSS) projects with a large base of comparably inexperienced part-time contributors. In this paper, we propose an efficient and practical method to identify valid bug reports which a) refer to an actual software bug, b) are not duplicates and c) contain enough information to be processed right away. Our classification is based on nine measures to quantify the social embeddedness of bug reporters in the collaboration network. We demonstrate its applicability in a case study, using a comprehensive data set of more than 700, 000 bug reports obtained from the Bugzilla installation of four major OSS communities, for a period of more than ten years. For those projects that exhibit the lowest fraction of valid bug reports, we find that the bug reporters' position in the collaboration network is a strong indicator for the quality of bug reports. Based on this finding, we develop an automated classification scheme that can easily be integrated into bug tracking platforms and analyze its performance in the considered OSS communities. A support vector machine (SVM) to identify valid bug reports based on the nine measures yields a precision of up to 90.3% with an associated recall of 38.9%. With this, we significantly improve the results obtained in previous case studies for an automated early identification of bugs that are eventually fixed. Furthermore, our study highlights the potential of using quantitative measures of social organization in collaborative software engineering. It also opens a broad perspective for the integration of social awareness in the design of support infrastructures.;Incluído;
2016/06/15 23:04:34;Varvaressos2014;AUTOMATED BUG FINDING IN VIDEO GAMES: A CASE STUDY FOR RUNTIME MONITORING;2014;"Runtime verification is the process of observing a sequence of events generated by a running system and comparing it to some formal specification for potential violations. We show how the use of a runtime monitor can greatly speed up the testing phase of a video game under development, by automating the detection of bugs when the game is being played. We take advantage of the fact that a video game, contrarily to generic software, follows a special structure that contains a \""game loop\"", this game loop can be used to centralize the instrumentation and generate events based on the game's internal state. We report on experiments made on a sample of five real-world video games of various genres and sizes, by successfully incrementing and efficiently monitoring various temporal properties over their execution-including actual bugs reported in the games' bug tracking database in the course of their development.";Removido;
2016/06/15 23:04:34;Vijayakumar2014;HOW MUCH EFFORT NEEDED TO FIX THE BUG? A DATA MINING APPROACH FOR EFFORT ESTIMATION AND ANALYSING OF BUG REPORT ATTRIBUTES IN FIREFOX;2014;Estimating the effort required to fix a bug is a significant task for the project manager to determine the project release. Among various ways to estimate the effort, analysis of bug report attributes proved excellent results. In this paper the effort required to fix the bug on the components of Firefox application is studied. A framework has been charted for analysing the feature attributes which on imparting association rule mining process resulted with dictating rules which provide the effort succumb to fix the bugs of a particular component. The bug reports used for this study are extracted from Bugzilla, an open source bug repository. These bug reports provides a variety of categorical data from previous projects. Analysis of this can improve the planning of personnel to fix the bug and raise the quality of bug reports.;Incluído;
2016/06/15 23:04:34;Vyas:2013:ESM:2525194.2525269;ETHNOGRAPHY OF SOFTWARE MAINTENANCE ACTIVITIES IN AN INDUSTRIAL ENGINEERING SETUP;2013;New technical and procedural interventions are less likely to be adopted in industry, unless they are smoothly integrated into the existing practices of professionals. In this paper, we provide a case study of the use of ethnographic methods for studying software bug-fixing activities at an industrial engineering conglomerate. We aimed at getting an in-depth understanding of software developers' everyday practices in bug-fixing related projects and in turn inform the design of novel productivity tools. The use of ethnography has allowed us to look at the social side of software maintenance practices. In this paper, we highlight 1) organizational issues that influence bug-fixing activities, 2) social role of bug tracking systems, and 3) social issues specific to different phases of bug-fixing activities.;Removido;
2016/06/15 23:04:34;Wang2011;BEHIND LINUS'S LAW: A PRELIMINARY ANALYSIS OF OPEN SOURCE SOFTWARE PEER REVIEW PRACTICES IN MOZILLA AND PYTHON;2011;Open source is an important model of collaborative knowledge work and virtual organizations. One of its work practices, peer review, is considered critical to its success, as Linus's law highlights. Thus, understanding open source peer review, particular effective review practices, will improve the understanding of how to support collaborative work in new ways. Therefore, we conduct case studies in two open source communities that are well recognized as effective and successful, Mozilla and Python. In this paper, we present the preliminary results of our analysis on data from the bug tracking systems of those two organizations. We identify four common activities critical to open source software peer review, submission, identification, resolution and evaluation. Differences between communities indicate factors, such as reporter expertise, product type and structure, and organization size, affect review activities. We also discuss features of open source software peer review distinct from traditional review, as well as reconsiderations of Linus's law.;Removido;
2016/06/15 23:04:34;Wang2011a;WHICH BUG SHOULD I FIX: HELPING NEW DEVELOPERS ONBOARD A NEW PROJECT;2011;A typical entry point for new developers in an open source project is to contribute a bug fix. However, finding an appropriate bug and an appropriate fix for that bug requires a good understanding of the project, which is nontrivial. Here, we extend Tesseract - an interactive project exploration environment - to allow new developers to search over bug descriptions in a project to quickly identify and explore bugs of interest and their related resources. More specifically, we extended Tesseract with search capabilities that enable synonyms and similar-bugs search over bug descriptions in a bug repository. The goal is to enable users to identify bugs of interest, resources related to that bug, (e.g., related files, contributing developers, communication records), and visually explore the appropriate socio-technical dependencies for the selected bug in an interactive manner. Here we present our search extension to Tesseract. © 2011 ACM.;Incluído;
2016/06/15 23:04:34;Wang:2015:CCS:2829386.2829718;COMPARATIVE CASE STUDIES OF OPEN SOURCE SOFTWARE PEER REVIEW PRACTICES;2015;Context: The power of open source software peer review lies in the involvement of virtual communities, especially users who typically do not have a formal role in the development process. As communities grow to a certain extent, how to organize and support the peer review process becomes increasingly challenging. A universal solution is likely to fail for communities with varying characteristics.Objective:This paper investigates differences of peer review practices across different open source software communities, especially the ones engage distinct types of users, in order to offer contextualized guidance for developing open source software projects.Method:Comparative case studies were conducted in two well-established large open source communities, Mozilla and Python, which engage extremely different types of users. Bug reports from their bug tracking systems were examined primarily, complemented by secondary sources such as meeting notes, blog posts, messages from mailing lists, and online documentations.Results:The two communities differ in the key activities of peer review processes, including different characteristics with respect to bug reporting, design decision making, to patch development and review. Their variances also involve the designs of supporting technology. The results highlight the emerging role of triagers, who bridge the core and peripheral contributors and facilitate the peer review process. The two communities demonstrate alternative designs of open source software peer review and their tradeoffs were discussed.Conclusion:It is concluded that contextualized designs of social and technological solutions to open source software peer review practices are important. The two cases can serve as learning resources for open source software projects, or other types of large software projects in general, to cope with challenges of leveraging enormous contributions and coordinating core developers. It is also important to improve support for triagers, who have not received much research effort yet.;Removido;
2016/06/15 23:04:34;Wang:2008:ADD:1368088.1368151;AN APPROACH TO DETECTING DUPLICATE BUG REPORTS USING NATURAL LANGUAGE AND EXECUTION INFORMATION;2008;An open source project typically maintains an open bug repository so that bug reports from all over the world can be gathered. When a new bug report is submitted to the repository, a person, called a triager, examines whether it is a duplicate of an existing bug report. If it is, the triager marks it as DUPLICATE and the bug report is removed from consideration for further work. In the literature, there are approaches exploiting only natural language information to detect duplicate bug reports. In this paper we present a new approach that further involves execution information. In our approach, when a new bug report arrives, its natural language information and execution information are compared with those of the existing bug reports. Then, a small number of existing bug reports are suggested to the triager as the most similar bug reports to the new bug report. Finally, the triager examines the suggested bug reports to determine whether the new bug report duplicates an existing bug report. We calibrated our approach on a subset of the Eclipse bug repository and evaluated our approach on a subset of the Firefox bug repository. The experimental results show that our approach can detect 67%-93% of duplicate bug reports in the Firefox bug repository, compared to 43%-72% using natural language information alone.;Incluído;
2016/06/15 23:04:34;Weiss:2007:LTF:1268983.1269017;HOW LONG WILL IT TAKE TO FIX THIS BUG?;2007;"Predicting the time and effort for a software problem has long been a difficult task. We present an approach that automatically predicts the fixing effort, i.e., the person-hours spent on fixing an issue. Our technique leverages existing issue tracking systems: given a new issue report, we use the Lucene framework to search for similar, earlier reports and use their average time as a prediction. Our approach thus allows for early effort estimation, helping in assigning issues and scheduling stable releases. We evaluated our approach using effort data from the JBoss project. Given a sufficient number of issues reports, our automatic predictions are close to the actual effort; for issues that are bugs, we are off by only one hour, beating na¨ýve predictions by a factor of four.";Incluído;
2016/06/15 23:04:34;White:2015:GRR:2820282.2820291;GENERATING REPRODUCIBLE AND REPLAYABLE BUG REPORTS FROM ANDROID APPLICATION CRASHES;2015;Manually reproducing bugs is time-consuming and tedious. Software maintainers routinely try to reproduce unconfirmed issues using incomplete or no informative bug reports. Consequently, while reproducing an issue, the maintainer must augment the report with information - such as a reliable sequence of descriptive steps to reproduce the bug - to aid developers with diagnosing the issue. This process encumbers issue resolution from the time the bug is entered in the issue tracking system until it is reproduced. This paper presents Crash Droid, an approach for automating the process of reproducing a bug by translating the call stack from a crash report into expressive steps to reproduce the bug and a kernel event trace that can be replayed on-demand. Crash Droid manages trace ability links between scenarios' natural language descriptions, method call traces, and kernel event traces. We evaluated Crash Droid on several open-source Android applications infected with errors. Given call stacks from crash reports, Crash Droid was able to generate expressive steps to reproduce the bugs and automatically replay the crashes. Moreover, users were able to confirm the crashes faster with Crash Droid than manually reproducing the bugs or using a stress-testing tool.;Incluído;
2016/06/15 23:04:34;Wijesiriwardana2012;A GUIDED MASHUP FRAMEWORK FOR RAPID SOFTWARE ANALYSIS SERVICE COMPOSITION;2012;Historical data about software projects is stored in repositories such as version control, bug tracking and mailing lists. Analyzing such data is vital to discover unthought-of-yet-interesting insights of a software project. Even though a wide range of software analysis techniques are already available, integration of such analyses is yet to be systematically addressed. Inspired from the recently introduced concept of Software as a Service, our research group investigated the concept of Software Analysis as a Service (SOFAS), a distributed and collaborative software analysis platform. SOFAS allows software analyses to be accessed, composed into workflows, and executed over the Internet. However, traditional service composition is a complex, time consuming and error-prone process, which requires experts in both composition languages and existing standards. In this paper, we propose a mashup platform to address the problem of software analysis composition in a light-weight, programming-free process-centric way. Our proposed mashup platform provides design-time guidance to the users throughout the mashup design by integrating a continuous feedback mechanism. It requires exploiting semantic web technologies and Software Engineering Ontologies (SEON).;Removido;
2016/06/15 23:04:34;Wong:2014:BBF:2705615.2706096;BOOSTING BUG-REPORT-ORIENTED FAULT LOCALIZATION WITH SEGMENTATION AND STACK-TRACE ANALYSIS;2014;To deal with post-release bugs, many software projects set up public bug repositories for users all over the world to report bugs that they have encountered. Recently, researchers have proposed various information retrieval based approaches to localizing faults based on bug reports. In these approaches, source files are processed as single units, where noise in large files may affect the accuracy of fault localization. Furthermore, bug reports often contain stack-trace information, but existing approaches often treat this information as plain text. In this paper, we propose to use segmentation and stack-trace analysis to improve the performance of bug localization. Specifically, given a bug report, we divide each source code file into a series of segments and use the segment most similar to the bug report to represent the file. We also analyze the bug report to identify possible faulty files in a stack trace and favor these files in our retrieval. According to our empirical results, our approach is able to significantly improve Bug Locator, a representative fault localization approach, on all the three software projects (i.e., Eclipse, AspectJ, and SWT) used in our empirical evaluation. Furthermore, segmentation and stack-trace analysis are complementary to each other for boosting the performance of bug-report-oriented fault localization.;Incluído;
2016/06/15 23:04:34;Wu2011a;BUGMINER: SOFTWARE RELIABILITY ANALYSIS VIA DATA MINING OF BUG REPORTS;2011;Software bugs reported by human users and automatic error reporting software are often stored in some bug tracking tools (e.g., Bugzilia and Debbugs). These accumulated bug reports may contain valuable information that could be used to improve the quality of the bug reporting, reduce the quality assurance effort and cost, analyze software reliability, and predict future bug report trend. In this paper, we present BugMiner, a tool that is able to derive useful information from historic bug report database using data mining, use these information to do completion check and redundancy check on a new or given bug report, and to estimate the bug report trend using statistical analysis. Our empirical studies of the tool using several real-world bug report repositories show that it is effective, easy to implement, and has relatively high accuracy despite low quality data.;Incluído;
2016/06/15 23:04:34;Wu2011;DREX: DEVELOPER RECOMMENDATION WITH K-NEAREST-NEIGHBOR SEARCH AND EXPERTISE RANKING;2011;This paper proposes a new approach called DREX (Developer Recommendation with k-nearest-neighbor search and Expertise ranking) to developer recommendation for bug resolution based on K-Nearest-Neighbor search with bug similarity and expertise ranking with various metrics, including simple frequency and social network metrics. We collect Mozilla Fire fox open bug repository as the experimental data set and compare different ranking metrics on the performance of recommending capable developers for bugs. Our experimental results demonstrate that, when recommending 10 developers for each one of the 250 testing bugs, DREX has produced better performance than traditional methods with multi-labeled text categorization. The best performance obtained by two metrics as Out-Degree and Frequency, is with recall as 0.6 on average. Moreover, other social network metrics such as Degree and Page Rank have produced comparable performance on developer recommendation as Frequency when used for developer expertise ranking.;Incluído;
2016/06/15 23:04:34;Xia:2015:AHA:2737603.2737646;AUTOMATIC, HIGH ACCURACY PREDICTION OF REOPENED BUGS;2015;Bug fixing is one of the most time-consuming and costly activities of the software development life cycle. In general, bugs are reported in a bug tracking system, validated by a triage team, assigned for someone to fix, and finally verified and closed. However, in some cases bugs have to be reopened. Reopened bugs increase software maintenance cost, cause rework for already busy developers and in some cases even delay the future delivery of a software release. Therefore, a few recent studies focused on studying reopened bugs. However, these prior studies did not achieve high performance (in terms of precision and recall), required manual intervention, and used very simplistic techniques when dealing with this textual data, which leads us to believe that further improvements are possible. In this paper, we propose ReopenPredictor, which is an automatic, high accuracy predictor of reopened bugs. ReopenPredictor uses a number of features, including textual features, to achieve high accuracy prediction of reopened bugs. As part of ReopenPredictor, we propose two algorithms that are used to automatically estimate various thresholds to maximize the prediction performance. To examine the benefits of ReopenPredictor, we perform experiments on three large open source projects—namely Eclipse, Apache HTTP and OpenOffice. Our results show that ReopenPredictor outperforms prior work, achieving a reopened F-measure of 0.744, 0.770, and 0.860 for Eclipse, Apache HTTP and OpenOffice, respectively. These results correspond to an improvement in the reopened F-measure of the method proposed in the prior work by Shihab et al. by 33.33, 12.57 and 3.12 % for Eclipse, Apache HTTP and OpenOffice, respectively.;Incluído;
2016/06/15 23:04:34;Xie2013;IMPACT OF TRIAGE: A STUDY OF MOZILLA AND GNOME;2013;Triage is of great interest in software projects because it has the potential to reduce developer effort by involving a broader base of non-developer contributors to filter and augment reported issues. Using issue tracking data and interviews with experienced contributors we investigate ways to quantify the impact of triagers on reducing the number of issues developers need to resolve in two OSS projects: Mozilla and Gnome. We find the primary impact of triagers to involve issue filtering, filling missing information, and determining the relevant product. While triagers were good at filtering invalid issues and as accurate as developers in filling in missing issue attributes, they had more difficulty accurately pinpointing the relevant product. We expect that this work will highlight the importance of issue triage in software projects and will help design further studies on understanding and improving triage practices.;Removido;
2016/06/15 23:04:34;Xuan:2012:DPB:2337223.2337227;DEVELOPER PRIORITIZATION IN BUG REPOSITORIES;2012;Developers build all the software artifacts in development. Existing work has studied the social behavior in software repositories. In one of the most important software repositories, a bug repository, developers create and update bug reports to support software development and maintenance. However, no prior work has considered the priorities of developers in bug repositories. In this paper, we address the problem of the developer prioritization, which aims to rank the contributions of developers. We mainly explore two aspects, namely modeling the developer prioritization in a bug repository and assisting predictive tasks with our model. First, we model how to assign the priorities of developers based on a social network technique. Three problems are investigated, including the developer rankings in products, the evolution over time, and the tolerance of noisy comments. Second, we consider leveraging the developer prioritization to improve three predicted tasks in bug repositories, i.e., bug triage, severity identification, and reopened bug prediction. We empirically investigate the performance of our model and its applications in bug repositories of Eclipse and Mozilla. The results indicate that the developer prioritization can provide the knowledge of developer priorities to assist software tasks, especially the task of bug triage;Incluído;
2016/06/15 23:04:34;Yu2012;PRACTICAL ISOLATION OF FAILURE-INDUCING CHANGES FOR DEBUGGING REGRESSION FAULTS;2012;During software evolution, new released versions still contain many bugs. One common scenario is that end users encounter regression faults and submit them to bug tracking systems. Different from in-house regression testing, typically only one test input is available, which passes the old version and fails the modified new version. To address the issue, delta debugging has been proposed for failure-inducing changes identification between two versions. Despite promising results, there are two practical factors that thwart the application of delta debugging: a large number of tests and misleading false positives. In this work, we present a combination of coverage analysis and delta debugging that automatically isolates failure-inducing changes. Evaluations on twelve real regression faults in GNU software demonstrate both the speed gain and effectiveness improvements. Moreover, a case study on libPNG and TCPflow indicates that our technique is comparable to peer techniques in debugging regressions faults.;Removido;
2016/06/15 23:04:34;Zanetti2013a;THE RISE AND FALL OF A CENTRAL CONTRIBUTOR: DYNAMICS OF SOCIAL ORGANIZATION AND PERFORMANCE IN THE GENTOO COMMUNITY;2013;Social organization and division of labor crucially influence the performance of collaborative software engineering efforts. In this paper, we provide a quantitative analysis of the relation between social organization and performance in Gentoo, an Open Source community developing a Linux distribution. We study the structure and dynamics of collaborations as recorded in the project's bug tracking system over a period of ten years. We identify a period of increasing centralization after which most interactions in the community were mediated by a single central contributor. In this period of maximum centralization, the central contributor unexpectedly left the project, thus posing a significant challenge for the community. We quantify how the rise, the activity as well as the subsequent sudden dropout of this central contributor affected both the social organization and the bug handling performance of the Gentoo community. We analyze social organization from the perspective of network theory and augment our quantitative findings by interviews with prominent members of the Gentoo community which shared their personal insights.;Removido;
2016/06/15 23:04:34;Zhang2014a;A NOVEL TECHNIQUE FOR DUPLICATE DETECTION AND CLASSIFICATION OF BUG REPORTS;2014;"Software products are increasingly complex, so it is becoming more difficult to find and correct bugs in large programs. Software developers rely on bug reports to fix bugs; thus, bug-tracking tools have been introduced to allow developers to upload, manage, and comment on bug reports to guide corrective software maintenance. However, the very high frequency of duplicate bug reports means that the triagers who help software developers in eliminating bugs must allocate large amounts of time and effort to the identification and analysis of these bug reports. In addition, classifying bug reports can help triagers arrange bugs in categories for the fixers who have more experience for resolving historical bugs in the same category. Unfortunately, due to a large number of submitted bug reports every day, the manual classification for these bug reports increases the triagers' workload. To resolve these problems, in this study, we develop a novel technique for automatic duplicate detection and classification of bug reports, which reduces the time and effort consumed by triagers for bug fixing. Our novel technique uses a support vector machine to check whether a new bug report is a duplicate. The concept profile is also used to classify the bug reports into related categories in a taxonomic tree. Finally, we conduct experiments that demonstrate the feasibility of our proposed approach using bug reports extracted from the large-scale open source project Mozilla. Copyright © 2014 The Institute of Electronics, Information and Communication Engineers.";Removido;
2016/06/15 23:04:34;Zhang:2011:BRB:2055440.2055904;A BUG RULE BASED TECHNIQUE WITH FEEDBACK FOR CLASSIFYING BUG REPORTS;2011;As software programs become increasingly large and complex, it is more important to improve the quality of software maintenance. Many software programs rely on bug reports to correct errors in maintenance activities. Bug tracking systems were developed to guide maintenance activities of software developers. However, due to the excessive number of duplicate bug reports, developers spend much time to identify these bug reports. In this study, in order to save developers' time in software maintenance, we propose a bug rule based classification technique to categorize bug reports. By utilizing developer feedback mechanism in the technique, it distinguishes duplicate and valid bug reports and is expected to improve the accuracy of bug reports retrieval. Finally, we show the feasibility of this technique in experiment and case study;Incluído;
2016/06/15 23:04:34;Zhang2014;BUTTER: AN APPROACH TO BUG TRIAGE WITH TOPIC MODELING AND HETEROGENEOUS NETWORK ANALYSIS;2014;When a bug is reported to the bug tracking system, it should be assigned to a developer responsible for its resolution after it is verified. This processing is also called bug triage. With increasing number of bug reports submitted to the bug tracking system, it is more and more difficult to assign appropriate developers to all the reported bugs manually. In this paper, we propose an approach called BUTTER (BUg Triage by topic modeling and heTERogeneous network analysis) to automatically assign bugs to developers. Different from other work, we regard that in most cases, bug resolution is a collaborative activity which involves many developers' participation. Although social network analysis has been introduced to characterize the collaboration of developers, networks constructed by researchers are usually homogenous. That is, all the nodes and links in these networks are regarded as having same properties. Considering developers collaborated on different bugs, we construct a heterogeneous network that includes relationships between submitters, bugs and developers to characterize developers' collaboration. Experiment shows that BUTTER outperforms other methods on automated bug triage.;Incluído;
2016/06/15 23:04:34;Zhang:2016:KSA:2873074.2873292;KSAP;2012;N/A;Removido;
2016/06/15 23:04:34;Zhang:2013:HNA:2569431.2569763;HETEROGENEOUS NETWORK ANALYSIS OF DEVELOPER CONTRIBUTION IN BUG REPOSITORIES;2013;Using a bug repository, developers contribute to improve the quality of software incrementally by creating and updating bug reports. All the software artifacts in bug repositories are derived from developer contribution. Most prior studies on developer contribution in bug repositories bias on one particular form, e.g., commenting bug reports. However, in real practice of bug repositories, developers participate in and contribute to software projects via multiple ways, e.g., reporting new bugs, reopening incorrectly fixed bugs, commenting unfixed bug reports, and fixing unsolved bugs. In this paper, we exploit recent advances in analysis of heterogeneous network to avoid biased aspects in measuring developer contribution and explore multiple types of developer contribution in bug repositories. Further, we consider leveraging such multiple types of developer contribution to assist a typical prediction problem in bug repositories, i.e., bug triage. Empirical studies on bug repositories of Eclipse and Mozilla show that our approach can provide enriched knowledge of developer contribution to improve the resolution of bug triage. This study strongly suggests using the promising aspects of heterogeneous network can open many actionable insights in analyzing software repositories.;Incluído;
2016/06/15 23:04:34;Zimmermann2009;CHANGES AND BUGS MINING AND PREDICTING DEVELOPMENT ACTIVITIES;2009;Software development results in a huge amount of data: changes to source code are recorded in version archives, bugs are reported to issue tracking systems, and communications are archived in e-mails and newsgroups. We present techniques for mining version archives and bug databases to understand and support software development. First, we introduce the concept of co-addition of method calls, which we use to identify patterns that describe how methods should be called. We use dynamic analysis to validate these patterns and identify violations. The co-addition of method calls can also detect cross-cutting changes, which are an indicator for concerns that could have been realized as aspects in aspect-oriented programming. Second, we present techniques to build models that can successfully predict the most defect-prone parts of large-scale industrial software, in our experiments Windows Server 2003. This helps managers to allocate resources for quality assurance to those parts of a system that are expected to have most defects. The proposed measures on dependency graphs outperformed traditional complexity metrics. In addition, we found empirical evidence for a domino effect, i.e., depending on defect-prone binaries increases the chances of having defects.;Removido;
2016/06/15 23:04:34;Zimmermann2009b;IMPROVING BUG TRACKING SYSTEMS;2009;It is important that information provided in bug reports is relevant and complete in order to help resolve bugs quickly. However, often such information trickles to developers after several iterations of communication between developers and reporters. Poorly designed bug tracking systems are partly to blame for this exchange of information being stretched over time. Our paper addresses the concerns of bug tracking systems by proposing four broad directions for enhancements. As a proof-of-concept, we also demonstrate a prototype interactive bug tracking system that gathers relevant information from the user and identifies files that need to be fixed to resolve the bug. © 2009 IEEE.;Incluído;
2016/06/15 23:04:34;Zou2015;AN EMPIRICAL STUDY OF BUG FIXING RATE;2015;Bug fixing is one of the most important activities in software development and maintenance. A software project often employs an issue tracking system such as Bugzilla to store and manage their bugs. In the issue tracking system, many bugs are invalid but take unnecessary efforts to identify them. In this paper, we mainly focus on bug fixing rate, i.e., The proportion of the fixed bugs in the reported closed bugs. In particular, we study the characteristics of bug fixing rate and investigate the impact of a reporter's different contribution behaviors to the bug fixing rate. We perform an empirical study on all reported bugs of two large open source software communities Eclipse and Mozilla. We find (1) the bug fixing rates of both projects are not high, (2) there exhibits a negative correlation between a reporter's bug fixing rate and the average time cost to close the bugs he/she reports, (3) the amount of bugs a reporter ever fixed has a strong positive impact on his/her bug fixing rate, (4) reporters' bug fixing rates have no big difference, whether their contribution behaviors concentrate on a few products or across many products, (5) reporters' bug fixing rates tend to increase as time goes on, i.e., Developers become more experienced at reporting bugs.;Incluído;
2016/06/15 23:04:34;2015;7TH INTERNATIONAL SYMPOSIUM ON SEARCH-BASED SOFTWARE ENGINEERING, SSBSE 2015;2015;"The proceedings contain 38 papers. The special focus in this conference is on Search-Based Software Engineering. The topics include: Genetic improvement of software for multiple objectives; amortised optimisation of non-functional properties in production environments; metrics are not enough; searching for useful parallelism in functional programs; an improved beam-search for the test case generation for formal verification systems; combining multiple coverage criteria in search-based unit test generation; epistatic genetic algorithm for test case prioritization; a scala combinator toolkit for semi-automated composition of metaheuristics; hypervolume-based search for test case prioritization; optimizing aspect-oriented product line architectures with search-based algorithms; adaptive neighbourhood search for the component deployment problem; transformed search based software engineering; regression test case prioritisation for guava; continuous test generation on guava; generating readable unit tests for guava; testing django configurations using combinatorial interaction testing; synthesis of equivalent method calls in guava; object-oriented genetic improvement for improved energy consumption in google guava; automated transplantation of call graph and layout features into kate; growing django citation services using SBSE; multi-objective module clustering for kate; search based component selection for budget hardware; search-based bug report prioritization for kate editor bugs repository; inferring test models from kate’s bug reports using multi-objective search; introducing learning mechanism for class responsibility assignment problem; transformed vargha-delaney effect size; optimizing software product line architectures with OPLA-tool; exploring the landscape of non-functional program properties using spatial analysis and interactive software release planning with preferences base.";Removido;
2016/06/15 23:04:34;2012;2012 9TH IEEE WORKING CONFERENCE ON MINING SOFTWARE REPOSITORIES, MSR 2012 - PROCEEDINGS;2012;"The proceedings contain 38 papers. The topics discussed include: towards improving bug tracking systems with game mechanisms; a linked data platform for mining software repositories; how distributed version control systems impact open source software projects; an empirical study of supplementary bug fixes; incorporating version histories in information retrieval based bug localization; think locally, act globally: improving defect and effort prediction models; are faults localizable?; green mining: a methodology of relating software change to power consumption; analysis of customer satisfaction survey data; mining usage data and development artifacts; bug introducing changes: a case study with android; trendy bugs: topic trends in the android bug reports; do the stars align? multidimensional analysis of android's layered architecture; and the build dependency perspective of android's concrete architecture.";Removido;
