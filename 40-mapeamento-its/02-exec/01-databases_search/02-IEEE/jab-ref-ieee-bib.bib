% This file was created with JabRef 2.10.
% Encoding: UTF-8


@Article{7224062,
  Title                    = {Small dim object tracking using a multi objective particle swarm optimisation technique},
  Author                   = {K. Ahmadi and E. Salari},
  Journal                  = {IET Image Processing},
  Year                     = {2015},
  Number                   = {9},
  Pages                    = {820-826},
  Volume                   = {9},

  Abstract                 = {Dim object tracking in a heavy clutter environment is a theoretical and technological challenge in the field of image processing. For a small dim object, conventional tracking methods fail for the lack of geometrical information. Multiple hypotheses testing (MHT) is one of the generally accepted methods in target tracking systems. However, processing a tree structure with a significant number of branches in MHT has been a challenging issue. Tracking high-speed objects with traditional MHT requires some presumptions which limit the capabilities of these methods. This study presents a hierarchal tracking system in two levels to solve this problem. For each point in the lower-level, a multi objective particle swarm optimisation technique is applied to a group of consecutive frames to reduce the number of branches in each tracking tree. Thus, an optimum track for each moving object is obtained in a group of frames. In the upper-level, an iterative process is used to connect the matching optimum tracks of the consecutive frames based on the spatial information and fitness values. The experimental results show that the proposed method has a superior performance in relation to some common dim object tracking methods over different image sequence data sets.},
  Doi                      = {10.1049/iet-ipr.2014.0927},
  ISSN                     = {1751-9659},
  Keywords                 = {clutter;image matching;image sequences;iterative methods;object tracking;particle swarm optimisation;target tracking;MHT;geometrical information;heavy clutter environment;image matching;image processing;image sequence data set;iterative process;multiobjective particle swarm optimisation technique;multiple hypotheses testing;small dim object tracking;target tracking system;tree structure}
}

@InProceedings{6975654,
  Title                    = {Supplementary Bug Fixes vs. Re-opened Bugs},
  Author                   = {L. An and F. Khomh and B. Adams},
  Booktitle                = {Source Code Analysis and Manipulation (SCAM), 2014 IEEE 14th International Working Conference on},
  Year                     = {2014},
  Month                    = {Sept},
  Pages                    = {205-214},

  Abstract                 = {A typical bug fixing cycle involves the reporting of a bug, the triaging of the report, the production and verification of a fix, and the closing of the bug. However, previous work has studied two phenomena where more than one fix are associated with the same bug report. The first one is the case where developers re-open a previously fixed bug in the bug repository (sometimes even multiple times) to provide a new bug fix that replace a previous fix, whereas the second one is the case where multiple commits in the version control system contribute to the same bug report ("supplementary bug fixes"). Even though both phenomena seem related, they have never been studied together, i.e., are supplementary fixes a subset of re-opened bugs or the other way around? This paper investigates the interplay between both phenomena in five open source software projects: Mozilla, Net beans, Eclipse JDT Core, Eclipse Platform SWT, and Web Kit. We found that re-opened bugs account for between 21.6% and 33.8% of all supplementary fixes. However, 33% to 57.5% of re-opened bugs had only one commit associated, which means that the original bug report was prematurely closed instead of fixed incorrectly. Furthermore, we constructed predictive models for re-opened bugs using historical information about supplementary bug fixes with a precision between 72.2% and 97%, as well as a recall between 47.7% and 65.3%. Software researchers and practitioners who are mining data repositories can use our approach to identify potential failures of their bug fixes and the re-opening of bug reports.},
  Doi                      = {10.1109/SCAM.2014.29},
  Keywords                 = {data mining;program debugging;public domain software;Eclipse JDT Core;Eclipse Platform SWT;Mozilla;Netbeans;WebKit;bug fixing cycle;bug report;mining data repositories;open source software projects;reopened bug subset;supplementary fix;version control system;Computer bugs;Control systems;Data mining;History;Open source software;Predictive models;mining software repositories;prediction model;re-opened bugs;supplementary fixes}
}

@InProceedings{4658104,
  Title                    = {Task articulation in software maintenance: Integrating source code annotations with an issue tracking system},
  Author                   = {J. Anvik and M. A. Storey},
  Booktitle                = {Software Maintenance, 2008. ICSM 2008. IEEE International Conference on},
  Year                     = {2008},
  Month                    = {Sept},
  Pages                    = {460-461},

  Abstract                 = {Managing and articulating development tasks is an important aspect of software maintenance. Developers already have a variety of specialty tools to support task management, for example, issue tracking and configuration management software, but they also make use of other tools within their software engineering environments to support software task management. An example of one such mechanism is the appropriation of source code comments to document finer grained details of formally specified tasks. In this research, we propose and present a tool that integrates these source code annotations with an issue tracking management system. We describe how this tool addresses deficiencies that occur in task management and propose future research to improve task management.},
  Doi                      = {10.1109/ICSM.2008.4658104},
  ISSN                     = {1063-6773},
  Keywords                 = {groupware;software engineering;configuration management software;issue tracking system;software engineering;software maintenance;software task management;source code annotations;task articulation;Collaborative software;Collaborative work;Computer science;Engineering management;Environmental management;Software development management;Software engineering;Software maintenance;Software tools;Tagging}
}

@InProceedings{6018045,
  Title                    = {Collaborative Software Development of Scalable DoD Computational Engineering},
  Author                   = {C. A. Atwood and S. Adamec and D. Post and L. Handley-Blair and M. Murphy},
  Booktitle                = {High Performance Computing Modernization Program Users Group Conference (HPCMP-UGC), 2010 DoD},
  Year                     = {2010},
  Month                    = {June},
  Pages                    = {414-420},

  Abstract                 = {The Computational Research and Engineering Acquisition Tools and Environments (CREATE) Program is charged with positively impacting the US Department of Defense (DoD) Acquisition Process via Computational Engineering for capability gaps identified by the CREATE Boards of Directors. These prioritized requirements have been characterized and are annually reconciled in terms of gaps associated with required analysis cycle-times, physical accuracy, and necessary analysis capabilities. Furthermore, the Office of the Secretary of Defense(OSD) Overarching Integrated Product Team (OIPT) has provided goals which drive the usage of CREATE software by DoD Acquisition Programs. In order to achieve these usage targets, the CREATE Program has established a governance model and thence a hosted set of services to enhance collaboration among the developer teams and the targeted Acquisition Program (AP) subject matter experts. The goals of these collaboration services are to: 1) scale and speed the feedback amongst the CREATE and AP teams, while 2) minimizing interruption to developer and user workflows. Towards these goals, the community services have been architected as discussion forums, issue tracking, and documentation. Such services are now common place in the enterprise and open-source software projects, and efficiently scale with the user community by enabling a searchable knowledge base. In addition, owing to the key capabilities of this DoD software, CREATE requires authenticated and authorized access for each member of the community. This paper summarizes the governance model and process by which the services were selected, the architecture implemented, and the challenges going forward.},
  Doi                      = {10.1109/HPCMP-UGC.2010.25},
  Keywords                 = {defence industry;groupware;military computing;software architecture;CREATE program;OIPT;OSD;Office of the Secretary of Defense;Overarching Integrated Product Team;US Department of Defense;acquisition process;acquisition program;collaborative software development;computational research and engineering acquisition tools and environments;scalable DoD computational engineering;software architecture;Collaboration;Communities;Information services;Servers;Software;Software measurement;US Department of Defense}
}

@InProceedings{6883055,
  Title                    = {Temporal visualization of collaborative software development in FOSS forks},
  Author                   = {A. Azarbakht},
  Booktitle                = {2014 IEEE Symposium on Visual Languages and Human-Centric Computing (VL/HCC)},
  Year                     = {2014},
  Month                    = {July},
  Pages                    = {201-202},

  Abstract                 = {Software development in free and open source (FOSS) projects is a collective human activity. Software developers in these projects collaborate via FOSS informalisms, i.e. mailing list, bug repository and code repository. Analysing the human collaborative work of these software developers over a time period, e.g. five years, sheds light on the underlying structure and dynamics of how the software is being developed, how the project is led, who the influencers are, and how to achieve a state of sustainability. In this paper, we propose to use temporal social network analysis with temporal visualization to study the evolution and social dynamics of FOSS communities. With these techniques we aim to identify measures associated with unhealthy group dynamics, e.g. a simmering conflict, as well as early indicators of major events in the lifespan of a community. One dynamic we are especially interested in, are those of forked FOSS projects. We used the results of a study of forked FOSS projects by [Robles and Gonzalez-Barahona 2012] as the starting platform for our study, and tried to gain a better understanding of the evolution of these communities.},
  Doi                      = {10.1109/VLHCC.2014.6883055},
  ISSN                     = {1943-6092},
  Keywords                 = {public domain software;social networking (online);software engineering;FOSS forks;collaborative software development;free and open source software projects;temporal social network analysis;temporal visualization;unhealthy group dynamics;Accuracy;Collaboration;Communities;Data visualization;Social network services;Software;Visualization}
}

@InProceedings{7166057,
  Title                    = {On the Cost of Mining Very Large Open Source Repositories},
  Author                   = {S. Banerjee and B. Cukic},
  Booktitle                = {Big Data Software Engineering (BIGDSE), 2015 IEEE/ACM 1st International Workshop on},
  Year                     = {2015},
  Month                    = {May},
  Pages                    = {37-43},

  Abstract                 = {Open source bug tracking systems provide a rich information suite that is actively used by software engineering researchers to design solutions to triaging, duplicate classification and developer assignment problems. Today, open repositories often contain in excess of 100, 000 reports, and in cases of RedHat and Mozilla, over a million. Obtaining and analyzing the contents of such datasets are both time and resource consuming. By summarizing the related work we demonstrate that researchers often focused on smaller subsets of the data, and seldom embrace the “big-dataism”. With the emergence of cloud based computation systems such as Amazon EC2, one expects it to be easier to perform large scale analyses. However, our detailed time and cost analysis indicates that significant challenges still remain. Acquiring the open source data can be time intensive, and prone to being misinterpreted as Denial of Service attacks. Generating similarity scores for all prior reports, for example, is a polynomial time problem. In this paper, we present actual costs that we incurred when analyzing the complete repositories from Eclipse, Firefox and Open Office. In our approach, we relied on computing clusters to process the data in an attempt to reduce the cost of analyzing large datasets on the cloud. We present estimated costs for a researcher attempting to analyze complete datasets from Eclipse, Mozilla, Novell and RedHat using the best possible resources. In an ideal situation, with no bottlenecks, a researcher investing just over $40, 000 and 2 weeks of non stop computing time would be able to measure similarity of problem reports within all four datasets.},
  Doi                      = {10.1109/BIGDSE.2015.16},
  Keywords                 = {Big Data;cloud computing;computational complexity;data mining;public domain software;software engineering;Amazon EC2;Big-Dataism;Eclipse;Firefox;Novell;Open Office;RedHat;cloud based computation systems;cost analysis;data processing;denial of service attacks;open source bug tracking systems;polynomial time problem;software engineering;time analysis;very large open source repository mining;Accuracy;Computer crime;Data mining;Graphics processing units;Random access memory;XML}
}

@InProceedings{7027440,
  Title                    = {Eclipse vs. Mozilla: A Comparison of Two Large-Scale Open Source Problem Report Repositories},
  Author                   = {S. Banerjee and J. Helmick and Z. Syed and B. Cukic},
  Booktitle                = {2015 IEEE 16th International Symposium on High Assurance Systems Engineering},
  Year                     = {2015},
  Month                    = {Jan},
  Pages                    = {263-270},

  Abstract                 = {Bug tracking systems play an important role in the development and maintenance of large-scale software systems. Having access to open source bug tracking systems has allowed researchers to take advantage of rich datasets and propose solutions to manage duplicate report classification, developer assignment and quality assessment. In spite of research advances, our understanding of the content of these repositories remains limited, primarily because of their size. In many cases, researchers analyze small portions of datasets thus limiting the understanding of the dynamics of problem reporting. The objective of this study is to explore the properties of two large-scale open source problem report repositories. The Eclipse dataset, at the time of download, consisted of 363; 770 reports spanning 11+ years, whereas Mozilla contained 699; 085 reports spanning 14+ years.Our research examines the evolution of datasets over time by analyzing the changes in the repository and the profiles of users who submit problem reports. We provide quantitative evidence on how submitter's maturity reduces the propensity to submit poor quality, insignificant or duplicate reports. We show that a diverse user base, characteristic of Mozilla, creates challenges for the development team as they spend more time triaging, rather than fixing, issues. Finally, we provide the research community with a series of observations and suggestions on how to study large-scale problem repositories.},
  Doi                      = {10.1109/HASE.2015.45},
  ISSN                     = {1530-2059},
  Keywords                 = {program debugging;public domain software;software maintenance;Eclipse dataset;Mozilla characteristic;Mozilla dataset;developer assignment;download time;duplicate report classification management;large-scale open source problem report repositories;large-scale software system development;large-scale software system maintenance;open source bug tracking systems;problem reporting dynamics;quality assessment;quantitative analysis;research community;user base;Communities;Computer bugs;Educational institutions;Maintenance engineering;Pragmatics;Quality assessment;Software systems}
}

@InProceedings{6786083,
  Title                    = {DECOBA: Utilizing Developers Communities in Bug Assignment},
  Author                   = {S. Banitaan and M. Alenezi},
  Booktitle                = {Machine Learning and Applications (ICMLA), 2013 12th International Conference on},
  Year                     = {2013},
  Month                    = {Dec},
  Pages                    = {66-71},
  Volume                   = {2},

  Abstract                 = {Bug Tracking System (BTS) is public ally accessible which enables geographically distributed developers to follow the work of each other and contribute in bug fixing. Developer interactions through commenting on bug reports generate a developer social network that can be used to improve software development and maintenance activities. In large scale complex software projects, software maintenance requires larger groups to participate in its activities. Most previous bug assignments approaches assign only one developer to new bugs. However, bug fixing is a collaborative effort between several developers (i.e., many developers contribute their experience in fixing a bug report). In this work, we build developers social networks based on developers comments on bug reports and detect developers communities. We also assign a relevant community to each newly committed bug report. Moreover, we rank developers in each community based on their experience. An experimental evaluation is conducted on three open source projects namely Net Beans, Free desktop, and Mandriva. The results show that the detected communities are significantly connected with high density. They also show that the proposed approach achieves feasible accuracy of bug assignment.},
  Doi                      = {10.1109/ICMLA.2013.107},
  Keywords                 = {groupware;program debugging;project management;public domain software;social networking (online);software maintenance;BTS;DECOBA;Freedesktop project;Mandriva project;NetBeans project;bug assignment;bug fixing;bug reports;bug tracking system;developer communities;developer interactions;developer social network;large-scale complex software projects;open source projects;software development activity improvement;software maintenance activity improvement;Collaboration;Communities;Computer bugs;Measurement;Predictive models;Social network services;Vectors;Bug Report Assignment;Community Detection;Developer Ranking;Developers Social Network}
}

@InProceedings{6226578,
  Title                    = {Revisiting bug triage and resolution practices},
  Author                   = {O. Baysal and R. Holmes and M. W. Godfrey},
  Booktitle                = {User Evaluation for Software Engineering Researchers (USER), 2012},
  Year                     = {2012},
  Month                    = {June},
  Pages                    = {29-30},

  Abstract                 = {Bug triaging is an error-prone, tedious and time-consuming task. However, little qualitative research has been done on the actual use of bug tracking systems, bug triage, and resolution processes. We are planning to conduct a qualitative study to understand the dynamics of bug triage and fixing process, as well as bug reassignments and reopens. We will study interviews conducted with Mozilla Core and Firefox developers to get insights into the primary obstacles developers face during the bug fixing process. Is the triage process flawed? Does bug review slow things down? Does approval takes too long? We will also categorize the main reasons for bug reassignments and reopens. We will then combine results with a quantitative study of Firefox bug reports, focusing on factors related to bug report edits and number of people involved in handling the bug.},
  Doi                      = {10.1109/USER.2012.6226578},
  Keywords                 = {program debugging;Mozilla core;Mozilla developers;bug fixing process;bug reassignments;bug reopens;bug tracking systems;bug triage;resolution practices;Computer bugs;Educational institutions;Encyclopedias;Fires;Interviews;Software;Sorting}
}

@InProceedings{6671287,
  Title                    = {The influence of non-technical factors on code review},
  Author                   = {O. Baysal and O. Kononenko and R. Holmes and M. W. Godfrey},
  Booktitle                = {2013 20th Working Conference on Reverse Engineering (WCRE)},
  Year                     = {2013},
  Month                    = {Oct},
  Pages                    = {122-131},

  Abstract                 = {When submitting a patch, the primary concerns of individual developers are “How can I maximize the chances of my patch being approved, and minimize the time it takes for this to happen?” In principle, code review is a transparent process that aims to assess qualities of the patch by their technical merits and in a timely manner; however, in practice the execution of this process can be affected by a variety of factors, some of which are external to the technical content of the patch itself. In this paper, we describe an empirical study of the code review process for WebKit, a large, open source project; we replicate the impact of previously studied factors - such as patch size, priority, and component and extend these studies by investigating organizational (the company) and personal dimensions (reviewer load and activity, patch writer experience) on code review response time and outcome. Our approach uses a reverse engineered model of the patch submission process and extracts key information from the issue tracking and code review systems. Our findings suggest that these nontechnical factors can significantly impact code review outcomes.},
  Doi                      = {10.1109/WCRE.2013.6671287},
  ISSN                     = {1095-1350},
  Keywords                 = {program diagnostics;reverse engineering;software quality;WebKit;code review outcome;code review process;code review response time;code review system;component;issue tracking system;nontechnical factors;open source project;patch size;patch submission process;priority;reverse engineered model;software quality;Browsers;Companies;Databases;Electronic mail;Google;Time factors;Code review;WebKit;non-technical factors;open source software;personal and organizational aspects}
}

@InProceedings{7181442,
  Title                    = {Rethinking User Interfaces for Feature Location},
  Author                   = {F. Beck and B. Dit and J. Velasco-Madden and D. Weiskopf and D. Poshyvanyk},
  Booktitle                = {2015 IEEE 23rd International Conference on Program Comprehension},
  Year                     = {2015},
  Month                    = {May},
  Pages                    = {151-162},

  Abstract                 = {Locating features in large software systems is a fundamental maintenance task for developers when fixing bugs and extending software. We introduce In Situ Impact Insight (I3), a novel user interface to support feature location. In addition to a list of search results, I3 provides support for developers during browsing and inspecting the retrieved code entities. In situ visualizations augment results and source code with additional information relevant for further exploration. Developers are able to retrieve details on the textual similarity of a source code entity to the search query and to other entities, as well as the information on co-changed entities from a project's history. Execution traces recorded during program runs can be used as filters to further refine the search results. We implemented I3 as an Eclipse plug-in and tested it in a user study involving 18 students and professional developers that were asked to perform three feature location tasks chosen from the issue tracking system of jEdit. The results of our study suggest that I3's user interface is intuitive and unobtrusively supports developers with the required information when and where they need it.},
  Doi                      = {10.1109/ICPC.2015.24},
  ISSN                     = {1092-8138},
  Keywords                 = {program diagnostics;program visualisation;query processing;software maintenance;source code (software);user interfaces;Eclipse plug-in;I3;I3 user interface;In Situ Impact Insight;feature location;in situ visualizations;jEdit tracking system;large software systems;program execution traces;retrieved code entity;search query;source code entity textual similarity;Feature extraction;History;Maintenance engineering;Software systems;User interfaces;Visualization}
}

@InProceedings{5428683,
  Title                    = {The Impact of Collaboration Network Structure on Issue Tracking's Process Efficiency at a Large Business Software Vendor},
  Author                   = {A. Beckhaus and L. M. Karg and D. Neumann},
  Booktitle                = {System Sciences (HICSS), 2010 43rd Hawaii International Conference on},
  Year                     = {2010},
  Month                    = {Jan},
  Pages                    = {1-10},

  Abstract                 = {Researchers in the IS domain have addressed communication structure and its effect on performance. While early research focused on small networks and utilized sociometric surveys, recent works have concentrated on electronic data sources provided by open source software repositories. Surprisingly, software vendors have less frequently been studied despite their need for continuous enhancement of organizational design. In this study, we analyze a global business software vendor by utilizing existing data sources. We investigate the association of both collaboration network centrality and communication with process efficiency. Despite coping with complex, interweaved processes and social networks, we find that communication, centrality in the large case-study-wide network, and communication pattern homogeneity are positively associated with process efficiency. However, centrality in small work groups slows the analyzed issue tracking process down, possibly due to increased overhead and bottleneck effects that become visible when looking at single issues qualitatively.},
  Doi                      = {10.1109/HICSS.2010.381},
  ISSN                     = {1530-1605},
  Keywords                 = {business data processing;groupware;information systems;public domain software;software houses;business software vendor;collaboration network structure;communication pattern homogeneity;electronic data sources;information system;issue tracking process;large business software vendor;open source software repositories;social networks;Business;Collaborative software;Collaborative work;Computer industry;Manufacturing industries;Open source software;Programming;Social network services;Software engineering;Software performance}
}

@InProceedings{7335409,
  Title                    = {The impact of cross-distribution bug duplicates, empirical study on Debian and Ubuntu},
  Author                   = {V. Boisselle and B. Adams},
  Booktitle                = {Source Code Analysis and Manipulation (SCAM), 2015 IEEE 15th International Working Conference on},
  Year                     = {2015},
  Month                    = {Sept},
  Pages                    = {131-140},

  Abstract                 = {Although open source distributions like Debian and Ubuntu are closely related, sometimes a bug reported in the Debian bug repository is reported independently in the Ubuntu repository as well, without the Ubuntu users nor developers being aware. Such cases of undetected cross-distribution bug duplicates can cause developers and users to lose precious time working on a fix that already exists or to work individually instead of collaborating to find a fix faster. We perform a case study on Ubuntu and Debian bug repositories to measure the amount of cross-distribution bug duplicates and estimate the amount of time lost. By adapting an existing within-project duplicate detection approach (achieving a similar recall of 60%), we find 821 cross-duplicates. The early detection of such duplicates could reduce the time lost by users waiting for a fix by a median of 38 days. Furthermore, we estimate that developers from the different distributions lose a median of 47 days in which they could have collaborated together, had they been aware of duplicates. These results show the need to detect and monitor cross-distribution duplicates.},
  Doi                      = {10.1109/SCAM.2015.7335409},
  Keywords                 = {program debugging;public domain software;Debian bug repository;Ubuntu bug repository;cross-distribution bug duplicate;open source distribution;Collaboration;Computer bugs;Feature extraction;Generators;Information retrieval;Linux;Organizations}
}

@InProceedings{5463291,
  Title                    = {A comparative exploration of FreeBSD bug lifetimes},
  Author                   = {G. Bougie and C. Treude and D. M. German and M. A. Storey},
  Booktitle                = {2010 7th IEEE Working Conference on Mining Software Repositories (MSR 2010)},
  Year                     = {2010},
  Month                    = {May},
  Pages                    = {106-109},

  Abstract                 = {In this paper, we explore the viability of mining the basic data provided in bug repositories to predict bug lifetimes. We follow the method of Lucas D. Panjer as described in his paper, Predicting Eclipse Bug Lifetimes. However, in place of Eclipse data, the FreeBSD bug repository is used. We compare the predictive accuracy of five different classification algorithms applied to the two data sets. In addition, we propose future work on whether there is a more informative way of classifying bugs than is considered by current bug tracking systems.},
  Doi                      = {10.1109/MSR.2010.5463291},
  ISSN                     = {2160-1852},
  Keywords                 = {data mining;pattern classification;program debugging;software engineering;Eclipse data;FreeBSD bug lifetimes;bug classification;bug repository;bug tracking system;classification algorithm;data mining;Accuracy;Classification algorithms;Computer bugs;Data mining;Kernel;Linux;Open source software;Project management;Software development management;Software systems;Bug lifetimes;FreeBSD;Mining Software Repositories}
}

@Article{4721183,
  Title                    = {Tracking Your Changes: A Language-Independent Approach},
  Author                   = {G. Canfora and L. Cerulo and M. Di Penta},
  Journal                  = {IEEE Software},
  Year                     = {2009},

  Month                    = {Jan},
  Number                   = {1},
  Pages                    = {50-57},
  Volume                   = {26},

  Abstract                 = {Versioning and bug-tracking systems are invaluable assets for large software projects that involve developers spread worldwide and numerous users reporting bugs and proposing enhancements. In addition to supporting development, versioning systems are a precious source of information for studying or monitoring a software system's evolution.},
  Doi                      = {10.1109/MS.2009.26},
  ISSN                     = {0740-7459},
  Keywords                 = {configuration management;program debugging;project management;software development management;software maintenance;software prototyping;system monitoring;language-independent approach;software project bug-tracking system;software project versioning;software system development;software system evolution monitoring;Cloning;Computer bugs;Humans;Information resources;Monitoring;Recommender systems;Software algorithms;Software systems;Software testing;Software tools;differencing tools;mining software archives;software evolution}
}

@InProceedings{5714448,
  Title                    = {An Initial Study on the Bug Report Duplication Problem},
  Author                   = {Y. C. Cavalcanti and E. S. d. Almeida and C. E. A. d. Cunha and D. Lucredio and S. R. d. L. Meira},
  Booktitle                = {Software Maintenance and Reengineering (CSMR), 2010 14th European Conference on},
  Year                     = {2010},
  Month                    = {March},
  Pages                    = {264-267},

  Abstract                 = {According to recent work, duplicate bug report entries in bug tracking systems impact negatively on software maintenance and evolution productivity due to, among other factors, the increased time spent on report analysis and validation, what in some cases take over 20 minutes. Therefore, a considerable amount of time is lost mainly with duplicate bug report analysis. This work presents an initial characterization study using data from bug trackers from private and open source projects, in order to understand the possible factors that cause bug report duplication and its impact on software development.},
  Doi                      = {10.1109/CSMR.2010.52},
  ISSN                     = {1534-5351},
  Keywords                 = {program debugging;software maintenance;bug report duplication problem;bug tracker;bug tracking system;duplicate bug report analysis;duplicate bug report entry;software development;software maintenance;Context;Electronic mail;Measurement;Organizations;Productivity;Programming;Software;problem report;report duplication;software bugs;software maintenance}
}

@InProceedings{4024004,
  Title                    = {On the Use of Process Trails to Understand Software Development},
  Author                   = {L. Cerulo},
  Booktitle                = {2006 13th Working Conference on Reverse Engineering},
  Year                     = {2006},
  Month                    = {Oct},
  Pages                    = {303-304},

  Abstract                 = {Software repositories, such as version control systems (CVS) and bug-tracking systems (Bugzilla), provide useful information about software process trails left by developers during the evolution of a software project. Mining these repositories provides a way to understand software development, to support predictions about software development, and to plan various aspects of software projects. We introduce three cases in the areas of impact analysis, change request assignment, and crosscutting concern mining, that takes benefit from historical information and show that the combination of different type of analyses can improve the performance of these software engineering models},
  Doi                      = {10.1109/WCRE.2006.40},
  ISSN                     = {1095-1350},
  Keywords                 = {configuration management;data mining;program debugging;program diagnostics;software process improvement;Bugzilla;bug-tracking systems;change request assignment;crosscutting concern mining;impact analysis;process trails;software development;software engineering model;software repository;version control systems;Control systems;Documentation;Information analysis;Information resources;Performance analysis;Programming;Software engineering;Software performance;Software systems;Software tools}
}

@InProceedings{4224163,
  Title                    = {AEGIS: A Proactive Methodology to Shield against Zero-Day Exploits},
  Author                   = {M. Chandrasekaran and M. Baig and S. Upadhyaya},
  Booktitle                = {Advanced Information Networking and Applications Workshops, 2007, AINAW '07. 21st International Conference on},
  Year                     = {2007},
  Month                    = {May},
  Pages                    = {556-563},
  Volume                   = {2},

  Abstract                 = {Given the large number of vulnerability instances disclosed in various bug-tracking communities, system administrators face an up-hill task of protecting their system/ network against zero-day exploits. In order to safeguard against such exploits, the present challenges come in two-fold: (i) there exists a compelling need to assimilate configuration specific vulnerability information from various bug-tracking diaspora; also (ii) there is a need to proactively generate policy specific signatures which act as a first line of defense. In this paper we propose an automated approach for determining vulnerabilities pertinent to the current network/ system configuration using the information aggregated from different bug tracking communities. Such vulnerability assessment and indication mechanisms significantly alleviate the system administratorÂ¿s burden of manual content digging for vulnerabilities in his own configuration context. Furthermore, we propose an Extensible Defense Oriented Representation Schema (EDORS) for vulnerability representation, which is subsequently used by the policy engine to generate appropriate signatures. As a result, the generated signatures can be viewed as a preventive interim security measure against recently published threats until its patch is released. We have also evaluated our framework through a series of experiments.},
  Doi                      = {10.1109/AINAW.2007.72},
  Keywords                 = {Application software;Computer science;Context awareness;Decision making;Laboratories;Middleware;Mobile computing;Reflection;Safety;Usability}
}

@InProceedings{6612223,
  Title                    = {Performance evaluation of VSM and LSI models to determine bug reports similarity},
  Author                   = {I. Chawla and S. K. Singh},
  Booktitle                = {Contemporary Computing (IC3), 2013 Sixth International Conference on},
  Year                     = {2013},
  Month                    = {Aug},
  Pages                    = {375-380},

  Abstract                 = {Bug reports of open source software systems are increasing exponentially. One reason for growing bug reports is that bug reporters do not browse the bug repository before submitting a bug report. There may be some similar bugs already reported: one, which are exactly similar or duplicate and other, which are semantically similar means they may belong to the same software component or files. The information contained in the previously reported similar bugs can be helpful in fixing and resolving the newly reported bugs. In this paper, we applied and compared performance of two information retrieval (IR) models: Vector Space Model (VSM) and Latent Semantic Indexing (LSI), in extracting existing similar bug reports. The performance of these two models have been evaluated based on the Top Ten results retrieved by them for relevant bug reports. Experiments have been conducted on 106 bug reports of three components from Google chrome, browser. Result shows that LSI performs better in most cases in comparison to VSM.},
  Doi                      = {10.1109/IC3.2013.6612223},
  Keywords                 = {information retrieval;pattern matching;performance evaluation;program debugging;public domain software;software management;Google chrome;IR model;LSI models;VSM;browser;bug reports similarity determination;bug repository;information retrieval;latent semantic indexing;open source software systems;performance evaluation;vector space model;Computer bugs;Indexing;Information retrieval;Large scale integration;Semantics;Software;Vectors;Bug report;Latent Semantic Indexing;Vector space model}
}

@InProceedings{6018025,
  Title                    = {A Common Computational Science Environment for High Performance Computing Centers},
  Author                   = {J. Clarke and J. Vines and K. Kirk and E. Mark and R. Angelini and C. Spear and N. Waisbrot and J. Martin and K. Leiter},
  Booktitle                = {High Performance Computing Modernization Program Users Group Conference (HPCMP-UGC), 2010 DoD},
  Year                     = {2010},
  Month                    = {June},
  Pages                    = {442-449},

  Abstract                 = {The Computational Sciences Environment (CSE) was developed to provide a standard development platform for data analysis, visualization, and software testing and evaluation. The Classified Data Analysis and Assessment Center (CDAAC), in conjunction with the Computational Sciences and Engineering Branch (CSEB) of the Army Research Laboratory, assembled a set of open source data analysis tools and applications, software management and testing tools, and libraries necessary to run the tools; and made them available as a package called CSE. CSE also provides experimental software builds for users who might need newer features than what is currently available in the release package. The CSE team provides support for developers, the end-user, and distributed development teams. Tests are regularly run on the software, both current and release, and the results are submitted to quality dashboards for review using CTest. CTest is part of an open-source software building tool called CMake. Developers can use CSE as a template and can customize it to meet their specific project goals. CSE provides developers with a common tool set to assist in developing portable high performance computing (HPC) Applications. Development of CSE has been managed through an open-source project management application that provides Software Configuration Management (SCM) integration of the CSE repository, informational wikis, bug tracking, and feature requests. To support distributed development teams, CSE provides project management tools, software repositories, SCM, and online software quality dashboards.},
  Doi                      = {10.1109/HPCMP-UGC.2010.68},
  Keywords                 = {computer centres;data analysis;data visualisation;program testing;project management;public domain software;software libraries;software management;software packages;software quality;software tools;CSE;CTest;SCM;classified data analysis and assessment center;computational science environment;data visualization;high performance computing centre;informational wikis;libraries;open source software;project management tools;quality dashboards;software configuration management;software package;software quality;software repositories;software testing;software tools;Buildings;Data analysis;Data visualization;Libraries;Software;Testing;US Department of Defense}
}

@InProceedings{6601296,
  Title                    = {Integrating Issue Tracking Systems with Community-Based Question and Answering Websites},
  Author                   = {D. Correa and A. Sureka},
  Booktitle                = {2013 22nd Australian Software Engineering Conference},
  Year                     = {2013},
  Month                    = {June},
  Pages                    = {88-96},

  Abstract                 = {Issue tracking systems such as Bugzilla are tools to facilitate collaboration between software maintenance professionals. Popular issue tracking systems consists of discussion forums to facilitate bug reporting and comment posting. We observe that several comments posted in issue tracking system contains link to external websites such as YouTube (video sharing website), Twitter (micro-blogging website), Stack overflow (a community-based question and answering website for programmers), Wikipedia and focused discussions forums. Stack overflow is a popular community-based question and answering website for programmers and is widely used by software engineers as it contains answers to millions of questions (an extensive knowledge resource) posted by programmers on diverse topics. We conduct a series of experiments on open-source Google Chromium and Android issue tracker data (publicly available real-world dataset) to understand the role and impact of Stack overflow in issue resolution. Our experimental results show evidences of several references to Stack overflow in threaded discussions and demonstrate correlation between a lower mean time to repair (in one dataset) with presence of Stack overflow links. We also observe that the average number of comments posted in response to bug reports are less when Stack overflow links are presented in contrast to bug reports not containing Stack overflow references. We conduct experiments based on textual similarly analysis (content-based linguistic features) and contextual data analysis (exploited metadata such as tags associated to a Stack overflow question) to recommend Stack overflow questions for an incoming bug report. We perform empirical analysis to measure the effectiveness of the proposed method on a dataset containing ground-truth and present our insights. We present the result of a survey (of Google Chromium Developers) that we conducted to understand practitioner's perspective and experience.},
  Doi                      = {10.1109/ASWEC.2013.20},
  ISSN                     = {1530-0803},
  Keywords                 = {data analysis;data mining;meta data;program debugging;public domain software;question answering (information retrieval);social networking (online);software maintenance;software metrics;text analysis;user interfaces;Android issue tracker data;Bugzilla;Stack overflow;Twitter;Wikipedia;YouTube;bug reporting;comment posting;community-based question-and-answering Web sites;content-based linguistic features;contextual data analysis;discussion forums;exploited metadata;issue tracking system integration;microblogging Web site;mining software repositories;open-source Google Chromium issue tracker data;software maintenance professionals;tags;textual similarly analysis;video sharing Web site;Androids;Chromium;Discussion forums;Google;Humanoid robots;Message systems;Software maintenance;Community Driven Q&amp;A Website;Empirical Software Engineering and Measurements (ESEM);Mining Bug Reports;Mining Software Repositories (MSR);Social Media for Software Engineering;Software Maintenance}
}

@InProceedings{4658092,
  Title                    = {Supporting software evolution analysis with historical dependencies and defect information},
  Author                   = {M. D'Ambros},
  Booktitle                = {Software Maintenance, 2008. ICSM 2008. IEEE International Conference on},
  Year                     = {2008},
  Month                    = {Sept},
  Pages                    = {412-415},

  Abstract                 = {More than 90% of the cost of software is due to maintenance and evolution. Understanding the evolution of large software systems is a complex problem, which requires the use of various techniques and the support of tools. Several software evolution approaches put the emphasis on structural entities such as packages, classes and structural relationships. However, software evolution is not only about the history of software artifacts, but it also includes other types of data such as problem reports, mailing list archives etc. We propose an approach which focuses on historical dependencies and defects. We claim that they play an important role in software evolution and they are complementary to techniques based on structural information. We use historical dependencies and defect information to learn about a software system and detect potential problems in the source code. Moreover, based on design flaws detected in the source code, we predict the location of future bugs to focus maintenance activities on the buggy parts of the system. We validated our defect prediction by comparing it with the actual defects reported in the bug tracking system.},
  Doi                      = {10.1109/ICSM.2008.4658092},
  ISSN                     = {1063-6773},
  Keywords                 = {program visualisation;software maintenance;software prototyping;software reliability;defect meta-model;large software system;program visualisation;software artifact history dependency;software defect information;software evolution analysis;software maintenance;source code;Computer bugs;Costs;History;Informatics;Information analysis;Packaging;Software maintenance;Software packages;Software quality;Software systems}
}

@InProceedings{4493295,
  Title                    = {A Flexible Framework to Support Collaborative Software Evolution Analysis},
  Author                   = {M. D'Ambros and M. Lanza},
  Booktitle                = {Software Maintenance and Reengineering, 2008. CSMR 2008. 12th European Conference on},
  Year                     = {2008},
  Month                    = {April},
  Pages                    = {3-12},

  Abstract                 = {To understand the evolution of software, researchers have developed a plethora of tools to parse, model, and analyze the history of systems. Despite their usefulness, a common downside of such tools is that their use comes with many strings attached, such as installation, data formats, usability, etc. The result is that many tools are only used by their creators, which is detrimental to cross-fertilization of research ideas and collaborative analysis. In this paper we present the Churrasco framework, which supports software evolution modeling, visualization and analysis through a web interface. The user provides only the URL of the Subversion repository to be analyzed and, if available, of the corresponding bug tracking system. Churrasco processes the given data and automatically creates and stores an evolutionary model in a centralized database. This database, called Meta-base is connected to Churrasco through object-relational persistence. The persistency mechanism is meta-described in terms of the EMOF meta-meta- model and automatically generated based on any given evolutionary meta-model. In case the meta-model changes, the persistency mechanism is automatically updated. After providing a detailed description of Churrasco, we provide evidence, by means of an example scenario, that it allows for collaborative software evolution analysis, based on visualizations available on our analysis web portal.},
  Doi                      = {10.1109/CSMR.2008.4493295},
  ISSN                     = {1534-5351},
  Keywords                 = {Internet;object-oriented databases;relational databases;reverse engineering;software tools;Churrasco framework;Meta-base;URL;Web interface;bug tracking system;centralized database;collaborative software evolution analysis;evolutionary meta-model;object-relational persistence;software visualization;Cause effect analysis;Collaborative software;Data visualization;History;Informatics;Information analysis;Software systems;Software tools;Usability;Visual databases}
}

@InProceedings{4290709,
  Title                    = {"A Bug's Life" Visualizing a Bug Database},
  Author                   = {M. D'Ambros and M. Lanza and M. Pinzger},
  Booktitle                = {2007 4th IEEE International Workshop on Visualizing Software for Understanding and Analysis},
  Year                     = {2007},
  Month                    = {June},
  Pages                    = {113-120},

  Abstract                 = {Visualization has long been accepted as a viable means to comprehend large amounts of information. Especially in the context of software evolution a well-designed visualization is crucial to be able to cope with the sheer data that needs to be analyzed. Many approaches have been investigated to visualize evolving systems, but most of them focus on structural data and are useful to answer questions about the structural evolution of a system. In this paper we consider an often neglected type of information, namely the one provided by bug tracking systems, which store data about the problems that various people, from developers to end users, detected and reported. We first briefly introduce the context by reporting on the particularities of the present data, and then propose two visualizations to render bugs as first-level entities.},
  Doi                      = {10.1109/VISSOF.2007.4290709},
  Keywords                 = {data structures;data visualisation;database management systems;program debugging;bug database visualization;bug rendering;bug tracking systems;data storage;data structure;software evolution;Computer architecture;Computer bugs;Data visualization;Feedback;History;Informatics;Radiography;Reverse engineering;Visual databases;Watches}
}

@InProceedings{6494945,
  Title                    = {Healing online service systems via mining historical issue repositories},
  Author                   = {R. Ding and Q. Fu and J. G. Lou and Q. Lin and D. Zhang and J. Shen and T. Xie},
  Booktitle                = {Automated Software Engineering (ASE), 2012 Proceedings of the 27th IEEE/ACM International Conference on},
  Year                     = {2012},
  Month                    = {Sept},
  Pages                    = {318-321},

  Abstract                 = {Online service systems have been increasingly popular and important nowadays, with an increasing demand on the availability of services provided by these systems, while significant efforts have been made to strive for keeping services up continuously. Therefore, reducing the MTTR (Mean Time to Restore) of a service remains the most important step to assure the user-perceived availability of the service. To reduce the MTTR, a common practice is to restore the service by identifying and applying an appropriate healing action (i.e., a temporary workaround action such as rebooting a SQL machine). However, manually identifying an appropriate healing action for a given new issue (such as service down) is typically time consuming and error prone. To address this challenge, in this paper, we present an automated mining-based approach for suggesting an appropriate healing action for a given new issue. Our approach generates signatures of an issue from its corresponding transaction logs and then retrieves historical issues from a historical issue repository. Finally, our approach suggests an appropriate healing action by adapting healing actions for the retrieved historical issues. We have implemented a healing suggestion system for our approach and applied it to a real-world product online service that serves millions of online customers globally. The studies on 77 incidents (severe issues) over 3 months showed that our approach can effectively provide appropriate healing actions to reduce the MTTR of the service.},
  Doi                      = {10.1145/2351676.2351735},
  Keywords                 = {data mining;fault tolerant computing;information services;MTTR;automated mining-based approach;healing online service systems;healing suggestion system;historical issue repository mining;historical issue retrieval;mean time to restore;service user-perceived availability;transaction logs;Online service system;healing action}
}

@Article{6799150,
  Title                    = {Using Defect Taxonomies for Testing Requirements},
  Author                   = {M. Felderer and A. Beer},
  Journal                  = {IEEE Software},
  Year                     = {2015},

  Month                    = {May},
  Number                   = {3},
  Pages                    = {94-101},
  Volume                   = {32},

  Abstract                 = {Systematic defect management based on bug-tracking systems such as Bugzilla is well established and has been successfully used in many software organizations. Defect management weights the failures observed during test execution according to their severity and forms the basis for effective defect taxonomies. In practice, most defect taxonomies are used only for the a posteriori allocation of testing resources to prioritize failures for debugging. Thus, these taxonomies' full potential to control and improve all the steps of testing has remained unexploited. This is especially the case for testing a system's user requirements. System-level defect taxonomies can improve the design of requirements-based tests, the tracing of defects to requirements, the quality assessment of requirements, and the control of the relevant defect management. So, we developed requirements-based testing with defect taxonomies (RTDT). This approach is aligned with the standard test process and uses defect taxonomies to support all phases of testing requirements. To illustrate this approach and its benefits, we use an example project (which we call Project A) from a public health insurance institution.},
  Doi                      = {10.1109/MS.2014.56},
  ISSN                     = {0740-7459},
  Keywords                 = {program testing;software quality;Bugzilla;RTDT;a posteriori allocation;bug-tracking system;defect taxonomies;requirements quality assessment;requirements-based testing;systematic defect management;Graphical user interfaces;Requirements engineering;Software engineering;Software testing;Syntactics;Taxonomy;defect taxonomy;requirements validation;requirements-based testing;software engineering;software quality;test management}
}

@InProceedings{1235403,
  Title                    = {Populating a Release History Database from version control and bug tracking systems},
  Author                   = {M. Fischer and M. Pinzger and H. Gall},
  Booktitle                = {Software Maintenance, 2003. ICSM 2003. Proceedings. International Conference on},
  Year                     = {2003},
  Month                    = {Sept},
  Pages                    = {23-32},

  Abstract                 = {Version control and bug tracking systems contain large amounts of historical information that can give deep insight into the evolution of a software project. Unfortunately, these systems provide only insufficient support for a detailed analysis of software evolution aspects. We address this problem and introduce an approach for populating a release history database that combines version data with bug tracking data and adds missing data not covered by version control systems such as merge points. Then simple queries can be applied to the structured data to obtain meaningful views showing the evolution of a software project. Such views enable more accurate reasoning of evolutionary aspects and facilitate the anticipation of software evolution. We demonstrate our approach on the large open source project Mozilla that offers great opportunities to compare results and validate our approach.},
  Doi                      = {10.1109/ICSM.2003.1235403},
  ISSN                     = {1063-6773},
  Keywords                 = {configuration management;database management systems;program debugging;project management;query processing;software maintenance;system monitoring;Mozilla;Release History Database;bug tracking systems;database population;historical information;large open source project;merge points;software evolution;version control;Application software;Computer errors;Control systems;Data engineering;Databases;History;Information analysis;Open source software;Systems engineering and theory;Technological innovation}
}

@InProceedings{6686063,
  Title                    = {The Role of Emotions in Contributors Activity: A Case Study on the GENTOO Community},
  Author                   = {D. Garcia and M. S. Zanetti and F. Schweitzer},
  Booktitle                = {Cloud and Green Computing (CGC), 2013 Third International Conference on},
  Year                     = {2013},
  Month                    = {Sept},
  Pages                    = {410-417},

  Abstract                 = {We analyze the relation between the emotions and the activity of contributors in the Open Source Software project GENTOO. Our case study builds on extensive data sets from the project's bug tracking platform BUGZILLA, to quantify the activity of contributors, and its mail archives, to quantify the emotions of contributors by means of sentiment analysis. The GENTOO project is known for a period of centralization within its bug triaging community. This was followed by considerable changes in community organization and performance after the sudden retirement of the central contributor. We analyze how this event correlates with the negative emotions, both in bilateral email discussions with the central contributor, and at the level of the whole community of contributors. We then extend our study to consider the activity patterns of GENTOO contributors in general. We find that contributors are more likely to become inactive when they express strong positive or negative emotions in the bug tracker, or when they deviate from the expected value of emotions in the mailing list. We use these insights to develop a Bayesian classifier that detects the risk of contributors leaving the project. Our analysis opens new perspectives for measuring online contributor motivation by means of sentiment analysis and for real-time predictions of contributor turnover in Open Source Software projects.},
  Doi                      = {10.1109/CGC.2013.71},
  Keywords                 = {human factors;program debugging;public domain software;BUGZILLA project bug tracking platform;Bayesian classifier;GENTOO community;bilateral email discussions;bug triaging community;contributor activity;online contributor motivation;open source software project;sentiment analysis;Communities;Media;Open source software;Organizations;Psychology;Social network services;activity;machine learning;motivation;open source;sentiment analysis;turnover}
}

@InProceedings{5463340,
  Title                    = {Identifying security bug reports via text mining: An industrial case study},
  Author                   = {M. Gegick and P. Rotella and T. Xie},
  Booktitle                = {2010 7th IEEE Working Conference on Mining Software Repositories (MSR 2010)},
  Year                     = {2010},
  Month                    = {May},
  Pages                    = {11-20},

  Abstract                 = {A bug-tracking system such as Bugzilla contains bug reports (BRs) collected from various sources such as development teams, testing teams, and end users. When bug reporters submit bug reports to a bug-tracking system, the bug reporters need to label the bug reports as security bug reports (SBRs) or not, to indicate whether the involved bugs are security problems. These SBRs generally deserve higher priority in bug fixing than not-security bug reports (NSBRs). However, in the bug-reporting process, bug reporters often mislabel SBRs as NSBRs partly due to lack of security domain knowledge. This mislabeling could cause serious damage to software-system stakeholders due to the induced delay of identifying and fixing the involved security bugs. To address this important issue, we developed a new approach that applies text mining on natural-language descriptions of BRs to train a statistical model on already manually-labeled BRs to identify SBRs that are manually-mislabeled as NSBRs. Security engineers can use the model to automate the classification of BRs from large bug databases to reduce the time that they spend on searching for SBRs. We evaluated the model's predictions on a large Cisco software system with over ten million source lines of code. Among a sample of BRs that Cisco bug reporters manually labeled as NSBRs in bug reporting, our model successfully classified a high percentage (78%) of the SBRs as verified by Cisco security engineers, and predicted their classification as SBRs with a probability of at least 0.98.},
  Doi                      = {10.1109/MSR.2010.5463340},
  ISSN                     = {2160-1852},
  Keywords                 = {Computer bugs;Data engineering;Data security;Databases;Delay;Mining industry;Predictive models;Software systems;System testing;Text mining}
}

@InProceedings{5959723,
  Title                    = {SOFAS: A Lightweight Architecture for Software Analysis as a Service},
  Author                   = {G. Ghezzi and H. C. Gall},
  Booktitle                = {Software Architecture (WICSA), 2011 9th Working IEEE/IFIP Conference on},
  Year                     = {2011},
  Month                    = {June},
  Pages                    = {93-102},

  Abstract                 = {Access to data stored in software repositories by systems such as version control, bug and issue tracking, or mailing lists is essential for assessing the quality of a software system. A myriad of analyses exploiting that data have been proposed throughout the years: source code analysis, code duplication analysis, co-change analysis, bug prediction, or detection of bug fixing patterns. However, easy and straight forward synergies between these analyses rarely exist. To tackle this problem we have developed SOFAS, a distributed and collaborative software analysis platform to enable a seamless interoperation of such analyses. In particular, software analyses are offered as Restful web services that can be accessed and composed over the Internet. SOFAS services are accessible through a software analysis catalog where any project stakeholder can, depending on the needs or interests, pick specific analyses, combine them, let them run remotely and then fetch the final results. That way, software developers, testers, architects, or quality assurance experts are given access to quality analysis services. They are shielded from many peculiarities of tool installations and configurations, but SOFAS offers them sophisticated and easy-to-use analyses. This paper describes in detail our SOFAS architecture, its considerations and implementation aspects, and the current set of implemented and offered Restful analysis services.},
  Doi                      = {10.1109/WICSA.2011.21},
  Keywords                 = {Web services;groupware;information retrieval;program testing;service-oriented architecture;software quality;Internet;RESTful Web service;SOFAS;bug fixing pattern;bug prediction;cochange analysis;code duplication analysis;collaborative software analysis platform;data access;issue tracking;lightweight architecture;mailing list;quality analysis service;quality assurance expert;software analysis as a service;software developer;software repository;source code analysis;version control;Computer architecture;Couplings;History;Measurement;Ontologies;Software;Web services}
}

@InProceedings{7180122,
  Title                    = {The MetricsGrimoire Database Collection},
  Author                   = {J. M. Gonzalez-Barahona and G. Robles and D. Izquierdo-Cortazar},
  Booktitle                = {2015 IEEE/ACM 12th Working Conference on Mining Software Repositories},
  Year                     = {2015},
  Month                    = {May},
  Pages                    = {478-481},

  Abstract                 = {The Metrics Grimoire system is composed by a set of tools designed to retrieve data from repositories related to software development. Their aim is to produce organized databases suitable for easy querying with research and industrial purposes. The data in those databases have a similar structure, to easy cross-database studies, and can be enriched with information such as linkage of the multiple identities of actors, or their affiliation. This paper presents the general structure of those databases, and a collection of up-to-date database dumps that are publicly available. They correspond to two well-known projects, Open Stack, and Eclipse, including data from source code management repositories, issue tracking systems, mailing lists, and code review systems.},
  Doi                      = {10.1109/MSR.2015.68},
  ISSN                     = {2160-1852},
  Keywords                 = {database management systems;software engineering;Eclipse;Open Stack;metrics grimoire database collection;software development;source code management repositories;up-to-date database;Companies;Databases;Merging;Open source software;Standards organizations}
}

@InProceedings{6624039,
  Title                    = {Communication in open source software development mailing lists},
  Author                   = {A. Guzzi and A. Bacchelli and M. Lanza and M. Pinzger and A. van Deursen},
  Booktitle                = {Mining Software Repositories (MSR), 2013 10th IEEE Working Conference on},
  Year                     = {2013},
  Month                    = {May},
  Pages                    = {277-286},

  Abstract                 = {Open source software (OSS) development teams use electronic means, such as emails, instant messaging, or forums, to conduct open and public discussions. Researchers investigated mailing lists considering them as a hub for project communication. Prior work focused on specific aspects of emails, for example the handling of patches, traceability concerns, or social networks. This led to insights pertaining to the investigated aspects, but not to a comprehensive view of what developers communicate about. Our objective is to increase the understanding of development mailing lists communication. We quantitatively and qualitatively analyzed a sample of 506 email threads from the development mailing list of a major OSS project, Lucene. Our investigation reveals that implementation details are discussed only in about 35% of the threads, and that a range of other topics is discussed. Moreover, core developers participate in less than 75% of the threads. We observed that the development mailing list is not the main player in OSS project communication, as it also includes other channels such as the issue repository.},
  Doi                      = {10.1109/MSR.2013.6624039},
  ISSN                     = {2160-1852},
  Keywords                 = {project management;public domain software;software engineering;software management;Lucene;OSS project communication;development mailing lists communication;email threads;open source software development mailing lists;Buildings;Data mining;Electronic mail;Linux;Software;Sorting}
}

@InProceedings{7180127,
  Title                    = {The Firefox Temporal Defect Dataset},
  Author                   = {M. Habayeb and A. Miranskyy and S. S. Murtaza and L. Buchanan and A. Bener},
  Booktitle                = {2015 IEEE/ACM 12th Working Conference on Mining Software Repositories},
  Year                     = {2015},
  Month                    = {May},
  Pages                    = {498-501},

  Abstract                 = {The bug tracking repositories of software projects capture initial defect (bug) reports and the history of interactions among developers, testers, and customers. Extracting and mining information from these repositories is time consuming and daunting. Researchers have focused mostly on analyzing the frequency of the occurrence of defects and their attributes (e.g., The number of comments and lines of code changed, count of developers). However, the counting process eliminates information about the temporal alignment of events leading to changes in the attributes count. Software quality teams could plan and prioritize their work more efficiently if they were aware of these temporal sequences and knew their frequency of occurrence. In this paper, we introduce a novel dataset mined from the Fire fox bug repository (Bugzilla) which contains information about the temporal alignment of developer interactions. Our dataset covers eight years of data from the Fire fox project on activities throughout the project's lifecycle. Some of these activities have not been reported in frequency-based or other temporal datasets. The dataset we mined from the Fire fox project contains new activities, such as reporter experience, file exchange events, code-review process activities, and setting of milestones. We believe that this new dataset will improve analysis of bug reports and enable mining of temporal relationships so that practitioners can enhance their bug-fixing process.},
  Doi                      = {10.1109/MSR.2015.73},
  ISSN                     = {2160-1852},
  Keywords                 = {data mining;program debugging;project management;search engines;Bugzilla;Firefox bug repository;Firefox temporal defect dataset;attribute count;bug report analysis improvement;bug tracking repositories;bug-fixing process;code lines;code-review process activities;defect attributes;defect occurrence;developer count;developer interactions;file exchange events;frequency analysis;frequency-based activities;information extraction;information mining;occurrence frequency;project lifecycle;reporter experience;software projects;software quality teams;temporal datasets;temporal event alignment;temporal relationship mining;temporal sequences;Communities;Computer bugs;Data mining;Feature extraction;History;Software;Software engineering;Bug reports;Bug repositories;Dataset;Defect tracking;Temporal activities}
}

@InProceedings{6861074,
  Title                    = {Heterogeneous models matching for consistency management},
  Author                   = {M. El Hamlaoui and S. Ebersold and B. Coulette and M. Nassar and A. Anwar},
  Booktitle                = {2014 IEEE Eighth International Conference on Research Challenges in Information Science (RCIS)},
  Year                     = {2014},
  Month                    = {May},
  Pages                    = {1-12},

  Abstract                 = {This work is situated in the context of the application of Model Driven Engineering to complex systems view-based modelling. In fact, view-based models - called also partial models - are manipulated by different actors (designers), and are thus generally heterogeneous, that is, described with different DSLs (Domain Specific Languages). Instead of building a single global model, which is not realistic, we propose to organize the different partial models as a network of related models, which provides a global view of the system through a correspondence model. As models are modelled separately by different designers, they also evolve separately that induces a problem of consistency. To solve it, we propose a semi-automatic process based on the correspondence model allowing detecting changes, calculating their impacts, and proposing modifications to maintain the consistency among them. The approach is supported by a tool chain and illustrated by the example of a Bug Tracking System.},
  Doi                      = {10.1109/RCIS.2014.6861074},
  ISSN                     = {2151-1349},
  Keywords                 = {software engineering;Domain Specific Languages;consistency management;correspondence model;heterogeneous model matching;model driven engineering;Abstracts;Adaptation models;Analytical models;Business;DSL;Information systems;Unified modeling language;Heterogeneous models;change processing;consistency;correspondence model}
}

@InProceedings{6178935,
  Title                    = {Bug Maps: A Tool for the Visual Exploration and Analysis of Bugs},
  Author                   = {A. Hora and N. Anquetil and S. Ducasse and M. Bhatti and C. Couto and M. T. Valente and J. Martins},
  Booktitle                = {Software Maintenance and Reengineering (CSMR), 2012 16th European Conference on},
  Year                     = {2012},
  Month                    = {March},
  Pages                    = {523-526},

  Abstract                 = {To harness the complexity of big legacy software, software engineering tools need more and more information on these systems. This information may come from analysis of the source code, study of execution traces, computing of metrics, etc. One source of information received less attention than source code: the bugs on the system. Little is known about the evolutionary behavior, lifetime, distribution, and stability of bugs. In this paper, we propose to consider bugs as first class entities and a useful source of information that can answer such topics. Such analysis is inherently complex, because bugs are intangible, invisible, and difficult to be traced. Therefore, our tool extracts information about bugs from bug tracking systems, link this information to other software artifacts, and explore interactive visualizations of bugs that we call bug maps.},
  Doi                      = {10.1109/CSMR.2012.68},
  ISSN                     = {1534-5351},
  Keywords                 = {evolutionary computation;information resources;program debugging;program testing;software maintenance;bug maps;bug tracking system;bugs analysis;bugs stability;evolutionary behavior;information source;interactive bugs visualization;legacy software;software artifact;software engineering tools;source code;visual exploration;Browsers;Color;Computer bugs;History;Measurement;Software;Visualization}
}

@InProceedings{7081860,
  Title                    = {GiLA: GitHub label analyzer},
  Author                   = {J. L. C. Izquierdo and V. Cosentino and B. Rolandi and A. Bergel and J. Cabot},
  Booktitle                = {2015 IEEE 22nd International Conference on Software Analysis, Evolution, and Reengineering (SANER)},
  Year                     = {2015},
  Month                    = {March},
  Pages                    = {479-483},

  Abstract                 = {Reporting bugs, asking for new features and in general giving any kind of feedback is a common way to contribute to an Open-Source Software (OSS) project. In GitHub, the largest code hosting service for OSS, this feedback is typically expressed as new issues for the project managed by an issue-tracking system available in each new project repository. Among other features, the issue tracker allows creating and assigning labels to issues with the goal of helping the project community to better classify and manage those issues (e.g., facilitating the identification of issues for top priority components or candidate developers that could solve them). Nevertheless, as the project grows a manual browsing of the project issues is no longer feasible. In this paper we present GiLA, a tool which generates a set of visualizations to facilitate the analysis of issues in a project depending on their label-based categorization. We believe our visualizations are useful to see the most popular labels (and their relationships) in a project, identify the most active community members for those labels and compare the typical issue evolution for each label category.},
  Doi                      = {10.1109/SANER.2015.7081860},
  ISSN                     = {1534-5351},
  Keywords                 = {program visualisation;project management;public domain software;software development management;source code (software);GiLA;GitHub label analyzer;OSS project;active community members;code hosting service;issue tracker;issue-tracking system;label-based categorization;open-source software project;project community;project management;project repository;visualizations;Communities;Computer architecture;Databases;Servers;Visualization;Web services}
}

@InProceedings{4630070,
  Title                    = {Automated duplicate detection for bug tracking systems},
  Author                   = {N. Jalbert and W. Weimer},
  Booktitle                = {2008 IEEE International Conference on Dependable Systems and Networks With FTCS and DCC (DSN)},
  Year                     = {2008},
  Month                    = {June},
  Pages                    = {52-61},

  Abstract                 = {Bug tracking systems are important tools that guide the maintenance activities of software developers. The utility of these systems is hampered by an excessive number of duplicate bug reports-in some projects as many as a quarter of all reports are duplicates. Developers must manually identify duplicate bug reports, but this identification process is time-consuming and exacerbates the already high cost of software maintenance. We propose a system that automatically classifies duplicate bug reports as they arrive to save developer time. This system uses surface features, textual semantics, and graph clustering to predict duplicate status. Using a dataset of 29,000 bug reports from the Mozilla project, we perform experiments that include a simulation of a real-time bug reporting environment. Our system is able to reduce development cost by filtering out 8% of duplicate bug reports while allowing at least one report for each real defect to reach developers.},
  Doi                      = {10.1109/DSN.2008.4630070},
  ISSN                     = {1530-0889},
  Keywords                 = {graph theory;pattern classification;pattern clustering;program debugging;software maintenance;software tools;tracking;automated duplicate bug report detection;graph clustering;software bug tracking system;software development maintenance activity;surface feature;textual semantics;Computer bugs;Costs;Filtering;Open source software;Operating systems;Software maintenance;Software quality;Software systems;Software tools;Spatial databases}
}

@Article{1238707,
  Title                    = {Issue tracking},
  Author                   = {J. N. Johnson and P. F. Dubois},
  Journal                  = {Computing in Science Engineering},
  Year                     = {2003},

  Month                    = {Nov},
  Number                   = {6},
  Pages                    = {71-77},
  Volume                   = {5},

  Abstract                 = {All programming projects have one thing in common: there is always more to do. Some things that need doing are bug fixes; others are enhancements such as cleaning up and refactorlng existing code, adding tests, and writing documentation. but before your office wall becomes a collage of sticky-note reminders, you might want to try an issue tracker instead. In this article, we describe two open-source issue-tracking software packages: Roundup, an implementation of the winning design in Los Alamos National Laboratory's Software Carpentry contest and Bugzilla (from the GNU project).},
  Doi                      = {10.1109/MCISE.2003.1238707},
  ISSN                     = {1521-9615},
  Keywords                 = {client-server systems;public domain software;software packages;Bugzilla;GNU project;Los Alamos National Laboratory;Roundup;Software Carpentry contest;issue tracker;open-source issue tracking;programming projects;software packages}
}

@InProceedings{4639063,
  Title                    = {Towards the next generation of bug tracking systems},
  Author                   = {S. Just and R. Premraj and T. Zimmermann},
  Booktitle                = {2008 IEEE Symposium on Visual Languages and Human-Centric Computing},
  Year                     = {2008},
  Month                    = {Sept},
  Pages                    = {82-85},

  Abstract                 = {Developers typically rely on the information submitted by end-users to resolve bugs. We conducted a survey on information needs and commonly faced problems with bug reporting among several hundred developers and users of the APACHE, ECLIPSE and MOZILLA projects. In this paper, we present the results of a card sort on the 175 comments sent back to us by the responders of the survey. The card sort revealed several hurdles involved in reporting and resolving bugs, which we present in a collection of recommendations for the design of new bug tracking systems. Such systems could provide contextual assistance, reminders to add information, and most important, assistance to collect and report crucial information to developers.},
  Doi                      = {10.1109/VLHCC.2008.4639063},
  ISSN                     = {1943-6092},
  Keywords                 = {program debugging;systems analysis;tracking;APACHE project;ECLIPSE project;MOZILLA project;bug tracking systems;card sort;next generation;Cognitive science;Communication system software;Computer bugs;Feedback;Information analysis;Sorting;Spatial databases;Taxonomy;Testing}
}

@InProceedings{6178863,
  Title                    = {A Comparative Study of the Performance of IR Models on Duplicate Bug Detection},
  Author                   = {N. Kaushik and L. Tahvildari},
  Booktitle                = {Software Maintenance and Reengineering (CSMR), 2012 16th European Conference on},
  Year                     = {2012},
  Month                    = {March},
  Pages                    = {159-168},

  Abstract                 = {Open source projects incorporate bug triagers to help with the task of bug report assignment to developers. One of the tasks of a triager is to identify whether an incoming bug report is a duplicate of a pre-existing report. In order to detect duplicate bug reports, a triager either relies on his memory and experience or on the search capabilities of the bug repository. Both these approaches can be time consuming for the triager and may also lead to the misidentification of duplicates. In the literature, several approaches to automate duplicate bug report detection have been proposed. However, there has not been an exhaustive comparison of the performance of different IR models, especially with topic-based ones such as LSI and LDA. In this paper, we compare the performance of the traditional vector space model (using different weighting schemes) with that of topic based models, leveraging heuristics that incorporate exception stack frames, surface features, summary and long description from the free-form text in the bug report. We perform experiments on subsets of bug reports from Eclipse and Firefox and achieve a recall rate of 60% and 58% respectively. We find that word-based models, in particular a Log-Entropy based weighting scheme, outperform topic based ones such as LSI, LDA and Random Projections. Our findings also suggests that for the problem of duplicate bug detection, it is important to consider a project's domain and characteristics to devise a set of heuristics to achieve optimal results.},
  Doi                      = {10.1109/CSMR.2012.78},
  ISSN                     = {1534-5351},
  Keywords                 = {information retrieval;program debugging;public domain software;report generators;Eclipse;Firefox;IR models;LDA;LSI;Log-Entropy based weighting scheme;bug report assignment;bug repository;bug triagers;duplicate bug detection;duplicate bug report detection automation;free-form text;open source projects;random projections;topic based models;vector space model;word-based models;Computer bugs;Entropy;Fires;Large scale integration;Software;Synchronization;Vectors;bug;duplicate;information retrieval}
}

@InProceedings{6224296,
  Title                    = {A Linked Data platform for mining software repositories},
  Author                   = {I. Keivanloo and C. Forbes and A. Hmood and M. Erfani and C. Neal and G. Peristerakis and J. Rilling},
  Booktitle                = {Mining Software Repositories (MSR), 2012 9th IEEE Working Conference on},
  Year                     = {2012},
  Month                    = {June},
  Pages                    = {32-35},

  Abstract                 = {The mining of software repositories involves the extraction of both basic and value-added information from existing software repositories. The repositories will be mined to extract facts by different stakeholders (e.g. researchers, managers) and for various purposes. To avoid unnecessary pre-processing and analysis steps, sharing and integration of both basic and value-added facts are needed. In this research, we introduce SeCold, an open and collaborative platform for sharing software datasets. SeCold provides the first online software ecosystem Linked Data platform that supports data extraction and on-the-fly inter-dataset integration from major version control, issue tracking, and quality evaluation systems. In its first release, the dataset contains about two billion facts, such as source code statements, software licenses, and code clones from 18 000 software projects. In its second release the SeCold project will contain additional facts mined from issue trackers and versioning systems. Our approach is based on the same fundamental principle as Wikipedia: researchers and tool developers share analysis results obtained from their tools by publishing them as part of the SeCold portal and therefore make them an integrated part of the global knowledge domain. The SeCold project is an official member of the Linked Data dataset cloud and is currently the eighth largest online dataset available on the Web.},
  Doi                      = {10.1109/MSR.2012.6224296},
  ISSN                     = {2160-1852},
  Keywords                 = {data mining;software packages;code clones;collaborative platform;linked data platform;mining software repositories;on-the-fly inter-dataset integration;online software ecosystem linked data platform;software datasets;software licenses;software packages;software repositories;source code statements;value added information;Cloning;Communities;Data mining;Encyclopedias;Licenses;Ontologies;Software;Linked Data;fact sharing;software mining}
}

@InProceedings{5431740,
  Title                    = {An Open Source-Based Approach to Software Development Infrastructures},
  Author                   = {Y. Ki and M. Song},
  Booktitle                = {Automated Software Engineering, 2009. ASE '09. 24th IEEE/ACM International Conference on},
  Year                     = {2009},
  Month                    = {Nov},
  Pages                    = {525-529},

  Abstract                 = {As software systems become larger and more complex, automated software engineering tools play a crucial role for effective software development management, which is a key factor to lead quality software systems. In this work, we present TRICA, an open source-based software development infrastructure. The name of TRICA represents its features such as Traceability, Relationship, Informativeness, Cost-effectiveness, and Automation. Essentially, in TRICA, a continuous integration tool is coupled with a software configuration management tool and an issue tracking tool. We provisioned a mechanism to connect the open source tools in TRICA so that project members use the collaborated information to solve various issues and implementation problems efficiently, and easily share forthcoming issues during the course of the project. We show that TRICA can help to decentralize risks throughout the software development cycle and achieve successful software development.},
  Doi                      = {10.1109/ASE.2009.73},
  ISSN                     = {1938-4300},
  Keywords                 = {configuration management;groupware;integrated software;program diagnostics;public domain software;software development management;software quality;software tools;TRICA;automated software engineering tools;collaborated information;continuous integration tool;open source tools;software configuration management tool;software development cycle;software development management;software quality;software systems;tracking tool;Automation;Collaborative software;Collaborative tools;Open source software;Programming;Software development management;Software engineering;Software systems;Software tools;Testing;SCM;continuous integration;issue tracking;open source;software engineering tools}
}

@InProceedings{5306384,
  Title                    = {Interactive views for analyzing problem reports},
  Author                   = {P. Knab and B. Fluri and H. C. Gall and M. Pinzger},
  Booktitle                = {Software Maintenance, 2009. ICSM 2009. IEEE International Conference on},
  Year                     = {2009},
  Month                    = {Sept},
  Pages                    = {527-530},

  Abstract                 = {Issue tracking repositories contain a wealth of information for reasoning about various aspects of software development processes. In this paper, we focus on bug triaging and provide visual means to explore the effort estimation quality and the bug life-cycle of reported problems. Our approach follows the micro/macro reading technique and uses a combination of graphical views to investigate details of individual problem reports while maintaining the context provided by the surrounding data population. This enables the detection and detailed analysis of hidden patterns and facilitates the analysis of problem report outliers. In an industrial study, we use our approach in various problem report analysis scenarios and answer questions related to effort estimation and resource planning.},
  Doi                      = {10.1109/ICSM.2009.5306384},
  ISSN                     = {1063-6773},
  Keywords                 = {data visualisation;program debugging;bug life-cycle;bug triaging;macroreading technique;microreading technique;problem report;software development;Life estimation;Pattern analysis;Programming}
}

@InProceedings{6345811,
  Title                    = {Detecting and classifying patterns of requirements clarifications},
  Author                   = {E. Knauss and D. Damian and G. Poo-Caamaño and J. Cleland-Huang},
  Booktitle                = {2012 20th IEEE International Requirements Engineering Conference (RE)},
  Year                     = {2012},
  Month                    = {Sept},
  Pages                    = {251-260},

  Abstract                 = {In current project environments, requirements often evolve throughout the project and are worked on by stakeholders in large and distributed teams. Such teams often use online tools such as mailing lists, bug tracking systems or online discussion forums to communicate, clarify or coordinate work on requirements. In this kind of environment, the expected evolution from initial idea, through clarification, to a stable requirement, often stagnates. When project managers are not aware of underlying problems, development may proceed before requirements are fully understood and stabilized, leading to numerous implementation issues and often resulting in the need for early redesign and modification. In this paper, we present an approach to analyzing online requirements communication and a method for the detection and classification of clarification events in requirement discussions. We used our approach to analyze online requirements communication in the IBM® Rational Team Concert® (RTC) project and identified a set of six clarification patterns. Since a predominant amount of clarifications through the lifetime of a requirement is often indicative of problematic requirements, our approach lends support to project managers to assess, in real-time, the state of discussions around a requirement and promptly react to requirements problems.},
  Doi                      = {10.1109/RE.2012.6345811},
  ISSN                     = {1090-705X},
  Keywords                 = {distributed processing;formal verification;pattern classification;project management;systems analysis;IBM® Rational Team Concert® project;RTC project;clarification event classification;clarification event detection;distributed teams;online requirement communication;project environments;project managers;requirement clarification pattern;Context;Manuals;Message systems;Natural languages;Software;Trajectory;Visualization;communication of requirements;distributed requirements engineering;requirements clarification patterns}
}

@InProceedings{6818309,
  Title                    = {SortingHat: A framework for deep matching between classes of entities},
  Author                   = {S. Kulkarni and S. Srinivasa and J. N. Khasnabish and K. Nagal and S. G. Kurdagi},
  Booktitle                = {Data Engineering Workshops (ICDEW), 2014 IEEE 30th International Conference on},
  Year                     = {2014},
  Month                    = {March},
  Pages                    = {90-93},

  Abstract                 = {This paper addresses the problem of “deep matching” - or matching different classes of entities based on latent underlying semantics, rather than just their visible attributes. An example of this is the “automatic task assignment” problem where several tasks have to be assigned to people with varied skill-sets and experiences. Datasets showing types of entities (tasks and people) along with their involvement of other concepts, are used as the basis for deep matching. This paper describes a work in progress, of a deep matching application called SortingHat. We analyze issue tracking data of a large corporation containing task descriptions and assignments to people that were computed manually. We identify several entities and concepts from the dataset and build a co-occurrence graph as the basic data structure for computing deep matches. We then propose a set of query primitives that can establish several forms of semantic matching across different classes of entities.},
  Doi                      = {10.1109/ICDEW.2014.6818309},
  Keywords                 = {data analysis;data structures;graph theory;pattern matching;SortingHat;automatic task assignment problem;co-occurrence graph;data structure;deep matching problem;entity classes;query primitives;semantic matching;tracking data analysis;visible attributes;Cities and towns;Conferences;Data mining;Information technology;Internet;Probability distribution;Semantics}
}

@InProceedings{6462705,
  Title                    = {Comparison of Seven Bug Report Types: A Case-Study of Google Chrome Browser Project},
  Author                   = {S. Lal and A. Sureka},
  Booktitle                = {2012 19th Asia-Pacific Software Engineering Conference},
  Year                     = {2012},
  Month                    = {Dec},
  Pages                    = {517-526},
  Volume                   = {1},

  Abstract                 = {Bug reports submitted to an issue tracking system can belong to different categories such as crash, regression, security, cleanup, polish, performance and usability. A deeper understanding of the properties and features of various categories of bug reports can have implications in improving software maintenance processes, tools and practices. We identify several metrics and characteristics serving as dimensions on which various types of bug reports can be compared. We perform a case-study on Google Chromium Browser open-source project and conduct a series of experiments to calculate various metrics. We present a characterization study comparing different types of bug reports on metrics such as: statistics on close-time, number of stars, number of comments, discriminatory and frequent words for each class, entropy across reporters, entropy across component, opening and closing trend, continuity and debugging efficiency performance characteristics. The calculated metrics shows the similarities and differences on various dimensions for seven different types of bug reports.},
  Doi                      = {10.1109/APSEC.2012.54},
  ISSN                     = {1530-1362},
  Keywords                 = {online front-ends;program debugging;software maintenance;software metrics;Google Chrome browser project;Google Chromium browser open-source project;bug report types;debugging efficiency performance characteristics;issue tracking system;software maintenance processes;software metrics;Computer bugs;Entropy;Google;Market research;Security;Usability;Issue Tracking Systems;Mining Bug Archives;Mining Software Repositories;Software Maintenance}
}

@InProceedings{5315994,
  Title                    = {An empirical study on bug assignment automation using Chinese bug data},
  Author                   = {Z. Lin and F. Shu and Y. Yang and C. Hu and Q. Wang},
  Booktitle                = {2009 3rd International Symposium on Empirical Software Engineering and Measurement},
  Year                     = {2009},
  Month                    = {Oct},
  Pages                    = {451-455},

  Abstract                 = {Bug assignment is an important step in bug life-cycle management. In large projects, this task would consume a substantial amount of human effort. To compare with the previous studies on automatic bug assignment in FOSS (free/open source software) projects, we conduct a case study on a proprietary software project in China. Our study consists of two experiments of automatic bug assignment, using Chinese text and the other non-text information of bug data respectively. Based on text data of the bug repository, the first experiment uses SVM to predict bug assignments and achieve accuracy close to that by human triagers. The second one explores the usefulness of non-text data in making such prediction. The main results from our study includes that text data are most useful data in the bug tracking system to triage bugs, and automation based on text data could effectively reduce the manual effort.},
  Doi                      = {10.1109/ESEM.2009.5315994},
  ISSN                     = {1949-3770},
  Keywords                 = {program debugging;public domain software;software maintenance;statistical analysis;support vector machines;text analysis;Chinese bug textual data;FOSS;SVM;automatic bug assignment;bug life-cycle management;bug repository;empirical study;free/open source software project;triage bug tracking system;Automation;Computer bugs;Data mining;Engineering management;Humans;Open source software;Software debugging;Software engineering;Software measurement;Support vector machines}
}

@InProceedings{4698909,
  Title                    = {Using Issue Tracking Tools to Facilitate Student Learning of Communication Skills in Software Engineering Courses},
  Author                   = {C. Liu},
  Booktitle                = {18th Conference on Software Engineering Education Training (CSEET'05)},
  Year                     = {2005},
  Month                    = {April},
  Pages                    = {61-68},

  Abstract                 = {When teaching communication and teamwork skills in software engineering courses, it is often difficult to relate the theories of communication as presented in communication textbooks to actual student interactions and team activities because the majority of student interactions and team activities take place outside the classroom. Through our experience in teaching communication theories in CS456/556, a software engineering course at Ohio University, we observed that when communication theories are delivered in traditional methods such as lectures without additional exercises designed for students to apply the theories, many students tend to treat them as an independent part of the course and continue to guide their behaviors in team activities with their old habits and preexisting intuitions. We found that issue tracking tools can help facilitate student learning of communication skills by forcing students to explicitly carry out effective steps recommended by communication theories and thus improve communications among students. Moreover, issue tracking tools also improve communications between the students and the instructor, and enable the instructor to be more aware of team status, detect team problems early on, and reply less on time-consuming and often inaccurate in-class team status reports},
  Doi                      = {10.1109/CSEET.2005.40},
  ISSN                     = {1093-0175},
  Keywords                 = {behavioural sciences;computer science education;educational courses;software engineering;teaching;team working;Ohio University;communication skills teaching;issue tracking tools;lectures;software engineering courses;student behavior;student exercises;student interactions;student learning;team activities;team problems;team status;teamwork skills teaching;Computer science;Education;Educational institutions;Feedback;Programming;Software design;Software engineering;Software tools;Teamwork;Unified modeling language}
}

@InProceedings{6899209,
  Title                    = {Faceted Bug Report Search with Topic Model},
  Author                   = {K. Liu and H. B. K. Tan},
  Booktitle                = {Computer Software and Applications Conference (COMPSAC), 2014 IEEE 38th Annual},
  Year                     = {2014},
  Month                    = {July},
  Pages                    = {123-128},

  Abstract                 = {During bug reporting, The same bugs could be repeatedly reported. As a result, extra time could be spent on bug triaging and fixing. In order to reduce redundant effort, it is important to provide bug reporters with the ability to search for previously reported bugs efficiently and accurately. The existing bug tracking systems are using relatively simple ranking functions, which often produce unsatisfactory results. In this paper, we apply Ranking SVM, a Learning to Rank technique to construct a ranking model for accurate bug report search. Based on the search results, a topic model is used to cluster the bug reports into multiple facets. Each facet contains similar bug reports of the same topic. Users and testers can locate relevant bugs more efficiently through a simple query. We perform evaluations on more than 16,340 Eclipse and Mozilla bug reports. The evaluation results show that the proposed approach can achieve better search results than the existing search functions.},
  Doi                      = {10.1109/COMPSAC.2014.19},
  Keywords                 = {learning (artificial intelligence);program debugging;search problems;support vector machines;Eclipse bug reports;Mozilla bug reports;bug tracking systems;faceted bug report search;learning;ranking SVM;simple ranking functions;topic model;Computational modeling;Databases;Feature extraction;Standards;Support vector machines;Training;Vectors;bug report search;clustering;faceted search;ranking SVM;topic model}
}

@InProceedings{6340250,
  Title                    = {A Source Code Recommender System to Support Newcomers},
  Author                   = {Y. Malheiros and A. Moraes and C. Trindade and S. Meira},
  Booktitle                = {2012 IEEE 36th Annual Computer Software and Applications Conference},
  Year                     = {2012},
  Month                    = {July},
  Pages                    = {19-24},

  Abstract                 = {Newcomers in a software development project often need assistance to complete their first tasks. Then a mentor, an experienced member of the team, usually teaches the newcomers what they need to complete their tasks. But, to allocate an experienced member of a team to teach a newcomer during a long time is neither always possible nor desirable, because the mentor could be more helpful doing more important tasks. During the development the team interacts with a version control system, bug tracking and mailing lists, and all these tools record data creating the project memory. Recommender systems can use the project memory to help newcomers in some tasks answering their questions, thus in some cases the developers do not need a mentor. In this paper we present Mentor, a recommender system to help newcomers to solve change requests. Mentor uses the Prediction by Partial Matching (PPM) algorithm and some heuristics to analyze the change requests, and the version control data, and recommend potentially relevant source code that will help the developer in the change request solution. We did three experiments to compare the PPM algorithm with the Latent Semantic Indexing (LSI). Using PPM we achieved results for recall rate between 37% and 66.8%, and using LSI the results were between 20.3% and 51.6%.},
  Doi                      = {10.1109/COMPSAC.2012.11},
  ISSN                     = {0730-3157},
  Keywords                 = {configuration management;indexing;pattern matching;program debugging;recommender systems;software maintenance;LSI;Mentor;PPM algorithm;bug tracking;experienced team member;latent semantic indexing;mailing lists;newcomers;prediction by partial matching algorithm;project memory;recommender system;software development project;source code recommender system;version control data;version control system;Context;Databases;Entropy;Large scale integration;Measurement;Recommender systems;Software;information theory;recommender systems;software engineering;software maintenance}
}

@InProceedings{6577739,
  Title                    = {A case study for understanding the organization of distributed problem-solving within the Mozilla's community: Poster paper},
  Author                   = {H. Masmoudi and I. Boughzala},
  Booktitle                = {IEEE 7th International Conference on Research Challenges in Information Science (RCIS)},
  Year                     = {2013},
  Month                    = {May},
  Pages                    = {1-2},

  Abstract                 = {There is a little understanding of distributed solving activities in Open Source communities. This study aimed to provide some insights in this way. It was applied to the context of Bugzilla, the bug tracking system of Mozilla community. This study investigated the organizational aspects of this meditated, complex and highly distributed context through a linguistic analysis method. The main finding of this research shows that the organization of distributed problem-solving activities in Bugzilla isn't based only on the hierarchical distribution of the work between core and periphery participants but on their implication in the interactions. This implication varies according to the status of each one participant in the community. That is why we distinguish their roles, as well as, the established modes to manage such activity.},
  Doi                      = {10.1109/RCIS.2013.6577739},
  ISSN                     = {2151-1349},
  Keywords                 = {distributed processing;program debugging;Bugzilla;Mozilla community;bug tracking system;distributed problem-solving;linguistic analysis method;open source community;Communities;Context;Focusing;Organizations;Pragmatics;Problem-solving;Software;Distributed resolution;Interaction;Language;Open Source Community;Organisation}
}

@InProceedings{7352679,
  Title                    = {The organization of distributed problem-solving networks: Examining how core and periphery interact together to solve problems in Mozilla's community},
  Author                   = {H. Masmoudi and V. Fernandez and L. Marrauld},
  Booktitle                = {Engineering, Technology and Innovation (ICE) IEEE International Technology Management Conference, 2013 International Conference on},
  Year                     = {2013},
  Month                    = {June},
  Pages                    = {1-10},

  Abstract                 = {The emerging empirical literature on Open Source communities indicates that a majority of code writing and communication activity is concentrated with a few contributors, the “core” (maintainers). However, these communities allow and encourage participation from anybody, the “periphery”. The focus of this work is on explaining how distributed communities solve software problems through the participation of a large number of participants. In particular, this paper investigates interaction, collaboration and division of labor between the core and periphery in a distributed problem-solving activity. Using a linguistic method of analysis, we study bugs that affected Firefox Internet browser as reflected in the discussions and actions reported in Bugzilla (the Mozilla's bug tracking system). As results, we find various categories in the modes of interaction between the core and periphery participants of the community and suggest that interactions are influenced by their status.},
  Doi                      = {10.1109/ITMC.2013.7352679},
  Keywords                 = {online front-ends;problem solving;program debugging;public domain software;Bugzilla;Firefox Internet browser;Mozilla community;distributed problem-solving activity;distributed problem-solving network;linguistic method;open source community;software problem;Computer bugs;Context;Measurement;Organizations;Pragmatics;Problem-solving;Software;Collaboration;Interaction;Open Source;Problem-Solving;lexical analysis}
}

@InProceedings{6354930,
  Title                    = {Design of Development as a Service in the Cloud},
  Author                   = {K. Matsumoto and S. Kibe and M. Uehara and H. Mori},
  Booktitle                = {2012 15th International Conference on Network-Based Information Systems},
  Year                     = {2012},
  Month                    = {Sept},
  Pages                    = {815-819},

  Abstract                 = {SaaS (Software as a Service) is software that provides the necessary service only when actually required. On the other hand, PaaS (Platform as a Service) is a platform where integrated software development is executed using the networked environment. SaaS for developers is supported by version control systems or forums. However, these services do not support deployment. Therefore, users need to use other services (like PaaS). We propose a development environment service, in which development and deployment are integrated. In this paper, we propose a development and deployment service in the Educational Cloud. The integrated system is referred to as Development as a Service (DEVaaS), which describes the system. This system currently supports a bug tracking system, continuous integration system, version control system, several well-known programming languages, an editor, and deployment environments in the cloud.},
  Doi                      = {10.1109/NBiS.2012.60},
  ISSN                     = {2157-0418},
  Keywords                 = {cloud computing;computer aided instruction;software engineering;DEVaaS;PaaS;SaaS;design;development as a service;educational cloud;integrated software development;platform as a service;software as a service;Computer languages;Control systems;Internet;Project management;Servers;Cloud;DEVaaS;Development;PaaS;SaaS}
}

@InProceedings{1607227,
  Title                    = {CoxR: open source development history search system},
  Author                   = {M. Matsushita and K. Sasaki and K. Inoue},
  Booktitle                = {12th Asia-Pacific Software Engineering Conference (APSEC'05)},
  Year                     = {2005},
  Month                    = {Dec},
  Pages                    = {6 pp.-},

  Abstract                 = {In typical open source software development, developers use revision control systems for product management, mailing list systems for human communications, and bug tracking systems for process management. All of these systems store development histories of the products that show significant information of problems during the development. However, it would be a hard job to retrieve useful information related to a current problem faced by developers. In this paper, we describe a software development supporting system CoxR that is capable of crawling the development histories. CoxR creates software development information Web which consists of developers, emails, and program deltas, and provides an interface to search, navigate, browse, and retrieve past development results. Through a case study, we confirmed that CoxR helps developers to solve their problems by making it easier to search development history.},
  Doi                      = {10.1109/APSEC.2005.56},
  ISSN                     = {1530-1362},
  Keywords                 = {public domain software;search engines;software engineering;CoxR;information retrieval;open source development history search system;software development supporting system;Communication system control;Control systems;Data mining;History;Information retrieval;Navigation;Open source software;Programming;Software development management;Technology management}
}

@InProceedings{7039122,
  Title                    = {Software defect prediction with Bug-Code analyzer - A data collection tool demo},
  Author                   = {G. Mauša and T. G. Grbac and B. D. Bašić},
  Booktitle                = {Software, Telecommunications and Computer Networks (SoftCOM), 2014 22nd International Conference on},
  Year                     = {2014},
  Month                    = {Sept},
  Pages                    = {425-426},

  Abstract                 = {Empirical software engineering research community aims to accumulate knowledge in software engineering community based on the empirical studies on datasets obtained from the real software projects. Limiting factor to building the theory over thus accumulated knowledge is often related to dataset bias. One solution to this problem is developing a systematic data collection procedure through standard guidelines that would be available to open community and thus enable reducing data collection bias. In this paper we present a tool demonstration that implements a systematic data collection procedure for software defect prediction datasets from the open source bug tracking and the source code management repositories. Main challenging issue that the tool addresses is linking the information related to the same entity (e.g. class file) from these two sources. The tool implements interfaces to bug and source code repositories and even other tools for calculating the software metrics. Finally, it offers the user to create software defect prediction datasets even if he is unaware of all the details behind this complex task.},
  Doi                      = {10.1109/SOFTCOM.2014.7039122},
  Keywords                 = {program debugging;program testing;public domain software;software metrics;source code (software);bug-code analyzer;class file;complex task;data collection bias reduction;data collection tool;empirical software engineering research community;open community;open source bug tracking;real software projects;software defect prediction datasets;software metrics;source code management repositories;standard guidelines;systematic data collection procedure;Communities;Computer bugs;Data collection;Joining processes;Measurement;Software;Software engineering;Automated Tool;Mining Software Repositories;Software Defect Prediction}
}

@Article{1259245,
  Title                    = {Automated bug tracking: the promise and the pitfalls},
  Author                   = {L. McLaughlin},
  Journal                  = {IEEE Software},
  Year                     = {2004},

  Month                    = {Jan},
  Number                   = {1},
  Pages                    = {100-103},
  Volume                   = {21},

  Abstract                 = {Bug tacking systems give developers a unique and clear view into user's everyday product experiences. Adding some statistical analysis and software teams can efficiently improve product quality. It's hard to tell precisely how well the error reporting system working, but this seems to be a bug weapon that has landed a permanent spot in microsoft's arsenal. Automated bug tracking, combined with statistical reporting, plays a key role for developers at the Mozilla Foundations, best known for its open source Web browser and email software. The sparse, random sampling approach produces enough data for the team to do what it call "statistical debugging"-bug detection through statistical analysis.},
  Doi                      = {10.1109/MS.2004.1259245},
  ISSN                     = {0740-7459},
  Keywords                 = {DP industry;data privacy;program debugging;software quality;software tools;statistical analysis;automated bug tracking system;data privacy;email software;open source Web browser;product experiences;product quality;statistical analysis;statistical debugging;statistical reporting}
}

@InProceedings{4658083,
  Title                    = {Automated severity assessment of software defect reports},
  Author                   = {T. Menzies and A. Marcus},
  Booktitle                = {Software Maintenance, 2008. ICSM 2008. IEEE International Conference on},
  Year                     = {2008},
  Month                    = {Sept},
  Pages                    = {346-355},

  Abstract                 = {In mission critical systems, such as those developed by NASA, it is very important that the test engineers properly recognize the severity of each issue they identify during testing. Proper severity assessment is essential for appropriate resource allocation and planning for fixing activities and additional testing. Severity assessment is strongly influenced by the experience of the test engineers and by the time they spend on each issue. The paper presents a new and automated method named SEVERIS (severity issue assessment), which assists the test engineer in assigning severity levels to defect reports. SEVERIS is based on standard text mining and machine learning techniques applied to existing sets of defect reports. A case study on using SEVERIS with data from NASApsilas Project and Issue Tracking System (PITS) is presented in the paper. The case study results indicate that SEVERIS is a good predictor for issue severity levels, while it is easy to use and efficient.},
  Doi                      = {10.1109/ICSM.2008.4658083},
  ISSN                     = {1063-6773},
  Keywords                 = {data mining;learning (artificial intelligence);resource allocation;software engineering;NASA;automated severity assessment;machine learning techniques;mission critical systems;resource allocation;severity issue assessment;software defect reports;text mining;Automatic testing;Computer bugs;Computer science;Costs;NASA;Personnel;Robots;Software testing;System testing;Text mining}
}

@InProceedings{6360068,
  Title                    = {Using RE knowledge to assist automatically during requirement specification},
  Author                   = {T. Merten and T. Schäfer and S. Bürsner},
  Booktitle                = {Requirements Engineering Education and Training (REET), 2012 IEEE 7th International Workshop on},
  Year                     = {2012},
  Month                    = {Sept},
  Pages                    = {9-13},

  Abstract                 = {In a two semester software engineering (SE) course at Bonn-Rhine-Sieg University students have the opportunity to actually elicit, analyze and document requirements as well as design and develop a correspondent software product in teams of approximately four. The students have to use an issue tracking software in combination with a Requirements Engineering (RE) tool to document and plan their work. Though the course starts with RE theory from elicitation via documentation and traceability, we found that the students find it difficult to combine different RE artifact types and to develop useful traces between them. In this paper we present an approach to provide feedback and give pro-active advice inside an RE tool, while the specification is created. To derive this feedback we use a knowledge base containing rules and best practices to create a requirements specification. An assistance system applies these rules to guide the user in different situations, beginning with an empty specification up to the implementation of various RE artifact types and traces between them. This paper presents the status of our knowledge-based feedback mechanism and possible extensions. In order to get primary indicators for the value of this approach we did experiments and workshops with eight students who worked with the same tool with and without the feedback system.},
  Doi                      = {10.1109/REET.2012.6360068},
  Keywords                 = {Cognition;Concrete;Documentation;Education;Knowledge based systems;Knowledge engineering;Software;RE;direct feedback;knowledge engineering;software-based feedback agents;teaching}
}

@InProceedings{6621378,
  Title                    = {Multi-layer QoS Monitoring in Private Clouds},
  Author                   = {O. Morariu and T. Borangiu and C. Morariu},
  Booktitle                = {2013 24th International Workshop on Database and Expert Systems Applications},
  Year                     = {2013},
  Month                    = {Aug},
  Pages                    = {236-240},

  Abstract                 = {Cloud computing represents at this point the standard delivery method for the infrastructure and platform of next generation applications. The emergence of a wide range of commercial cloud services have changed not only the way code is written and maintained, but also the way it is executed. Private clouds play an important role in this new service delivery model being designed to provide computing capacity within the organization premises either standalone or in a hybrid model. As resources of the private cloud are limited, QoS assurance becomes an important challenge. This paper presents the design of a monitoring solution that integrates several open source tools and can assure QoS for private clouds. The solution is implemented for IBM CloudBurst 2.1 and IBM TSAM product stack and can monitor a wide range of services, from CPU and memory load to J2EE services and HTTP statistics generate real time alerts and provide integration with a Jira based issue tracking tools. The overall solution provides a closed loop QoS system for private clouds that is able to prevent a large set of issues and provide real time diagnostic data for root cause analysis.},
  Doi                      = {10.1109/DEXA.2013.31},
  ISSN                     = {1529-4188},
  Keywords                 = {cloud computing;monitoring;program diagnostics;public domain software;quality of service;real-time systems;resource allocation;CPU;HTTP statistics;IBM CloudBurst 2.1;IBM TSAM product stack;J2EE services;Jira based issue tracking tools;QoS assurance;closed loop QoS system;cloud computing capacity;commercial cloud services;hybrid model;memory load;multilayer QoS monitoring;open source tools;private cloud resources;real time alerts;real time diagnostic data;root cause analysis;service delivery model;standard delivery method;Cloud computing;Instruction sets;Measurement;Monitoring;Quality of service;Real-time systems;IBM CloudBurst;diagnostic;private cloud;quality of service;real time monitoring;service monitoring}
}

@InProceedings{6623999,
  Title                    = {Bug report assignee recommendation using activity profiles},
  Author                   = {H. Naguib and N. Narayan and B. Brügge and D. Helal},
  Booktitle                = {Mining Software Repositories (MSR), 2013 10th IEEE Working Conference on},
  Year                     = {2013},
  Month                    = {May},
  Pages                    = {22-30},

  Abstract                 = {One question which frequently arises within the context of artifacts stored in a bug tracking repository is: “who should work on this bug report?” A number of approaches exist to semi-automatically identify and recommend developers, e.g. using machine learning techniques and social networking analysis. In this work, we propose a new approach for assignee recommendation leveraging user activities in a bug tracking repository. Within the bug tracking repository, an activity profile is created for each user from the history of all his activities (i.e. review, assign, and resolve). This profile, to some extent, indicates the user's role, expertise, and involvement in this project. These activities influence and contribute to the identification and ranking of suitable assignees. In order to evaluate our work, we apply it to bug reports of three different projects. Our results indicate that the proposed approach is able to achieve an average hit ratio of 88%. Comparing this result to the LDA-SVM - based assignee recommendation technique, it was found that the proposed approach performs better.},
  Doi                      = {10.1109/MSR.2013.6623999},
  ISSN                     = {2160-1852},
  Keywords                 = {program debugging;recommender systems;software engineering;average hit ratio;bug report assignee recommendation;bug report assignment;bug report resolving;bug report review;bug tracking repository;user activity profiles;user expertise;user involvement;user role;Data mining;Databases;Equations;History;Mathematical model;Open source software;Activity profile;assignee recommendation;bug report;bug tracking}
}

@InProceedings{6152388,
  Title                    = {Predicting expert developers for newly reported bugs using frequent terms similarities of bug attributes},
  Author                   = {N. K. Nagwani and S. Verma},
  Booktitle                = {2011 Ninth International Conference on ICT and Knowledge Engineering},
  Year                     = {2012},
  Month                    = {Jan},
  Pages                    = {113-117},

  Abstract                 = {A software bug repository not only contains the data about software bugs, but also contains the information about the contribution of developers, quality engineers (testers), managers and other team members. It contains the information about the efforts of team members involved in resolving the software bugs. This information can be analyzed to identify some useful knowledge patterns. One such pattern is identifying the developers, who can help in resolving the newly reported software bugs. In this paper a new algorithm is proposed to discover experts for resolving the newly assigned software bugs. The purpose of proposed algorithm is two fold. First is to identify the appropriate developers for newly reported bugs. And second is to find the expertise for newly reported bugs that can help other developers to fix these bugs if required. All the important information in software bug reports is of textual data types like bug summary, description etc. The algorithm is designed using the analysis of this textual information. Frequent terms are generated from this textual information and then term similarity is used to identify appropriate experts (developers) for the newly reported software bug.},
  Doi                      = {10.1109/ICTKE.2012.6152388},
  ISSN                     = {2157-0981},
  Keywords                 = {program debugging;bug attributes;bug summary;expert developers;frequent terms similarities;knowledge patterns;newly reported bugs;quality engineers;software bug repository;term similarity;textual data types;textual information;Computer bugs;Conferences;Data mining;Prediction algorithms;Software;Software algorithms;Vocabulary;Bug Mining;Expert Finding;Faster Bug Fixing;Software Bug Repositories}
}

@InProceedings{5422923,
  Title                    = {Predictive data mining model for software bug estimation using average weighted similarity},
  Author                   = {N. K. Nagwani and S. Verma},
  Booktitle                = {Advance Computing Conference (IACC), 2010 IEEE 2nd International},
  Year                     = {2010},
  Month                    = {Feb},
  Pages                    = {373-378},

  Abstract                 = {Software bug estimation is a very essential activity for effective and proper software project planning. All the software bug related data are kept in software bug repositories. Software bug (defect) repositories contains lot of useful information related to the development of a project. Data mining techniques can be applied on these repositories to discover useful interesting patterns. In this paper a prediction data mining technique is proposed to predict the software bug estimation from a software bug repository. A two step prediction model is proposed In the first step bug for which estimation is required, its summary and description is matched against the summary and description of bugs available in bug repositories. A weighted similarity model is suggested to match the summary and description for a pair of software bugs. In the second step the fix duration of all the similar bugs are calculated and stored and its average is calculated, which indicates the predicted estimation of a bug. The proposed model is implemented using open source technologies and is explained with the help of illustrative example.},
  Doi                      = {10.1109/IADCC.2010.5422923},
  Keywords                 = {data mining;public domain software;software libraries;average weighted similarity;open source technologies;predictive data mining model;software bug estimation;software bug repositories;software project planning;Computer bugs;Data mining;Open source software;Predictive models;Programming;Project management;Software development management;Software quality;Software testing;System testing;Bug estimation;Estimation Prediction;Software bug repositories;Weighted Similarity}
}

@InProceedings{6756268,
  Title                    = {Generating taxonomic terms for software bug classification by utilizing topic models based on Latent Dirichlet Allocation},
  Author                   = {N. K. Nagwani and S. Verma and K. K. Mehta},
  Booktitle                = {ICT and Knowledge Engineering (ICT KE), 2013 11th International Conference on},
  Year                     = {2013},
  Month                    = {Nov},
  Pages                    = {1-5},

  Abstract                 = {Discovering categorical (taxonomic) terms in text classification is an important and complex problem. Development of a good text classifier depends on the method of identification and generation of proper taxonomic terms. Software bug indicates improper behavior of the functionalities given during the requirements. These bugs are tracked with the help of bug tracking systems (BTS) where the bug information is presented using several attributes out of which some important attributes are textual for example summary and description. For effective classification of the software bugs a good text classifying mechanism is required for which proper taxonomic terms are required to be identified. In this work a methodology is presented to find the taxonomic terms using Latent Dirichlet Allocation (LDA) for software bug classification.},
  Doi                      = {10.1109/ICTKE.2013.6756268},
  ISSN                     = {2157-0981},
  Keywords                 = {classification;probability;program debugging;text analysis;LDA;bug tracking system;categorical terms;latent Dirichlet allocation;software bug classification;taxonomic term;text classification;topic model;Androids;Computer bugs;Conferences;Java;Mathematical model;Resource management;Software;Bug Tracking Systems;Latent Dirichlet Allocation;Software Bug Attributes;Software Bug Classification;Taxonomic Terms}
}

@InProceedings{7476690,
  Title                    = {BUMPER: A Tool for Coping with Natural Language Searches of Millions of Bugs and Fixes},
  Author                   = {M. Nayrolles and A. Hamou-Lhadj},
  Booktitle                = {2016 IEEE 23rd International Conference on Software Analysis, Evolution, and Reengineering (SANER)},
  Year                     = {2016},
  Month                    = {March},
  Pages                    = {649-652},
  Volume                   = {1},

  Abstract                 = {In recent years, mining bug report (BR) repositories has perhaps been one of the most active software engineering research fields. There exist many open source bug tracking and version control systems thatdevelopers and researchers can use to examine bug reports so as to reasonabout software quality. The issue is that these repositories use different interfaces and ways toaccess and represent data, which hinders productivity and reuse. To address this, we introduce BUMPER (BUg Metarepository for dEvelopersand Researchers), a common infrastructure for developers and researchersinterested in mining data from many (heterogeneous) repositories. BUMPER is an open source web-based environment that extracts informationfrom a variety of BR repositories and version control systems. It is equipped with a powerful search engine to help users rapidly querythe repositories using a single point of access. To demonstrate the effectiveness of BUMPER, we use it to build a largedataset from a variety of repositories. The dataset contains more thanone million bug reports and fixes. Both BUMPER and the dataset are publiclyavailable at https://bumper-app.com.},
  Doi                      = {10.1109/SANER.2016.71},
  Keywords                 = {Computer bugs;Control systems;Data mining;Indexes;Natural languages;Servers;Software}
}

@InProceedings{5645567,
  Title                    = {A Case Study of Bias in Bug-Fix Datasets},
  Author                   = {T. H. D. Nguyen and B. Adams and A. E. Hassan},
  Booktitle                = {2010 17th Working Conference on Reverse Engineering},
  Year                     = {2010},
  Month                    = {Oct},
  Pages                    = {259-268},

  Abstract                 = {Software quality researchers build software quality models by recovering traceability links between bug reports in issue tracking repositories and source code files. However, all too often the data stored in issue tracking repositories is not explicitly tagged or linked to source code. Researchers have to resort to heuristics to tag the data (e.g., to determine if an issue is a bug report or a work item), or to link a piece of code to a particular issue or bug. Recent studies by Bird et al. and by Antoniol et al. suggest that software models based on imperfect datasets with missing links to the code and incorrect tagging of issues, exhibit biases that compromise the validity and generality of the quality models built on top of the datasets. In this study, we verify the effects of such biases for a commercial project that enforces strict development guidelines and rules on the quality of the data in its issue tracking repository. Our results show that even in such a perfect setting, with a near-ideal dataset, biases do exist - leading us to conjecture that biases are more likely a symptom of the underlying software development process instead of being due to the used heuristics.},
  Doi                      = {10.1109/WCRE.2010.37},
  ISSN                     = {1095-1350},
  Keywords                 = {program debugging;program diagnostics;software quality;source coding;bug fix dataset;software development process;software quality model;software traceability;source code flies;Birds;Computer bugs;Couplings;Software engineering;Software quality;Tagging;bias;bug-fix;data quality;prediction;sample}
}

@InProceedings{7476092,
  Title                    = {Severity prediction of software bugs},
  Author                   = {A. F. Otoom and D. Al-Shdaifat and M. Hammad and E. E. Abdallah},
  Booktitle                = {2016 7th International Conference on Information and Communication Systems (ICICS)},
  Year                     = {2016},
  Month                    = {April},
  Pages                    = {92-95},

  Abstract                 = {We target the problem of identifying the severity of a bug report. Our main aim is to develop an intelligent system that is capable of predicting the severity of a newly submitted bug report through a bug tracking system. For this purpose, we build a dataset consisting of 59 features characterizing 163 instances that belong to two classes: severe and non-severe. We combine the proposed feature set with strong classification algorithms to assist in predicting the severity of bugs. Moreover, the proposed algorithms are integrated within a boosting algorithm for an enhanced performance. Our results show that the proposed technique has proved successful with a classification performance accuracy of more than 76% with the AdaBoost algorithm and cross validation test. Moreover, boosting has been effective in enhancing the performance of its base classifiers with improvements of up to 4.9%.},
  Doi                      = {10.1109/IACS.2016.7476092},
  Keywords                 = {Boosting;Classification algorithms;Computer bugs;Feature extraction;Radial basis function networks;Software;Vegetation;Adaboost;machine learning;severity predection;software bugs}
}

@InProceedings{7091211,
  Title                    = {What Community Contribution Pattern Says about Stability of Software Project?},
  Author                   = {A. Rastogi and A. Sureka},
  Booktitle                = {2014 21st Asia-Pacific Software Engineering Conference},
  Year                     = {2014},
  Month                    = {Dec},
  Pages                    = {31-34},
  Volume                   = {2},

  Abstract                 = {Free/Libre Open Source Software (FLOSS) community management is an important issue. Contributor churn (joining or leaving a project) causes failure of the majority of software projects. In this paper, we present a framework to characterize stability of the community in software maintenance projects by mining Issue Tracking System (ITS). We identify key stability indicators and propose metrics to measure them. We conduct time series analysis on metrics data to examine the stability of the community. We model community participation patterns and forecast future behavior to help plan and support informed decision making. We present a case study of four years data of Google Chromium Project and investigate the inferential ability of the framework.},
  Doi                      = {10.1109/APSEC.2014.88},
  ISSN                     = {1530-1362},
  Keywords                 = {project management;public domain software;software management;system recovery;FLOSS community management;Google chromium project;ITS;community contribution pattern;decision making;free-libre open source software;inferential ability;issue tracking system;key stability indicators;software maintenance projects;software project;time series analysis;Analytical models;Computational modeling;Data models;Market research;Measurement;Predictive models;Stability analysis;Developer Contribution Patterns;Issue Tracking System;Mining Software Repositories}
}

@InProceedings{6754373,
  Title                    = {SamikshaUmbra: Contribution and Performance Assessment of Software Maintenance Professionals by Mining Software Repositories},
  Author                   = {A. Rastogi and A. Sureka},
  Booktitle                = {2013 20th Asia-Pacific Software Engineering Conference (APSEC)},
  Year                     = {2013},
  Month                    = {Dec},
  Pages                    = {170-175},
  Volume                   = {2},

  Abstract                 = {Contribution and performance assessment is an established practice in organization with its sphere of influence spanning process, policy, people (client) and personnel (employee). Multiple roles in organization (for e.g. employees, project manager, hr manager etc.) view contribution and performance assessment with different perspectives and objectives. However, despite its ability to ensure growth and affluence of organization existing contribution and performance assessment practices are marred with flaws and imperfections. The objective of this work is to serve wide-ranged requirements of software maintenance professionals (in context of contribution and performance assessment) in organization by application of variegated approaches (tools, techniques, models etc.) on software repositories (Issue Tracking System, Version Control System, Source Code Repositories etc.). We study pain-points of practitioners (in context of contribution and performance assessment) and present solution approach by mining software repositories. We implement the approach on real-world data and gather insights from practitioners to validate and improve our research. In this paper, 'SamikshaUmbra' (research umbrella that circumscribe related research threads) we present approach to meet stated research objectives and viable research directions.},
  Doi                      = {10.1109/APSEC.2013.134},
  ISSN                     = {1530-1362},
  Keywords                 = {data mining;organisational aspects;research and development;software development management;software maintenance;SamikshaUmbra;contribution practice;issue tracking system;organization affluence;organization growth;performance assessment practice;related research threads;research directions;research objectives;research umbrella;software maintenance professionals;software repositories mining;source code repositories;version control system;Context;Data mining;Measurement;Organizations;Software maintenance;Standards organizations;Contribution and Performance Assessment;Mining Software Repositories;Software Maintenance Professionals}
}

@InProceedings{5770605,
  Title                    = {An Approach for Search Based Testing of Null Pointer Exceptions},
  Author                   = {D. Romano and M. Di Penta and G. Antoniol},
  Booktitle                = {2011 Fourth IEEE International Conference on Software Testing, Verification and Validation},
  Year                     = {2011},
  Month                    = {March},
  Pages                    = {160-169},

  Abstract                 = {Uncaught exceptions, and in particular null pointer exceptions (NPEs), constitute a major cause of crashes for software systems. Although tools for the static identification of potential NPEs exist, there is need for proper approaches able to identify system execution scenarios causing NPEs. This paper proposes a search-based test data generation approach aimed at automatically identify NPEs. The approach consists of two steps: (i) an inter-procedural data and control flow analysis - relying on existing technology - that identifies paths between input parameters and potential NPEs, and (ii) a genetic algorithm that evolves a population of test data with the aim of covering such paths. The algorithm is able to deal with complex inputs containing arbitrary data structures. The approach has been evaluated on to test class clusters from six Java open source systems, where NPE bugs have been artificially introduced. Results show that the approach is, indeed, able to identify the NPE bugs, and it outperforms random testing. Also, we show how the approach is able to identify real NPE bugs some of which are posted in the bug-tracking system of the Apache libraries.},
  Doi                      = {10.1109/ICST.2011.49},
  ISSN                     = {2159-4848},
  Keywords                 = {Java;data structures;genetic algorithms;program control structures;program debugging;program testing;public domain software;software libraries;system recovery;Apache library;Java open source system;NPE bug;bug-tracking system;control flow analysis;data structure;genetic algorithm;interprocedural data;null pointer exception;search based testing;search-based test data generation;software system crash;system execution;test class cluster;Gallium;Genetic algorithms;Instruments;Java;Libraries;Null value;Testing;Null pointer exceptions;Search-based testing}
}

@InProceedings{6650542,
  Title                    = {A closer look at bugs},
  Author                   = {T. Dal Sassc and M. Lanza},
  Booktitle                = {Software Visualization (VISSOFT), 2013 First IEEE Working Conference on},
  Year                     = {2013},
  Month                    = {Sept},
  Pages                    = {1-4},

  Abstract                 = {The evolution of non-trivial software systems is accompanied by unexpected behaviour and side-effects, referred as bugs or defects. These defects are reported to and stored in bug tracking systems, which contain descriptions of the problems that have been encountered. However, bug tracking systems store and present bug reports in textual form, which makes their understanding dispersive and unintuitive. We present an approach to display bug reports through a web-based visual analytics platform, named in*Bug. in*Bug allows users to navigate and inspect the vast information space created by bug tracking systems, with the goal of easing the comprehension of bug reports in detail and also obtain an understanding “in the large” of how bugs are reported with respect to one system or to an entire software ecosystem.},
  Doi                      = {10.1109/VISSOFT.2013.6650542},
  Keywords                 = {program debugging;software maintenance;tracking;Web-based visual analytics platform;bug reports;bug tracking systems;in*Bug;nontrivial software system evolution;software ecosystem;Computer bugs;Data visualization;Ecosystems;Joining processes;Software;Visual analytics}
}

@InProceedings{6747208,
  Title                    = {In * bug: Visual analytics of bug repositories},
  Author                   = {T. Dal Sasso and M. Lanza},
  Booktitle                = {Software Maintenance, Reengineering and Reverse Engineering (CSMR-WCRE), 2014 Software Evolution Week - IEEE Conference on},
  Year                     = {2014},
  Month                    = {Feb},
  Pages                    = {415-419},

  Abstract                 = {Bug tracking systems are used to track and store the defects reported during the life of software projects. The underlying repositories represent a valuable source of information used for example for defect prediction and program comprehension. However, bug tracking systems present the actual bugs essentially in textual form, which is not only cumbersome to navigate, but also hinders the understanding of the intricate pieces of information that revolve around software bugs. We present in*Bug, a web-based visual analytics platform to navigate and inspect bug repositories. in*Bug provides several interactive views to understand detailed information about the bugs and the people that report them. The tool can be downloaded at http://inbug.inf.usi.ch},
  Doi                      = {10.1109/CSMR-WCRE.2014.6747208},
  Keywords                 = {data visualisation;information storage;program debugging;software tools;Web-based visual analytics platform;bug repositories;bug tracking systems;defect prediction;in*Bug;information repositories;program comprehension;software bugs;software projects;Complexity theory;Computer bugs;Data visualization;Navigation;Software;Visual analytics}
}

@Article{1407819,
  Title                    = {Bugzilla, ITracker, and other bug trackers},
  Author                   = {N. Serrano and I. Ciordia},
  Journal                  = {IEEE Software},
  Year                     = {2005},

  Month                    = {March},
  Number                   = {2},
  Pages                    = {11-13},
  Volume                   = {22},

  Abstract                 = {Bug-tracking helps the software developers in knowing what the error is, resolving it, and learning from it. Working on a software project includes managing the bugs we find. At first, we might list them on a spreadsheet. But when the number of bugs becomes too large and a lot of people must access and input data on them, we have to give up the spreadsheet and instead use a bug- or issue-tracking system. Many software projects reach this point, especially during testing and deployment when users tend to find an application's bugs. Nowadays we can choose among dozens of bug-tracking systems. This paper looks at two specific open source products and provides useful hints for working with any bug-tracking tool.},
  Doi                      = {10.1109/MS.2005.32},
  ISSN                     = {0740-7459},
  Keywords                 = {program debugging;program diagnostics;program testing;public domain software;software tools;bug-tracking system;bug-tracking tool;open source product;program debugging;program diagnostics;program testing;Application software;Computer bugs;Control systems;Filters;Information systems;Linux;NASA;Open source software;Software tools;Spatial databases;bug database;bug tracker;issues database}
}

@InProceedings{6516342,
  Title                    = {Automatic Bug Assignment Using Information Extraction Methods},
  Author                   = {R. Shokripour and Z. M. Kasirun and S. Zamani and J. Anvik},
  Booktitle                = {Advanced Computer Science Applications and Technologies (ACSAT), 2012 International Conference on},
  Year                     = {2012},
  Month                    = {Nov},
  Pages                    = {144-149},

  Abstract                 = {The number of reported bugs in large open source projects is high and triaging these bugs is an important issue in software maintenance. As a step in the bug triaging process, assigning a new bug to the most appropriate developer to fix it, is not only a time-consuming and tedious task. The triager, the person who considers a bug and assigns it to a developer, also needs to be aware of developer activities at different parts of the project. It is clear that only a few developers have this ability to carry out this step of bug triaging. The main goal of this paper is to suggest a new approach to the process of performing automatic bug assignment. The information needed to select the best developers to fix a new bug report is extracted from the version control repository of the project. Unlike all the previous suggested approaches which used Machine Learning and Information Retrieval methods, this research employs the Information Extraction (IE) methods to extract the information from the software repositories. The proposed approach does not use the information of the bug repository to make decisions about bugs in order to obtain better results on projects which do not have many fixed bugs. The aim of this research is to recommend the actual fixers of the bugs. Using this approach, we achieved 62%, 43% and 41% accuracies on Eclipse, Mozilla and Gnome projects, respectively.},
  Doi                      = {10.1109/ACSAT.2012.56},
  Keywords                 = {information retrieval;program debugging;public domain software;software maintenance;Eclipse projects;Gnome projects;IE methods;Mozilla projects;automatic bug assignment;bug repository;bug triaging process;developer activity;fixed bugs;information extraction methods;information retrieval methods;machine learning;open source projects;reported bugs;software maintenance;software repository;tedious task;time-consuming task;version control repository;Bug Assignment;File Activity Histories;Information Extraction;Named Entity Recognition}
}

@InProceedings{5718358,
  Title                    = {Measuring Reliability Growth of Open Source Software by Applying Stochastic Differential Equations},
  Author                   = {V. B. Singh and P. K. Kapur and A. Tandon},
  Booktitle                = {Software Engineering (WCSE), 2010 Second World Congress on},
  Year                     = {2010},
  Month                    = {Dec},
  Pages                    = {115-118},
  Volume                   = {2},

  Abstract                 = {This, paper presents (i) several software reliability, growth models (SRGM) which tries to predict, quantitatively the failure, phenomena, in, an, Open, Source, Software, project over a period of time. Here, it is assumed that the number of failures during testing is dependent upon the number of instructions execution, (ii) in order to cater the, irregular state, of, bug-report, phenomena, on, the, bug tracking system and irregular fluctuation in terms of noise, the reliability models have been proposed by applying an Itô type Stochastic Differential Equations (SDE). We have demonstrated that proposed models can support management in building reliable software systems by predicting remaining bugs. We have also compared our proposed models with several existing models on the basis of different comparison criteria.},
  Doi                      = {10.1109/WCSE.2010.149},
  Keywords                 = {differential equations;public domain software;software reliability;bug report phenomena;open source software;software reliability growth model;software system;stochastic differential equation;support management;Data models;Mathematical model;Software;Software reliability;Stochastic processes;Testing}
}

@InProceedings{6062192,
  Title                    = {JDF: detecting duplicate bug reports in Jazz},
  Author                   = {Y. Song and X. Wang and T. Xie and L. Zhang and H. Mei},
  Booktitle                = {2010 ACM/IEEE 32nd International Conference on Software Engineering},
  Year                     = {2010},
  Month                    = {May},
  Pages                    = {315-316},
  Volume                   = {2},

  Abstract                 = {Both developers and users submit bug reports to a bug repository. These reports can help reveal defects and improve software quality. As the number of bug reports in a bug repository increases, the number of the potential duplicate bug reports increases. Detecting duplicate bug reports helps reduce development efforts in fixing defects. However, it is challenging to manually detect all potential duplicates because of the large number of existing bug reports. This paper presents JDF (representing Jazz Duplicate Finder), a tool that helps users to find potential duplicates of bug reports on Jazz, which is a team collaboration platform for software development and process management. JDF finds potential duplicates for a given bug report using natural language and execution information.},
  Doi                      = {10.1145/1810295.1810368},
  ISSN                     = {0270-5257},
  Keywords                 = {groupware;natural language processing;software development management;software quality;team working;JDF;bug reports;bug repository;execution information;natural language;process management;software development;software quality;team collaboration;Calculators;Computer architecture;Educational institutions;Measurement;Natural languages;Servers;Software;bug report;execution information;information retrieval}
}

@InProceedings{6759007,
  Title                    = {Forge++: The Changing Landscape of FLOSS Development},
  Author                   = {M. Squire},
  Booktitle                = {2014 47th Hawaii International Conference on System Sciences},
  Year                     = {2014},
  Month                    = {Jan},
  Pages                    = {3266-3275},

  Abstract                 = {Software forges are centralized online systems that provide useful tools to help distributed development teams work together, especially in free, libre, and open source software (FLOSS). Forge-provided tools may include web space, version control systems, mailing lists and communication forums, bug tracking systems, file downloads, wikis, and the like. Empirical software engineering researchers can mine the artifacts from these tools to better understand how FLOSS is made. As the landscape of distributed software development has grown and changed, the tools needed to make FLOSS have changed as well. There are three newer tools at the center of FLOSS development today: distributed version control based forges (like Github), programmer question-and-answer communities (like Stack Overflow), and paste bin tools (like Gist or Pastebin.com). These tools are extending and changing the toolset used for FLOSS development, and redefining what a software forge looks like. The main contributions of this paper are to describe each of these tools, to identify the data and artifacts available for mining from these tools, and to outline some of the ways researchers can use these artifacts to continue to understand how FLOSS is made.},
  Doi                      = {10.1109/HICSS.2014.405},
  ISSN                     = {1530-1605},
  Keywords                 = {Internet;data mining;distributed processing;public domain software;software engineering;software tools;team working;FLOSS development;Forge++;Gist;Github;Pastebin.com;Stack Overflow;centralized online systems;data mining;distributed development teams;distributed software development;distributed version control based forges;free-libre-open source software;pastebin tools;programmer question-and-answer communities;software forges;Communities;Computer languages;Control systems;Data mining;Google;Licenses;Software;forges;github;open source software;pastebin;repositories;software development;stack overflow}
}

@InProceedings{5783175,
  Title                    = {SaaS support in software documentation systems},
  Author                   = {E. Stepalina},
  Booktitle                = {Software Engineering Conference (CEE-SECR), 2010 6th Central and Eastern European},
  Year                     = {2010},
  Month                    = {Oct},
  Pages                    = {192-197},

  Abstract                 = {In recent days more and more software developments tools become distributed by the SaaS (Software-As-A Service) model alongside with ready-to-install products. The developers of task and bug tracking systems now offer their solutions by a monthly fee. For instance, JIRA Studio produced by Atlassian can be connected to a corporative domain by subscription. This scheme allows software companies to reduce costs at the project's start and get scalable resources in future. Software documentation systems can also be purchased by a subscription now. The effectiveness of their usage for various documentation development is interesting. There are four major types of documentation supporting the development process and resulted products: project, technical, code and user documentation. Each of this type claims specific requirements for the documentation tool. The requirement analysis shows that rented documentation systems are the most appropriate for user and technical documentation. There are two major classes of software documentation systems: 1) Wiki, 2) DITA-orientedXML CMS. The following wiki systems have a hosted version: commercial Confluence, Central Desktop, EditMe, Incentive, Netcipia, PBWiki, Wikia, Wikispaces; open source BusinessWiki, Metadot Wiki, MindTouch, Wagn, Wikidot. The richest by the functionality andplugin collection is Confluence produced by Atlassian. The following XML CMS are offered by a SaaS model (all are commercial): Astoria On Demand, DITA Exchange. DocZone. SaaS is optionally supported in Bluestream XDocs, Siberlogic SiberSafe, Trisoft Infoshare, Vasont, X-Hive Docato. As wiki system is a ready integrated environment for creating and publishing documentation, DITA-system consists not only of XML CMS. To deploy a DITA-system, you should have an XML editor, publisher and CMS. The listed CMS can be integrated with top DITA XML editors and provide an API to integrate with other editors. These CMS also have build-in tools to export documents in mu- - ltiple formats. However, the universal component architecture of DITA-systems makes the deployment and configuration more difficult than wiki implementation. Hosted documentation systems are offered by different prices. The offerings of top documentation systems are considered in this paper. Wiki subscription fees range from 4,95$ (EditMe) to 20$ (Confluence) per one user/month. XML CMS subscription price starts from 500$ per month and can reach 12000$ per month. These subscriptions have no fixed price; in each individual case the CMS vendor performs a specific project of a DITA-system implementation. Wiki rental costs approximate to CMS subscriptions' costs for large number of users, 500 and more. The advantages of renting a powerful documentation system for small and large project are the following: 1) Maximal functionality at a low affordable cost, 2) Platform independency and high system accessibility, 3) Document quality improvement at the expense of quality controlling tools application, 4) Higher effectiveness of documentation (content re-use, single source usage, automated tools for localization), 5) Organization of robust and scalable documentation process. As the SaaS business model becomes more popular, small companies get access to powerful software documentation systems, which are too expensive to purchase a standalone license at the startup. However, the system's access security, reliability and information confidentiality issues remain opened and controversial.},
  Doi                      = {10.1109/CEE-SECR.2010.5783175},
  Keywords                 = {Web sites;XML;cloud computing;document handling;software engineering;systems analysis;τasont;Astoria On Demand;Atlassian;Bluestream XDocs;Central Desktop;Confluence;DITA Exchange;DITA-orientedXML CMS;DocZone;EditMe;Incentive;JIRA Studio;Metadot Wiki;MindTouch;Netcipia;PBWiki;SaaS business model;SaaS support;Siberlogic SiberSafe;Trisoft Infoshare;Wagn;Wikia;Wikidot;Wikispaces;X-Hive Docato;bug tracking systems;documentation publishing;open source BusinessWiki;quality controlling tools application;ready-to-install products;requirement analysis;software companies;software developments tools;software documentation systems;task tracking systems;Documentation;Electronic publishing;Google;Information services;Internet;Subscriptions;XML;SaaS;Software documentation;XML CMS;wiki}
}

@InProceedings{6100061,
  Title                    = {Towards more accurate retrieval of duplicate bug reports},
  Author                   = {C. Sun and D. Lo and S. C. Khoo and J. Jiang},
  Booktitle                = {Automated Software Engineering (ASE), 2011 26th IEEE/ACM International Conference on},
  Year                     = {2011},
  Month                    = {Nov},
  Pages                    = {253-262},

  Abstract                 = {In a bug tracking system, different testers or users may submit multiple reports on the same bugs, referred to as duplicates, which may cost extra maintenance efforts in triaging and fixing bugs. In order to identify such duplicates accurately, in this paper we propose a retrieval function (REP) to measure the similarity between two bug reports. It fully utilizes the information available in a bug report including not only the similarity of textual content in summary and description fields, but also similarity of non-textual fields such as product, component, version, etc. For more accurate measurement of textual similarity, we extend BM25F - an effective similarity formula in information retrieval community, specially for duplicate report retrieval. Lastly we use a two-round stochastic gradient descent to automatically optimize REP for specific bug repositories in a supervised learning manner. We have validated our technique on three large software bug repositories from Mozilla, Eclipse and OpenOffice. The experiments show 10-27% relative improvement in recall rate@k and 17-23% relative improvement in mean average precision over our previous model. We also applied our technique to a very large dataset consisting of 209,058 reports from Eclipse, resulting in a recall rate@k of 37-71% and mean average precision of 47%.},
  Doi                      = {10.1109/ASE.2011.6100061},
  ISSN                     = {1938-4300},
  Keywords                 = {gradient methods;information retrieval;learning (artificial intelligence);program debugging;BM25F;REP;bug tracking system;duplicate bug reports;duplicate report retrieval;information retrieval community;retrieval function;software bug repositories;supervised learning;textual similarity;two-round stochastic gradient descent;Accuracy;Computer bugs;Information retrieval;Software;Support vector machines;Training;Tuning}
}

@InProceedings{6563851,
  Title                    = {Application of monitoring support visualization to bug tracking systems},
  Author                   = {Y. Takama and T. Kurosawa},
  Booktitle                = {Industrial Electronics (ISIE), 2013 IEEE International Symposium on},
  Year                     = {2013},
  Month                    = {May},
  Pages                    = {1-5},

  Abstract                 = {This paper proposes to apply information visualization technologies to the support of monitoring bug update information sent from multiple bug tracking systems. Bug update information managed by bug tracking systems (BTS) is one of text stream data, which continuously generates new data. Therefore, it is difficult for users to watch it all the time. In other words, the task of monitoring stream data inevitably involves breaks of the task, which would lose the context of monitoring. However, to the best of our knowledge, interaction design when involving breaks has not been fully studied yet. The proposed system visualizes the dynamic relationship between bugs with animation, and helps a user grasping the context of monitoring by highlighting updated bugs and the replay of animation for part of the last monitoring time. The effectiveness of the system is evaluated through experiments with test participants. Recent growth of the Web has brought us various kinds of text stream data, such as bulletin board systems (BBS), blogs, and social networking services (SNS). As such data is expected to be important resources for human support robots, this paper would contribute to interaction design of such robots.},
  Doi                      = {10.1109/ISIE.2013.6563851},
  ISSN                     = {2163-5137},
  Keywords                 = {Animation;Computer bugs;Context;Data visualization;Monitoring;Software;Visualization;bug tracking system;information visualization;monitoring support;stream data visualization}
}

@InProceedings{4579795,
  Title                    = {A Method of Reliability Assessment Based on Deterministic Chaos Theory for an Open Source Software},
  Author                   = {Y. Tamura and S. Yamada},
  Booktitle                = {Secure System Integration and Reliability Improvement, 2008. SSIRI '08. Second International Conference on},
  Year                     = {2008},
  Month                    = {July},
  Pages                    = {60-66},

  Abstract                 = {Open source software which serve as key components of critical infrastructures in the social life are still ever-expanding now. We focus on the quality problems of open source software developed under open source project. In case of considering the effect of the debugging process in the development of a method of reliability assessment for open source project, it is necessary to grasp the deeply-intertwined factors, such as programming path, size of each component, skill of fault reporters, and so on. Considering from a point of view of the software reliability growth model, it is difficult to cover the software fault-report phenomena on the bug tracking system of open source software. We propose a new approach to software reliability assessment based on deterministic chaos theory. Also, we analyze actual software fault count data to show numerical examples of software reliability assessment for the open source software.},
  Doi                      = {10.1109/SSIRI.2008.14},
  Keywords                 = {chaos;public domain software;software engineering;software reliability;bug tracking system;debugging process;deterministic chaos theory;open source software;software reliability assessment;Chaos;Debugging;Fault detection;Linux;Open source software;Programming;Quality management;Reliability engineering;Reliability theory;Software reliability;Deterministic chaos theory;Open source software;Reliability}
}

@InProceedings{4279994,
  Title                    = {Software Reliability Growth Model Based on Stochastic Differential Equations for Open Source Software},
  Author                   = {Y. Tamura and S. Yamada},
  Booktitle                = {2007 IEEE International Conference on Mechatronics},
  Year                     = {2007},
  Month                    = {May},
  Pages                    = {1-6},

  Abstract                 = {All over the world people can gain the information at the same time by growing rate of Internet access around the world in recent years. In accordance with such a penetration of the Internet, it is increasing public awareness of the importance of online real-time and interactive functions. Therefore, software development environment has been changing into new development paradigms such as concurrent distributed development environment and the so-called open source project by using network computing technologies. Especially, such OSS (open source software) systems which serve as key components of critical infrastructures in our society are still ever-expanding now. In this paper, we propose a software reliability growth model based on stochastic differential equations in order to consider the active state of the open source project. Especially, we assume that the software failure intensity depends on the time, and the software fault-report phenomena on the bug tracking system keep an irregular state. Also, we analyze actual software fault count data to show numerical examples of software reliability assessment for the OSS. Moreover, we compare our model with the conventional model based on stochastic differential equations in terms of goodness-of-fit for actual data. We show that the proposed model can assist improvement of quality for OSS systems developed under the open source project.},
  Doi                      = {10.1109/ICMECH.2007.4279994},
  Keywords                 = {differential equations;public domain software;software fault tolerance;software reliability;stochastic processes;network computing technology;open source software;software development environment;software fault-report phenomena;software reliability growth model;stochastic differential equation;Computer network reliability;Computer networks;Computer science;Differential equations;Internet;Mechatronics;Open source software;Programming;Software reliability;Stochastic processes;Open source software;reliability assessment;software reliability growth model;stochastic differential equation}
}

@InProceedings{6671284,
  Title                    = {Automatic recovery of root causes from bug-fixing changes},
  Author                   = {F. Thung and D. Lo and L. Jiang},
  Booktitle                = {2013 20th Working Conference on Reverse Engineering (WCRE)},
  Year                     = {2013},
  Month                    = {Oct},
  Pages                    = {92-101},

  Abstract                 = {What is the root cause of this failure? This question is often among the first few asked by software debuggers when they try to address issues raised by a bug report. Root cause is the erroneous lines of code that cause a chain of erroneous program states eventually leading to the failure. Bug tracking and source control systems only record the symptoms (e.g., bug reports) and treatments of a bug (e.g., committed changes that fix the bug), but not its root cause. Many treatments contain non-essential changes, which are intermingled with root causes. Reverse engineering the root cause of a bug can help to understand why the bug is introduced and help to detect and prevent other bugs of similar causes. The recovered root causes are also better ground truth for bug detection and localization studies. In this work, we propose a combination of machine learning and code analysis techniques to identify root causes from the changes made to fix bugs. We evaluate the effectiveness of our approach based on a golden set (i.e., ground truth data) of manually recovered root causes of 200 bug reports from three open source projects. Our approach is able to achieve a precision, recall, and F-measure (i.e., the harmonic mean of precision and recall) of 76.42%, 71.88%, and 74.08% respectively. Compared with the work by Kawrykow and Robillard, our approach achieves a 60.83% improvement in F-measure.},
  Doi                      = {10.1109/WCRE.2013.6671284},
  ISSN                     = {1095-1350},
  Keywords                 = {learning (artificial intelligence);program debugging;program diagnostics;reverse engineering;F-measure;automatic root cause recovery;bug detection;bug localization;bug reports;bug-fixing changes;code analysis techniques;machine learning;open source projects;reverse engineering;Computer bugs;Context;Control systems;Data models;Feature extraction;Support vector machines;Training data}
}

@InProceedings{6405302,
  Title                    = {When would this bug get reported?},
  Author                   = {F. Thung and D. Lo and L. Jiang and Lucia and F. Rahman and P. T. Devanbu},
  Booktitle                = {Software Maintenance (ICSM), 2012 28th IEEE International Conference on},
  Year                     = {2012},
  Month                    = {Sept},
  Pages                    = {420-429},

  Abstract                 = {Not all bugs in software would be experienced and reported by end users right away: Some bugs manifest themselves quickly and may be reported by users a few days after they get into the code base; others manifest many months or even years later, and may only be experienced and reported by a small number of users. We refer to the period of time between the time when a bug is introduced into code and the time when it is reported by a user as bug reporting latency. Knowledge of bug reporting latencies has an implication on prioritization of bug fixing activities-bugs with low reporting latencies may be fixed earlier than those with high latencies to shift debugging resources towards bugs highly concerning users. To investigate bug reporting latencies, we analyze bugs from three Java software systems: AspectJ, Rhino, and Lucene. We extract bug reporting data from their version control repositories and bug tracking systems, identify bug locations based on bug fixes, and back-trace bug introducing time based on change histories of the buggy code. Also, we remove non-essential changes, and most importantly, recover root causes of bugs from their treatments/fixes. We then calculate the bug reporting latencies, and find that bugs have diverse reporting latencies. Based on the calculated reporting latencies and features we extract from bugs, we build classification models that can predict whether a bug would be reported early (within 30 days) or later, which may be helpful for prioritizing bug fixing activities. Our evaluation on the three software systems shows that our bug reporting latency prediction models could achieve an AUC (Area Under the Receiving Operating Characteristics Curve) of 70.869%.},
  Doi                      = {10.1109/ICSM.2012.6405302},
  ISSN                     = {1063-6773},
  Keywords                 = {Java;aspect-oriented programming;pattern classification;program debugging;AUC;AspectJ;Java software systems;Lucene;Rhino;area under-the-receiving operating characteristics curve;back-trace bug;bug fixing activities;bug location identification;bug reporting data extraction;bug reporting latency prediction models;bug tracking systems;classification models;debugging resources;software bugs;software systems;version control repositories;Computer bugs;Conferences;Databases;Feature extraction;Java;Predictive models;Software systems}
}

@InProceedings{6649011,
  Title                    = {Exploiting hubs for self-adaptive secondary re-ranking in bug report duplicate detection},
  Author                   = {N. Tomašev and G. Leban and D. Mladenić},
  Booktitle                = {Information Technology Interfaces (ITI), Proceedings of the ITI 2013 35th International Conference on},
  Year                     = {2013},
  Month                    = {June},
  Pages                    = {131-136},

  Abstract                 = {Bug duplicate detection is an integral part of many bug tracking systems. Most bugs are reported multiple times and detecting the duplicates saves time and valuable resources. We propose a novel approach to potential duplicate report query ranking. Our secondary re-ranking procedure is self-adaptive, as it learns from previous report occurrences. It is based on the analysis of temporal evolution of the underlying distribution of influence. The experiments show definite improvements in system performance.},
  Doi                      = {10.2498/iti.2013.0488},
  ISSN                     = {1334-2762},
  Keywords                 = {program debugging;query processing;software maintenance;bug report duplicate detection;bug tracking system;hub exploitation;potential duplicate report query ranking;self-adaptive secondary re-ranking;system performance;temporal evolution analysis;Adaptive systems;Computer bugs;Context;Feature extraction;IEEE Potentials;Internet;Vectors;Bug duplicates;hubs;issue tracking;ranking}
}

@InProceedings{7335939,
  Title                    = {Characterizing and Predicting Bug Assignment in OpenStack},
  Author                   = {J. Tong and L. Ying and Y. Xiaoyong and T. Hongyan and W. Zhonghai},
  Booktitle                = {Trustworthy Systems and Their Applications (TSA), 2015 Second International Conference on},
  Year                     = {2015},
  Month                    = {July},
  Pages                    = {16-23},

  Abstract                 = {Open source software is becoming increasingly important in cloud computing. However, many cloud computing systems suffer from software bugs that cause significant dependability issues. Bug assignment and fixing are crucial parts of software maintenance to improve dependability. In this paper, we conduct an empirical study of 42,880 bug reports from OpenStack bug repository. We study the characteristics (e.g., distribution of bugs, distribution of assignees) of bug assignments in OpenStack and find the bug assignment pattern which we call as long tail. The findings can support the follow-up research on improving efficiency of bug assignment, that is, we propose a prediction method based on long tail model, and experimentally evaluate this method by applying it to OpenStack bug assignment.},
  Doi                      = {10.1109/TSA.2015.14},
  Keywords                 = {cloud computing;program debugging;public domain software;software maintenance;OpenStack bug repository;bug assignment characteristics;bug assignment efficiency;bug assignment pattern;bug assignment prediction method;cloud computing systems;long tail model;open source software;software bugs;software dependability;software maintenance;Cloud computing;Computational modeling;Computer bugs;Correlation;Predictive models;bug assignment;cloud computing;long tail;open source}
}

@InProceedings{6823876,
  Title                    = {Automated Bug Finding in Video Games: A Case Study for Runtime Monitoring},
  Author                   = {S. Varvaressos and K. Lavoie and A. B. Massé and S. Gaboury and S. Hallé},
  Booktitle                = {2014 IEEE Seventh International Conference on Software Testing, Verification and Validation},
  Year                     = {2014},
  Month                    = {March},
  Pages                    = {143-152},

  Abstract                 = {Runtime verification is the process of observing a sequence of events generated by a running system and comparing it to some formal specification for potential violations. We show how the use of a runtime monitor can greatly speed up the testing phase of a video game under development, by automating the detection of bugs when the game is being played. We take advantage of the fact that a video game, contrarily to generic software, follows a special structure that contains a "game loop", this game loop can be used to centralize the instrumentation and generate events based on the game's internal state. We report on experiments made on a sample of five real-world video games of various genres and sizes, by successfully incrementing and efficiently monitoring various temporal properties over their execution-including actual bugs reported in the games' bug tracking database in the course of their development.},
  Doi                      = {10.1109/ICST.2014.27},
  ISSN                     = {2159-4848},
  Keywords                 = {computer games;data flow analysis;formal specification;program debugging;program testing;program verification;automated bug finding;formal specification;runtime monitoring;runtime verification;video game testing phase;video games;Computer bugs;Games;Instruments;Monitoring;Runtime;Software;XML;runtime verification;temporal logic;video games}
}

@InProceedings{6965067,
  Title                    = {How Much Effort Needed to Fix the Bug? A Data Mining Approach for Effort Estimation and Analysing of Bug Report Attributes in Firefox},
  Author                   = {K. Vijayakumar and V. Bhuvaneswari},
  Booktitle                = {Intelligent Computing Applications (ICICA), 2014 International Conference on},
  Year                     = {2014},
  Month                    = {March},
  Pages                    = {335-339},

  Abstract                 = {Estimating the effort required to fix a bug is a significant task for the project manager to determine the project release. Among various ways to estimate the effort, analysis of bug report attributes proved excellent results. In this paper the effort required to fix the bug on the components of Firefox application is studied. A framework has been charted for analysing the feature attributes which on imparting association rule mining process resulted with dictating rules which provide the effort succumb to fix the bugs of a particular component. The bug reports used for this study are extracted from Bugzilla, an open source bug repository. These bug reports provides a variety of categorical data from previous projects. Analysis of this can improve the planning of personnel to fix the bug and raise the quality of bug reports.},
  Doi                      = {10.1109/ICICA.2014.75},
  Keywords                 = {data mining;program debugging;public domain software;software development management;Bugzilla;Firefox application;association rule mining process;bug report attributes analysis;data mining approach;dictating rules;effort estimation;feature attributes;open source bug repository;personnel planning;project manager;project release;Association rules;Computer bugs;Estimation;Feature extraction;Software;Software testing;Bugzilla;association rules;bug report;component;data mining;repository;severity}
}

@InProceedings{5928673,
  Title                    = {Behind Linus's law: A preliminary analysis of open source software peer review practices in Mozilla and Python},
  Author                   = {J. Wang and J. M. Carroll},
  Booktitle                = {Collaboration Technologies and Systems (CTS), 2011 International Conference on},
  Year                     = {2011},
  Month                    = {May},
  Pages                    = {117-124},

  Abstract                 = {Open source is an important model of collaborative knowledge work and virtual organizations. One of its work practices, peer review, is considered critical to its success, as Linus's law highlights. Thus, understanding open source peer review, particular effective review practices, will improve the understanding of how to support collaborative work in new ways. Therefore, we conduct case studies in two open source communities that are well recognized as effective and successful, Mozilla and Python. In this paper, we present the preliminary results of our analysis on data from the bug tracking systems of those two organizations. We identify four common activities critical to open source software peer review, submission, identification, resolution and evaluation. Differences between communities indicate factors, such as reporter expertise, product type and structure, and organization size, affect review activities. We also discuss features of open source software peer review distinct from traditional review, as well as reconsiderations of Linus's law.},
  Doi                      = {10.1109/CTS.2011.5928673},
  Keywords                 = {groupware;program debugging;programming languages;public domain software;software performance evaluation;software reviews;virtual enterprises;Linus law;Mozilla;Python;bug tracking system;collaborative knowledge work;data analysis;evaluation;identification;open source community;open source software peer review practice;organization size;product structure;product type;reporter expertise;resolution;submission;virtual organization;Collaboration;Communities;Computer bugs;Fires;Open source software;Organizations;Coordination;cooperation and collaboration;designing collaborative & virtual organizations}
}

@InProceedings{6462735,
  Title                    = {A Guided Mashup Framework for Rapid Software Analysis Service Composition},
  Author                   = {C. Wijesiriwardana and G. Ghezzi and H. Gall},
  Booktitle                = {2012 19th Asia-Pacific Software Engineering Conference},
  Year                     = {2012},
  Month                    = {Dec},
  Pages                    = {725-728},
  Volume                   = {1},

  Abstract                 = {Historical data about software projects is stored in repositories such as version control, bug tracking and mailing lists. Analyzing such data is vital to discover unthought-of-yet-interesting insights of a software project. Even though a wide range of software analysis techniques are already available, integration of such analyses is yet to be systematically addressed. Inspired from the recently introduced concept of Software as a Service, our research group investigated the concept of Software Analysis as a Service (SOFAS), a distributed and collaborative software analysis platform. SOFAS allows software analyses to be accessed, composed into workflows, and executed over the Internet. However, traditional service composition is a complex, time consuming and error-prone process, which requires experts in both composition languages and existing standards. In this paper, we propose a mashup platform to address the problem of software analysis composition in a light-weight, programming-free process-centric way. Our proposed mashup platform provides design-time guidance to the users throughout the mashup design by integrating a continuous feedback mechanism. It requires exploiting semantic web technologies and Software Engineering Ontologies (SEON).},
  Doi                      = {10.1109/APSEC.2012.112},
  ISSN                     = {1530-1362},
  Keywords                 = {cloud computing;groupware;ontologies (artificial intelligence);program diagnostics;project management;semantic Web;software engineering;software standards;Internet;SEON;SOFAS;bug tracking;collaborative software analysis platform;composition languages;continuous feedback mechanism;design-time guidance;distributed software analysis;error-prone process;guided mashup framework;historical data;mailing lists;mashup platform;programming-free process-centric way;research group;semantic Web technology;software analysis as a service;software analysis composition;software analysis service composition;software analysis techniques;software as a service;software engineering ontology;software projects;software standards;version control;Data mining;History;Mashups;Measurement;Ontologies;Semantics;Mashups;Software Analysis as a Service;Software Engineering Ontologies}
}

@InProceedings{6130646,
  Title                    = {DREX: Developer Recommendation with K-Nearest-Neighbor Search and Expertise Ranking},
  Author                   = {W. Wu and W. Zhang and Y. Yang and Q. Wang},
  Booktitle                = {2011 18th Asia-Pacific Software Engineering Conference},
  Year                     = {2011},
  Month                    = {Dec},
  Pages                    = {389-396},

  Abstract                 = {This paper proposes a new approach called DREX (Developer Recommendation with k-nearest-neighbor search and Expertise ranking) to developer recommendation for bug resolution based on K-Nearest-Neighbor search with bug similarity and expertise ranking with various metrics, including simple frequency and social network metrics. We collect Mozilla Fire fox open bug repository as the experimental data set and compare different ranking metrics on the performance of recommending capable developers for bugs. Our experimental results demonstrate that, when recommending 10 developers for each one of the 250 testing bugs, DREX has produced better performance than traditional methods with multi-labeled text categorization. The best performance obtained by two metrics as Out-Degree and Frequency, is with recall as 0.6 on average. Moreover, other social network metrics such as Degree and Page Rank have produced comparable performance on developer recommendation as Frequency when used for developer expertise ranking.},
  Doi                      = {10.1109/APSEC.2011.15},
  ISSN                     = {1530-1362},
  Keywords                 = {program debugging;social networking (online);DREX;K-nearest-neighbor search;Mozilla Fire fox;Page Rank;bug repository;bug resolution;bug similarity;developer recommendation;expertise ranking;social network metrics;Computer bugs;Fires;Measurement;Social network services;Software;Testing;Vectors;Developer Recommendation;Expertise Ranking;KNN Search;Open Bug Repository}
}

@InProceedings{6681358,
  Title                    = {Impact of Triage: A Study of Mozilla and Gnome},
  Author                   = {J. Xie and M. Zhou and A. Mockus},
  Booktitle                = {2013 ACM / IEEE International Symposium on Empirical Software Engineering and Measurement},
  Year                     = {2013},
  Month                    = {Oct},
  Pages                    = {247-250},

  Abstract                 = {Triage is of great interest in software projects because it has the potential to reduce developer effort by involving a broader base of non-developer contributors to filter and augment reported issues. Using issue tracking data and interviews with experienced contributors we investigate ways to quantify the impact of triagers on reducing the number of issues developers need to resolve in two OSS projects: Mozilla and Gnome. We find the primary impact of triagers to involve issue filtering, filling missing information, and determining the relevant product. While triagers were good at filtering invalid issues and as accurate as developers in filling in missing issue attributes, they had more difficulty accurately pinpointing the relevant product. We expect that this work will highlight the importance of issue triage in software projects and will help design further studies on understanding and improving triage practices.},
  Doi                      = {10.1109/ESEM.2013.62},
  ISSN                     = {1949-3770},
  Keywords                 = {online front-ends;project management;public domain software;software engineering;Gnome;Mozilla;OSS projects;issue filtering;issue tracking data;missing information filling;relevant product determination;software projects;triage impact;Accuracy;Atmospheric measurements;Communities;Computer bugs;Particle measurements;Software;Software engineering}
}

@InProceedings{6494902,
  Title                    = {Practical isolation of failure-inducing changes for debugging regression faults},
  Author                   = {K. Yu and M. Lin and J. Chen and X. Zhang},
  Booktitle                = {Automated Software Engineering (ASE), 2012 Proceedings of the 27th IEEE/ACM International Conference on},
  Year                     = {2012},
  Month                    = {Sept},
  Pages                    = {20-29},

  Abstract                 = {During software evolution, new released versions still contain many bugs. One common scenario is that end users encounter regression faults and submit them to bug tracking systems. Different from in-house regression testing, typically only one test input is available, which passes the old version and fails the modified new version. To address the issue, delta debugging has been proposed for failure-inducing changes identification between two versions. Despite promising results, there are two practical factors that thwart the application of delta debugging: a large number of tests and misleading false positives. In this work, we present a combination of coverage analysis and delta debugging that automatically isolates failure-inducing changes. Evaluations on twelve real regression faults in GNU software demonstrate both the speed gain and effectiveness improvements. Moreover, a case study on libPNG and TCPflow indicates that our technique is comparable to peer techniques in debugging regressions faults.},
  Doi                      = {10.1145/2351676.2351681},
  Keywords                 = {program debugging;regression analysis;software fault tolerance;GNU software;TCPflow;bug tracking system;delta debugging;effectiveness improvement;failure-inducing change identification;libPNG;regression fault debugging;regression testing;software evolution;speed gain;Regression fault;automated debugging;coverage analysis;delta debugging;field failure}
}

@InProceedings{6606653,
  Title                    = {Categorizing bugs with social networks: A case study on four open source software communities},
  Author                   = {M. S. Zanetti and I. Scholtes and C. J. Tessone and F. Schweitzer},
  Booktitle                = {2013 35th International Conference on Software Engineering (ICSE)},
  Year                     = {2013},
  Month                    = {May},
  Pages                    = {1032-1041},

  Abstract                 = {Efficient bug triaging procedures are an important precondition for successful collaborative software engineering projects. Triaging bugs can become a laborious task particularly in open source software (OSS) projects with a large base of comparably inexperienced part-time contributors. In this paper, we propose an efficient and practical method to identify valid bug reports which a) refer to an actual software bug, b) are not duplicates and c) contain enough information to be processed right away. Our classification is based on nine measures to quantify the social embeddedness of bug reporters in the collaboration network. We demonstrate its applicability in a case study, using a comprehensive data set of more than 700, 000 bug reports obtained from the Bugzilla installation of four major OSS communities, for a period of more than ten years. For those projects that exhibit the lowest fraction of valid bug reports, we find that the bug reporters' position in the collaboration network is a strong indicator for the quality of bug reports. Based on this finding, we develop an automated classification scheme that can easily be integrated into bug tracking platforms and analyze its performance in the considered OSS communities. A support vector machine (SVM) to identify valid bug reports based on the nine measures yields a precision of up to 90.3% with an associated recall of 38.9%. With this, we significantly improve the results obtained in previous case studies for an automated early identification of bugs that are eventually fixed. Furthermore, our study highlights the potential of using quantitative measures of social organization in collaborative software engineering. It also opens a broad perspective for the integration of social awareness in the design of support infrastructures.},
  Doi                      = {10.1109/ICSE.2013.6606653},
  ISSN                     = {0270-5257},
  Keywords                 = {groupware;pattern classification;program debugging;project management;public domain software;social networking (online);support vector machines;BUGZILLA installation;OSS communities;SVM;actual software bug;automated classification scheme;bug categorization;bug report quality;bug reporters;bug tracking platforms;bug triaging procedures;collaboration network;collaborative software engineering projects;open source software communities;part-time contributors;social awareness;social embeddedness;social networks;social organization;support vector machine;Collaboration;Communities;Computer bugs;History;Social network services;Software;Support vector machines}
}

@InProceedings{6614731,
  Title                    = {The rise and fall of a central contributor: Dynamics of social organization and performance in the GENTOO community},
  Author                   = {M. S. Zanetti and I. Scholtes and C. J. Tessone and F. Schweitzer},
  Booktitle                = {Cooperative and Human Aspects of Software Engineering (CHASE), 2013 6th International Workshop on},
  Year                     = {2013},
  Month                    = {May},
  Pages                    = {49-56},

  Abstract                 = {Social organization and division of labor crucially influence the performance of collaborative software engineering efforts. In this paper, we provide a quantitative analysis of the relation between social organization and performance in Gentoo, an Open Source community developing a Linux distribution. We study the structure and dynamics of collaborations as recorded in the project's bug tracking system over a period of ten years. We identify a period of increasing centralization after which most interactions in the community were mediated by a single central contributor. In this period of maximum centralization, the central contributor unexpectedly left the project, thus posing a significant challenge for the community. We quantify how the rise, the activity as well as the subsequent sudden dropout of this central contributor affected both the social organization and the bug handling performance of the Gentoo community. We analyze social organization from the perspective of network theory and augment our quantitative findings by interviews with prominent members of the Gentoo community which shared their personal insights.},
  Doi                      = {10.1109/CHASE.2013.6614731},
  Keywords                 = {Linux;program debugging;public domain software;GENTOO community;Linux distribution;bug handling performance;bug tracking system;central contributor;collaboration dynamics;collaboration structure;collaborative software engineering;labor division;maximum centralization;network theory;open source community;social organization;Collaboration;Communities;Computer bugs;Network topology;Organizations;Peer-to-peer computing;Topology}
}

@InProceedings{7062873,
  Title                    = {BUTTER: An Approach to Bug Triage with Topic Modeling and Heterogeneous Network Analysis},
  Author                   = {W. Zhang and G. Han and Q. Wang},
  Booktitle                = {Cloud Computing and Big Data (CCBD), 2014 International Conference on},
  Year                     = {2014},
  Month                    = {Nov},
  Pages                    = {62-69},

  Abstract                 = {When a bug is reported to the bug tracking system, it should be assigned to a developer responsible for its resolution after it is verified. This processing is also called bug triage. With increasing number of bug reports submitted to the bug tracking system, it is more and more difficult to assign appropriate developers to all the reported bugs manually. In this paper, we propose an approach called BUTTER (BUg Triage by topic modeling and heTERogeneous network analysis) to automatically assign bugs to developers. Different from other work, we regard that in most cases, bug resolution is a collaborative activity which involves many developers' participation. Although social network analysis has been introduced to characterize the collaboration of developers, networks constructed by researchers are usually homogenous. That is, all the nodes and links in these networks are regarded as having same properties. Considering developers collaborated on different bugs, we construct a heterogeneous network that includes relationships between submitters, bugs and developers to characterize developers' collaboration. Experiment shows that BUTTER outperforms other methods on automated bug triage.},
  Doi                      = {10.1109/CCBD.2014.14},
  Keywords                 = {program debugging;program verification;BUTTER;bug reports;bug resolution;bug tracking system;bug triage by topic modeling and heterogeneous network analysis;collaborative activity;developers collaboration;social network analysis;verification;Analytical models;Computer bugs;Dairy products;Mathematical model;Social network services;Software;Training;bug triage;heterogeneous network;topic model}
}

@Article{6880395,
  Title                    = {Who Will Stay in the FLOSS Community? Modeling Participant Initial Behavior},
  Author                   = {M. Zhou and A. Mockus},
  Journal                  = {IEEE Transactions on Software Engineering},
  Year                     = {2015},

  Month                    = {Jan},
  Number                   = {1},
  Pages                    = {82-99},
  Volume                   = {41},

  Abstract                 = {Motivation: To survive and succeed, FLOSS projects need contributors able to accomplish critical project tasks. However, such tasks require extensive project experience of long term contributors (LTCs). Aim: We measure, understand, and predict how the newcomers' involvement and environment in the issue tracking system (ITS) affect their odds of becoming an LTC. Method: ITS data of Mozilla and Gnome, literature, interviews, and online documents were used to design measures of involvement and environment. A logistic regression model was used to explain and predict contributor's odds of becoming an LTC. We also reproduced the results on new data provided by Mozilla. Results: We constructed nine measures of involvement and environment based on events recorded in an ITS. Macro-climate is the overall project environment while micro-climate is person-specific and varies among the participants. Newcomers who are able to get at least one issue reported in the first month to be fixed, doubled their odds of becoming an LTC. The macro-climate with high project popularity and the micro-climate with low attention from peers reduced the odds. The precision of LTC prediction was 38 times higher than for a random predictor. We were able to reproduce the results with new Mozilla data without losing the significance or predictive power of the previously published model. We encountered unexpected changes in some attributes and suggest ways to make analysis of ITS data more reproducible. Conclusions: The findings suggest the importance of initial behaviors and experiences of new participants and outline empirically-based approaches to help the communities with the recruitment of contributors for long-term participation and to help the participants contribute more effectively. To facilitate the reproduction of the study and of the proposed measures in other contexts, we provide the data we retrieved and the scripts we wrote at https://www.passion-lab.org/projects/developerfluency.html.},
  Doi                      = {10.1109/TSE.2014.2349496},
  ISSN                     = {0098-5589},
  Keywords                 = {behavioural sciences;project management;public domain software;FLOSS community;Free-Libre and/or open source software projects;Gnome;ITS data;LTC;Mozilla data;critical project;issue tracking system;logistic regression model;long term contributors;macroclimate;microclimate;open source software;Atmospheric measurements;Communities;Data mining;Data models;Electronic mail;Particle measurements;Predictive models;Long term contributor;extent of involvement;initial behavior;interaction with environment;issue tracking system;mining software repository;open source software}
}

@InProceedings{5306296,
  Title                    = {Changes and bugs Mining and predicting development activities},
  Author                   = {T. Zimmermann},
  Booktitle                = {Software Maintenance, 2009. ICSM 2009. IEEE International Conference on},
  Year                     = {2009},
  Month                    = {Sept},
  Pages                    = {443-446},

  Abstract                 = {Software development results in a huge amount of data: changes to source code are recorded in version archives, bugs are reported to issue tracking systems, and communications are archived in e-mails and newsgroups. We present techniques for mining version archives and bug databases to understand and support software development. First, we introduce the concept of co-addition of method calls, which we use to identify patterns that describe how methods should be called. We use dynamic analysis to validate these patterns and identify violations. The co-addition of method calls can also detect cross-cutting changes, which are an indicator for concerns that could have been realized as aspects in aspect-oriented programming. Second, we present techniques to build models that can successfully predict the most defect-prone parts of large-scale industrial software, in our experiments Windows Server 2003. This helps managers to allocate resources for quality assurance to those parts of a system that are expected to have most defects. The proposed measures on dependency graphs outperformed traditional complexity metrics. In addition, we found empirical evidence for a domino effect, i.e., depending on defect-prone binaries increases the chances of having defects.},
  Doi                      = {10.1109/ICSM.2009.5306296},
  ISSN                     = {1063-6773},
  Keywords                 = {data mining;object-oriented programming;program debugging;software quality;Windows Server 2003;aspect-oriented programming;bug databases;large-scale industrial software;quality assurance;resource allocation;software development;source code;tracking systems;version archives mining;Computer bugs;Computer industry;Databases;Large-scale systems;Pattern analysis;Predictive models;Programming;Quality assurance;Quality management;Resource management}
}

@Article{5487527,
  Title                    = {What Makes a Good Bug Report?},
  Author                   = {T. Zimmermann and R. Premraj and N. Bettenburg and S. Just and A. Schroter and C. Weiss},
  Journal                  = {IEEE Transactions on Software Engineering},
  Year                     = {2010},

  Month                    = {Sept},
  Number                   = {5},
  Pages                    = {618-643},
  Volume                   = {36},

  Abstract                 = {In software development, bug reports provide crucial information to developers. However, these reports widely differ in their quality. We conducted a survey among developers and users of APACHE, ECLIPSE, and MOZILLA to find out what makes a good bug report. The analysis of the 466 responses revealed an information mismatch between what developers need and what users supply. Most developers consider steps to reproduce, stack traces, and test cases as helpful, which are, at the same time, most difficult to provide for users. Such insight is helpful for designing new bug tracking tools that guide users at collecting and providing more helpful information. Our CUEZILLA prototype is such a tool and measures the quality of new bug reports; it also recommends which elements should be added to improve the quality. We trained CUEZILLA on a sample of 289 bug reports, rated by developers as part of the survey. The participants of our survey also provided 175 comments on hurdles in reporting and resolving bugs. Based on these comments, we discuss several recommendations for better bug tracking systems, which should focus on engaging bug reporters, better tool support, and improved handling of bug duplicates.},
  Doi                      = {10.1109/TSE.2010.63},
  ISSN                     = {0098-5589},
  Keywords                 = {program debugging;program testing;software quality;APACHE;CUEZILLA prototype;ECLIPSE;MOZILLA;bug tracking tools;software development;Computer bugs;Debugging;Engineering management;Human factors;Information analysis;Programming;Prototypes;Software engineering;Software maintenance;Software testing;Testing and debugging;and enhancement;distribution;human factors;maintenance;management;measurement.}
}

@InProceedings{5070993,
  Title                    = {Improving bug tracking systems},
  Author                   = {T. Zimmermann and R. Premraj and J. Sillito and S. Breu},
  Booktitle                = {Software Engineering - Companion Volume, 2009. ICSE-Companion 2009. 31st International Conference on},
  Year                     = {2009},
  Month                    = {May},
  Pages                    = {247-250},

  Abstract                 = {It is important that information provided in bug reports is relevant and complete in order to help resolve bugs quickly. However, often such information trickles to developers after several iterations of communication between developers and reporters. Poorly designed bug tracking systems are partly to blame for this exchange of information being stretched over time. Our paper addresses the concerns of bug tracking systems by proposing four broad directions for enhancements. As a proof-of-concept, we also demonstrate a prototype interactive bug tracking system that gathers relevant information from the user and identifies files that need to be fixed to resolve the bug.},
  Doi                      = {10.1109/ICSE-COMPANION.2009.5070993},
  Keywords                 = {interactive systems;invasive software;iterative methods;bug tracking system;interactive system;iteration;Computer bugs;Computer science;Data mining;Decision trees;Delay effects;Laboratories;Prototypes;Relational databases;Testing;Usability}
}

@InProceedings{7273626,
  Title                    = {An Empirical Study of Bug Fixing Rate},
  Author                   = {W. Zou and X. Xia and W. Zhang and Z. Chen and D. Lo},
  Booktitle                = {Computer Software and Applications Conference (COMPSAC), 2015 IEEE 39th Annual},
  Year                     = {2015},
  Month                    = {July},
  Pages                    = {254-263},
  Volume                   = {2},

  Abstract                 = {Bug fixing is one of the most important activities in software development and maintenance. A software project often employs an issue tracking system such as Bugzilla to store and manage their bugs. In the issue tracking system, many bugs are invalid but take unnecessary efforts to identify them. In this paper, we mainly focus on bug fixing rate, i.e., The proportion of the fixed bugs in the reported closed bugs. In particular, we study the characteristics of bug fixing rate and investigate the impact of a reporter's different contribution behaviors to the bug fixing rate. We perform an empirical study on all reported bugs of two large open source software communities Eclipse and Mozilla. We find (1) the bug fixing rates of both projects are not high, (2) there exhibits a negative correlation between a reporter's bug fixing rate and the average time cost to close the bugs he/she reports, (3) the amount of bugs a reporter ever fixed has a strong positive impact on his/her bug fixing rate, (4) reporters' bug fixing rates have no big difference, whether their contribution behaviors concentrate on a few products or across many products, (5) reporters' bug fixing rates tend to increase as time goes on, i.e., Developers become more experienced at reporting bugs.},
  Doi                      = {10.1109/COMPSAC.2015.57},
  Keywords                 = {program debugging;public domain software;software maintenance;Eclipse;Mozilla;bug fixing rate;open source software community;software development;software maintenance;Computer aided software engineering;Computer bugs;Correlation;Entropy;History;Open source software;Bug Fixing Rate;Bug Reports;Empirical Study;Statistical Analysis}
}

