% This file was created with JabRef 2.10.
% Encoding: UTF-8


@Conference{Alipour2013183,
  Title                    = {A contextual approach towards more accurate duplicate bug report detection},
  Author                   = {Alipour, A. and Hindle, A. and Stroulia, E.},
  Year                     = {2013},
  Note                     = {cited By 5},
  Pages                    = {183-192},

  Abstract                 = {Bug-tracking and issue-tracking systems tend to be populated with bugs, issues, or tickets written by a wide variety of bug reporters, with different levels of training and knowledge about the system being discussed. Many bug reporters lack the skills, vocabulary, knowledge, or time to efficiently search the issue tracker for similar issues. As a result, issue trackers are often full of duplicate issues and bugs, and bug triaging is time consuming and error prone. Many researchers have approached the bug-deduplication problem using off-the-shelf information-retrieval tools, such as BM25F used by Sun et al. In our work, we extend the state of the art by investigating how contextual information, relying on our prior knowledge of software quality, software architecture, and system-development (LDA) topics, can be exploited to improve bug-deduplication. We demonstrate the effectiveness of our contextual bug-deduplication method on the bug repository of the Android ecosystem. Based on this experience, we conclude that researchers should not ignore the context of software engineering when using IR tools for deduplication. © 2013 IEEE.},
  Affiliation              = {Department of Computing Science, University of Alberta, Edmonton, Canada},
  Art_number               = {6624026},
  Author_keywords          = {Contextual information; Deduplication; Duplicate bug reports; Information retrieval; Machine learning; Textual similarity; Triaging},
  Document_type            = {Conference Paper},
  Doi                      = {10.1109/MSR.2013.6624026},
  Journal                  = {IEEE International Working Conference on Mining Software Repositories},
  Source                   = {Scopus},
  Url                      = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84889064635&partnerID=40&md5=d3a117c0d8cdcdc74d970a4601ca97fe}
}

@Article{Antoniol200587,
  Title                    = {Towards the integration of versioning systems, bug reports and source code meta-models},
  Author                   = {Antoniol, G.a and Di Penta, M.a and Gall, H.b and Pinzger, M.c },
  Journal                  = {Electronic Notes in Theoretical Computer Science},
  Year                     = {2005},
  Note                     = {cited By 14},
  Number                   = {3},
  Pages                    = {87-99},
  Volume                   = {127},

  Abstract                 = {Versioning system repositories and bug tracking systems are valuable sources of information to study the evolution of large open source software systems. However, being conceived for specific purposes, i.e., to support the development or trigger maintenance activities, they do neither allow an easy information browsing nor support the study of software evolution. For example, queries such as locating and browsing the faultiest methods are not provided. This paper addresses such issues and proposes an approach and a framework to consistently merge information extracted from source code, versioning repositories and bug reports. Our information representation exploits the property concepts of the FAMIX information exchange meta-model, allowing to represent, browse, and query, at different level of abstractions, the concept of interest. This allows the user to navigate back and forth from versioning system modification reports to bug reports and to source code. This paper presents the analysis framework and approaches to populate it, tools developed and under development for it, as well as lessons learned while analyzing several releases of Mozilla. © 2005 Elsevier B.V.},
  Affiliation              = {RCOST - Res. Ctr. Software Technol., University of Sannio, Department of Engineering, Palazzo ex Poste, Via Traiano, 82100 Benevento, Italy; University of Zurich, Department of Informatics, Switzerland; Technical University of Vienna, Information Systems Institute, Austria},
  Author_keywords          = {Bug Reports; Object-Oriented Meta-Models; Release History; Source Code Analysis},
  Document_type            = {Conference Paper},
  Doi                      = {10.1016/j.entcs.2004.08.036},
  Source                   = {Scopus},
  Url                      = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-15544385242&partnerID=40&md5=ec6190f1286c80cb78380c54b480ea58}
}

@Conference{Banerjee201274,
  Title                    = {Automated duplicate bug report classification using subsequence matching},
  Author                   = {Banerjee, S. and Cukic, B. and Adjeroh, D.},
  Year                     = {2012},
  Note                     = {cited By 3},
  Pages                    = {74-81},

  Abstract                 = {The use of open bug tracking repositories like Bugzilla is common in many software applications. They allow developers, testers and users the ability to report problems associated with the system and track resolution status. Open and democratic reporting tools, however, face one major challenge: users can, and often do, submit reports describing the same problem. Research in duplicate report detection has primarily focused on word frequency based similarity measures paying little regard to the context or structure of the reporting language. Thus, in large repositories, reports describing different issues may be marked as duplicates due to the frequent use of common words. In this paper, we present Factor LCS, a methodology which utilizes common sequence matching for duplicate report detection. We demonstrate the approach by analyzing the complete Fire fox bug repository up until March 2012 as well as a smaller subset of Eclipse dataset from January 1, 2008 to December 31, 2008. We achieve a duplicate recall rate above 70% with Fire fox, which exceeds the results reported on smaller subsets of the same repository. © 2012 IEEE.},
  Affiliation              = {Lane Department of Computer Science and Electrical Engineering, West Virginia University, Morgantown, WV, United States},
  Art_number               = {6375640},
  Author_keywords          = {Documentation; Duplicate Bug Reports; Experimentation; String Algorithms; Verification},
  Document_type            = {Conference Paper},
  Doi                      = {10.1109/HASE.2012.38},
  Journal                  = {Proceedings of IEEE International Symposium on High Assurance Systems Engineering},
  Source                   = {Scopus},
  Url                      = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84871973402&partnerID=40&md5=f17bea67b2cb0e6341d72ff4b6423d1e}
}

@Conference{Behl2014294,
  Title                    = {A bug Mining tool to identify and analyze security bugs using Naive Bayes and TF-IDF: A Comparative Analysis},
  Author                   = {Behl, D. and Handa, S. and Arora, A.},
  Year                     = {2014},
  Note                     = {cited By 1},
  Pages                    = {294-299},

  Abstract                 = {Bug report contains a vital role during software development, However bug reports belongs to different categories such as performance, usability, security etc. This paper focuses on security bug and presents a bug mining system for the identification of security and non-security bugs using the term frequency-inverse document frequency (TF-IDF) weights and naïve bayes. We performed experiments on bug report repositories of bug tracking systems such as bugzilla and debugger. In the proposed approach we apply text mining methodology and TF-IDF on the existing historic bug report database based on the bug s description to predict the nature of the bug and to train a statistical model for manually mislabeled bug reports present in the database. The tool helps in deciding the priorities of the incoming bugs depending on the category of the bugs i.e. whether it is a security bug report or a non-security bug report, using naïve bayes. Our evaluation shows that our tool using TF-IDF is giving better results than the naïve bayes method. © 2014 IEEE.},
  Affiliation              = {CSE / IT Department, Jaypee Institute of Information Technology, Noida, India},
  Art_number               = {6798341},
  Author_keywords          = {Bug; mining; Naïve Bayes; non-security bug report; security bug reports; text analysis; TF-IDF},
  Document_type            = {Conference Paper},
  Doi                      = {10.1109/ICROIT.2014.6798341},
  Journal                  = {ICROIT 2014 - Proceedings of the 2014 International Conference on Reliability, Optimization and Information Technology},
  Source                   = {Scopus},
  Url                      = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84900319880&partnerID=40&md5=ab7d68ceb18934d44e5ff6ba3b226ed8}
}

@Conference{Bettenburg2008308,
  Title                    = {What makes a good bug report?},
  Author                   = {Bettenburg, N.a and Just, S.a and Schröter, A.b and Weiss, C.c and Premraj, R.a and Zimmermann, T.d },
  Year                     = {2008},
  Note                     = {cited By 116},
  Pages                    = {308-318},

  Abstract                 = {In software development, bug reports provide crucial information to developers. However, these reports widely differ in their quality. We conducted a survey among developers and users of APACHE, ECLIPSE, and MOZILLA to find out what makes a good bug report. The analysis of the 466 responses revealed an information mismatch between what developers need and what users supply. Most developers consider steps to reproduce, stack traces, and test cases as helpful, which are at the same time most difficult to provide for users. Such insight is helpful to design new bug tracking tools that guide users at collecting and providing more helpful information. Our CUEZILLA prototype is such a tool and measures the quality of new bug reports; it also recommends which elements should be added to improve the quality. We trained CUEZILLA on a sample of 289 bug reports, rated by developers as part of the survey. In our experiments, CUEZILLA was able to predict the quality of 31 - 48% of bug reports accurately. © 2008 ACM.},
  Affiliation              = {Saarland University, Germany; University of Victoria, Canada; University of Zurich, Switzerland; University of Calgary, Alberta, Canada},
  Document_type            = {Conference Paper},
  Doi                      = {10.1145/1453101.1453146},
  Journal                  = {Proceedings of the ACM SIGSOFT Symposium on the Foundations of Software Engineering},
  Source                   = {Scopus},
  Url                      = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-77949403731&partnerID=40&md5=38c526b9cb6a9b34cd11370e4f68214e}
}

@Conference{Bissyandé201389,
  Title                    = {Empirical evaluation of bug linking},
  Author                   = {Bissyandé, T.F.a and Thung, F.b and Wang, S.b and Lo, D.b and Jiang, L.b and Réveillère, L.a },
  Year                     = {2013},
  Note                     = {cited By 13},
  Pages                    = {89-98},

  Abstract                 = {To collect software bugs found by users, development teams often set up bug trackers using systems such as Bugzilla. Developers would then fix some of the bugs and commit corresponding code changes into version control systems such as svn or git. Unfortunately, the links between bug reports and code changes are missing for many software projects as the bug tracking and version control systems are often maintained separately. Yet, linking bug reports to fix commits is important as it could shed light into the nature of bug fixing processes and expose patterns in software management. Bug linking solutions, such as ReLink, have been proposed. The demonstration of their effectiveness however faces a number of issues, including a reliability issue with their ground truth datasets as well as the extent of their measurements. We propose in this study a benchmark for evaluating bug linking solutions. This benchmark includes a dataset of about 12,000 bug links from 10 programs. These true links between bug reports and their fixes have been provided during bug fixing processes. We designed a number of research questions, to assess both quantitatively and qualitatively the effectiveness of a bug linking tool. Finally, we apply this benchmark on ReLink to report the strengths and limitations of this bug linking tool. © 2013 IEEE.},
  Affiliation              = {LaBRI, University of Bordeaux, France; Singapore Management University, Singapore, Singapore},
  Art_number               = {6498458},
  Author_keywords          = {benchmark; Bug Linking; empirical evaluation; missing links; ReLink},
  Document_type            = {Conference Paper},
  Doi                      = {10.1109/CSMR.2013.19},
  Journal                  = {Proceedings of the European Conference on Software Maintenance and Reengineering, CSMR},
  Source                   = {Scopus},
  Url                      = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84877295642&partnerID=40&md5=da4994b2d9c9f6047b7428a0958d4268}
}

@Conference{Breu2010301,
  Title                    = {Information needs in bug reports: Improving cooperation between developers and users},
  Author                   = {Breu, S.a and Premraj, R.b and Sillito, J.c and Zimmermann, T.c d },
  Year                     = {2010},
  Note                     = {cited By 47},
  Pages                    = {301-310},

  Abstract                 = {For many software projects, bug tracking systems play a central role in supporting collaboration between the developers and the users of the software. To better understand this collaboration and how tool support can be improved, we have quantitatively and qualitatively analysed the questions asked in a sample of 600 bug reports from the MOZILLA and ECLIPSE projects. We categorised the questions and analysed response rates and times by category and project. Our results show that the role of users goes beyond simply reporting bugs: their active and ongoing participation is important for making progress on the bugs they report. Based on the results, we suggest four ways in which bug tracking systems can be improved. Copyright 2010 ACM.},
  Affiliation              = {Computing Laboratory, University of Oxford, Oxford, United Kingdom; VU University Amsterdam, Amsterdam, Netherlands; University of Calgary, Calgary, AB, Canada; Microsoft Research, Redmond, WA, United States},
  Author_keywords          = {Bug reports; Information needs; Question time; Questions; Response rate; Response time},
  Document_type            = {Conference Paper},
  Doi                      = {10.1145/1718918.1718973},
  Journal                  = {Proceedings of the ACM Conference on Computer Supported Cooperative Work, CSCW},
  Source                   = {Scopus},
  Url                      = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-77950902825&partnerID=40&md5=cc07359cf5ac31f58760453669952060}
}

@Article{Callahan199825,
  Title                    = {Web-based issue tracking for large software projects},
  Author                   = {Callahan, J.R.a c d e and Khatsuriya, R.R.a f g and Hefner, R.b h i },
  Journal                  = {IEEE Internet Computing},
  Year                     = {1998},
  Note                     = {cited By 0},
  Number                   = {5},
  Pages                    = {25-33},
  Volume                   = {2},

  Abstract                 = {Many problems are found and fixed during the development of a software system. The Project Issue Tracking System toolkit, a Web-based issue-management tool, can be used to organize issue reports during development and to communicate with different project teams around the world.},
  Affiliation              = {West Virginia University, NASA/WVU Software Research Lab., United States; Intermetrics Inc., NASA Software IV and V Facility, United States; Dept. of Comp. Sci. and Elec. Eng., West Virginia University, Morgantown, WV, United States; NASA/WVU Software Res. Laboratory, NASA Software IV and V Facility, Fairmont, WV, United States; University of Maryland, College Park, MD, United States; West Virginia University, Morgantown, WV, United States; University of Pune, India; Intermetrics, Inc., EOSDIS IV and V Tools Development, United States; West Virginia University, United States},
  Document_type            = {Article},
  Doi                      = {10.1109/4236.722227},
  Source                   = {Scopus},
  Url                      = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-0032167146&partnerID=40&md5=d14ca2273f08a5788bcc27c4102da668}
}

@Article{Cavalcanti2014620,
  Title                    = {Challenges and opportunities for software change request repositories: A systematic mapping study},
  Author                   = {Cavalcanti, Y.C.a c d and Da Mota Silveira Neto, P.A.a c and Machado, I.D.C.b c and Vale, T.F.b c and De Almeida, E.S.b c and Meira, S.R.D.L.a c },
  Journal                  = {Journal of Software: Evolution and Process},
  Year                     = {2014},
  Note                     = {cited By 4},
  Number                   = {7},
  Pages                    = {620-653},
  Volume                   = {26},

  Abstract                 = {Software maintenance starts as soon as the first artifacts are delivered and is essential for the success of the software. However, keeping maintenance activities and their related artifacts on track comes at a high cost. In this respect, change request (CR) repositories are fundamental in software maintenance. They facilitate the management of CRs and are also the central point to coordinate activities and communication among stakeholders. However, the benefits of CR repositories do not come without issues, and commonly occurring ones should be dealt with, such as the following: duplicate CRs, the large number of CRs to assign, or poorly described CRs. Such issues have led researchers to an increased interest in investigating CR repositories, by considering different aspects of software development and CR management. In this paper, we performed a systematic mapping study to characterize this research field. We analyzed 142 studies, which we classified in two ways. First, we classified the studies into different topics and grouped them into two dimensions: challenges and opportunities. Second, the challenge topics were classified in accordance with an existing taxonomy for information retrieval models. In addition, we investigated tools and services for CR management, to understand whether and how they addressed the topics identified. Copyright © 2013 John Wiley & Sons, Ltd. Change request repositories are fundamental for software maintenance. However, their benefits do not come without issues. We analyzed 142 studies to characterize the research on these issues and provide directions for future investigation. The studies were classified into topics and grouped into two dimensions: challenges and opportunities. Then, the challenges were classified in accordance with an existing taxonomy for information retrieval models. Additionally, we investigated different change request repositories to understand whether and how they addressed the topics identified. Copyright © 2013 John Wiley & Sons, Ltd.},
  Affiliation              = {Center for Informatics, Federal University of Pernambuco (CIn/UFPE), Pernambuco, Recife, Brazil; Computer Science Department, Federal University of Bahia (DCC/UFBA), Salvador Bahia, Brazil; Reuse in Software Engineering Group (RiSE), Recife Pernambuco, Brazil; Brazilian Federal Organization for Data Processing (SERPRO), Florianõpolis Santa Catarina, Brazil},
  Author_keywords          = {bug report; bug tracking; change request repository; software evolution; software maintenance; software quality assurance},
  Document_type            = {Article},
  Doi                      = {10.1002/smr.1639},
  Source                   = {Scopus},
  Url                      = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84904626790&partnerID=40&md5=7e8fe6e32dba1cdb6f3f9a3e39b3fed1}
}

@Article{Chaturvedi201232,
  Title                    = {An empirical comparison of machine learning techniques in predicting the bug severity of open and closed source projects},
  Author                   = {Chaturvedi, K.K.a and Singh, V.B.b },
  Journal                  = {International Journal of Open Source Software and Processes},
  Year                     = {2012},
  Note                     = {cited By 3},
  Number                   = {2},
  Pages                    = {32-59},
  Volume                   = {4},

  Abstract                 = {Bug severity is the degree of impact that a defect has on the development or operation of a component or system, and can be classified into different levels based on their impact on the system. Identification of severity level can be useful for bug triager in allocating the bug to the concerned bug fixer. Various researchers have attempted text mining techniques in predicting the severity of bugs, detection of duplicate bug reports and assignment of bugs to suitable fixer for its fix. In this paper, an attempt has been made to compare the performance of different machine learning techniques namely Support vector machine (SVM), probability based Naïve Bayes (NB), Decision Tree based J48 (A Java implementation of C4.5), rule based Repeated Incremental Pruning to Produce Error Reduction (RIPPER) and Random Forests (RF) learners in predicting the severity level (1 to 5) of a reported bug by analyzing the summary or short description of the bug reports. The bug report data has been taken from NASA's PITS (Projects and Issue Tracking System) datasets as closed source and components of Eclipse, Mozilla & GNOME datasets as open source projects. The analysis has been carried out in RapidMiner and STATISTICA data mining tools. The authors measured the performance of different machine learning techniques by considering (i) the value of accuracy and F-Measure for all severity level and (ii) number of best cases at different threshold level of accuracy and F-Measure. Copyright © 2012, IGI Global.},
  Affiliation              = {Indian Agricultural Statistics Research Institute, New Delhi, Delhi, India; Delhi College of Arts and Commerce, University of Delhi, New Delhi, Delhi, India},
  Author_keywords          = {10-fold Cross Validation; Bug Repositories; Bug Severity; Multiclass Classification; Supervised Classification; Text Mining},
  Document_type            = {Article},
  Doi                      = {10.4018/jossp.2013040103},
  Source                   = {Scopus},
  Url                      = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84887444112&partnerID=40&md5=48b87d2fab9aac27d99dfaef17d16032}
}

@Conference{Chaturvedi2012,
  Title                    = {Determining Bug severity using machine learning techniques},
  Author                   = {Chaturvedi, K.K.a b and Singh, V.B.c },
  Year                     = {2012},
  Note                     = {cited By 0},

  Abstract                 = {Software Bug reporting is an integral part of software development process. Once the Bug is reported on Bug Tracking System, their attributes are analyzed and subsequently assigned to various fixers for their resolution. During the last two decades Machine-Learning Techniques (MLT) has been used to create self-improving software. Supervised machine learning technique is widely used for prediction of patterns in various applications but, we have found very few for software repositories. Bug severity, an attribute of a software bug report is the degree of impact that a defect has on the development or operation of a component or system. Bug severity can be classified into different levels based on their impact on the system. In this paper, an attempt has been made to demonstrate the applicability of machine learning algorithms namely Naïve Bayes, k-Nearest Neighbor, Naïve Bayes Multinomial, Support Vector Machine, J48 and RIPPER in determining the class of bug severity of bug report data of NASA from PROMISE repository. The applicability of algorithm in determining the various levels of bug severity for bug repositories has been validated using various performance measures by applying 5-fold cross validation1. © 2012 IEEE.},
  Affiliation              = {Department of Computer Science, University of Delhi, Delhi, India; Indian Agricultural Statistics Research Institute, PUSA, Library Avenue, New Delhi, India; Delhi College of Arts and Commerce, University of Delhi, Delhi, India},
  Art_number               = {6349519},
  Author_keywords          = {Bug Severity; Feature Selection; Machine Learning; Supervised Classification},
  Document_type            = {Conference Paper},
  Doi                      = {10.1109/CONSEG.2012.6349519},
  Journal                  = {2012 CSI 6th International Conference on Software Engineering, CONSEG 2012},
  Source                   = {Scopus},
  Url                      = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84870834685&partnerID=40&md5=8852ad41ddc91eee4f2c7c6196a75716}
}

@Article{Chen2011421,
  Title                    = {An approach to improving bug assignment with bug tossing graphs and bug similarities},
  Author                   = {Chen, L. and Wang, X. and Liu, C.},
  Journal                  = {Journal of Software},
  Year                     = {2011},
  Note                     = {cited By 5},
  Number                   = {3},
  Pages                    = {421-427},
  Volume                   = {6},

  Abstract                 = {In open-source software development a new bug firstly is found by developers or users. Then the bug is described as a bug report, which is submitted to a bug repository. Finally the bug triager checks the bug report and typically assigns a developer to fix the bug. The assignment process is time-consuming and error-prone. Furthermore, a large number of bug reports are tossed (reassigned) to other developers, which increases bug-fix time. In order to quickly identify the fixer to bug reports we present an approach based on the bug tossing history and textual similarities between bug reports. This proposed approach is evaluated on Eclipse and Mozilla. The results show that our approach can significantly improve the efficiency of bug assignment: the bug fixer is often identified with fewer tossing events. © 2011 ACADEMY PUBLISHER.},
  Affiliation              = {School of Computer Science and Engineering, Beihang University, Beijing, China},
  Author_keywords          = {Bug assignment; Bug reports; Bug tossing; Information retrieval; Software engineering},
  Document_type            = {Article},
  Doi                      = {10.4304/jsw.6.3.421-427},
  Source                   = {Scopus},
  Url                      = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-79953044218&partnerID=40&md5=8697856195e10e9ef29e767c37df4f2d}
}

@Conference{Corley201131,
  Title                    = {Recovering traceability links between source code and fixed bugs via patch analysis},
  Author                   = {Corley, C.S.a and Kraft, N.A.b and Etzkorn, L.H.c and Lukins, S.K.c },
  Year                     = {2011},
  Note                     = {cited By 0},
  Pages                    = {31-37},

  Abstract                 = {Traceability links can be recovered using data mined from a revision control system, such as CVS, and an issue tracking system, such as Bugzilla. Existing approaches to recover links between a bug and the methods changed to fix the bug rely on the presence of the bug's identifier in a CVS log message. In this paper we present an approach that relies instead on the presence of a patch in the issue report for the bug. That is, rather than analyzing deltas retrieved from CVS to recover links, our approach analyzes patches retrieved from Bugzilla. We use BugTrace, the tool implementing our approach, to conduct a case study in which we compare the links recovered by our approach to links recovered by manual inspection. The results of the case study support the efficacy of our approach. After describing the limitations of our case study, we conclude by reviewing closely related work and suggesting possible future work. © 2011 ACM.},
  Affiliation              = {Dept. of Mathematics and Computer Science, University of North Alabama, Florence, AL, United States; Department of Computer Science, University of Alabama, Tuscaloosa, AL, United States; Department of Computer Science, University of Alabama in Huntsville, Huntsville, AL, United States},
  Author_keywords          = {bug assignment; bug mapping; link recovery; mining software repositories; trace automation; traceability},
  Document_type            = {Conference Paper},
  Doi                      = {10.1145/1987856.1987863},
  Journal                  = {Proceedings - International Conference on Software Engineering},
  Source                   = {Scopus},
  Url                      = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-79959848546&partnerID=40&md5=33fce364b3b75e87e3b93a89e2a1df93}
}

@Conference{Correa201325,
  Title                    = {Samekana: A Browser Extension for including relevant web links in issue tracking system discussion forum},
  Author                   = {Correa, D.a and Lal, S.b and Saini, A.a and Sureka, A.a },
  Year                     = {2013},
  Note                     = {cited By 0},
  Pages                    = {25-33},
  Volume                   = {1},

  Abstract                 = {Several widely used Issue tracking systems (such as Google Issue Tracker and Bugzilla) contains an integrated threaded discussion forum to facilitate discussion between the development and maintenance team (bug reporters, bug triagers, bug fixers and quality assurance managers). We observe that several comments (and even bug report descriptions) posted to issue tracing system contains links to external websites as references to knowledge sources relevant to the discussion. We conduct a survey (and present the results of the survey) of Google Chromium Developers on the importance and usefulness of web references in issue tracking system comments and the need of a web-browser extension which facilitates easy organization and inclusion of web-links in the post. We conduct a characterization study on an experimental dataset from Google Chromium Issue Tracking system and present results on the distribution of number of links in the dataset, categorization of links into predefined classes (such as blogs, community based Q&A websites, developer discussion forums, version control system), correlation of number and types of links with various bug report types (such as security, crash, regression and clean-up) and relation between presence of links and bug resolution time. Survey results and data characterization study motivate the need of building a developer productivity tool to facilitate web-link (as references) organization and inclusion in issue tracking system comments. We present a Google ChromiumWeb Browser Extension called as Samekana and publish the extension on Google Chromium Web Store which can be freely downloaded by users worldwide. The extension contains features such as annotating (using tags, title and description) and saving web references pertaining to multiple bug reports and tasks and then posting it as bibliography (for easy citation and reference) in issue tracking system comments. © 2013 IEEE.},
  Affiliation              = {Indraprastha Institute of Information Technology, Delhi (IIITD), India; Jaypee Institute of Information Technology (JIIT), India},
  Art_number               = {6805386},
  Author_keywords          = {Developer productivity tool; Empirical Software Engineering and Measurements (ESEM); Mining bug reports; Mining Software Repositories (MSR); Software maintenance},
  Document_type            = {Conference Paper},
  Doi                      = {10.1109/APSEC.2013.15},
  Journal                  = {Proceedings - Asia-Pacific Software Engineering Conference, APSEC},
  Source                   = {Scopus},
  Url                      = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84936867035&partnerID=40&md5=22c146ae09f6391fd97534ddb797e1e9}
}

@Conference{Correa201388,
  Title                    = {Integrating issue tracking systems with community-based question and answering websites},
  Author                   = {Correa, D. and Sureka, A.},
  Year                     = {2013},
  Note                     = {cited By 0},
  Pages                    = {88-96},

  Abstract                 = {Issue tracking systems such as Bugzilla are tools to facilitate collaboration between software maintenance professionals. Popular issue tracking systems consists of discussion forums to facilitate bug reporting and comment posting. We observe that several comments posted in issue tracking system contains link to external websites such as YouTube (video sharing website), Twitter (micro-blogging website), Stack overflow (a community-based question and answering website for programmers), Wikipedia and focused discussions forums. Stack overflow is a popular community-based question and answering website for programmers and is widely used by software engineers as it contains answers to millions of questions (an extensive knowledge resource) posted by programmers on diverse topics. We conduct a series of experiments on open-source Google Chromium and Android issue tracker data (publicly available real-world dataset) to understand the role and impact of Stack overflow in issue resolution. Our experimental results show evidences of several references to Stack overflow in threaded discussions and demonstrate correlation between a lower mean time to repair (in one dataset) with presence of Stack overflow links. We also observe that the average number of comments posted in response to bug reports are less when Stack overflow links are presented in contrast to bug reports not containing Stack overflow references. We conduct experiments based on textual similarly analysis (content-based linguistic features) and contextual data analysis (exploited metadata such as tags associated to a Stack overflow question) to recommend Stack overflow questions for an incoming bug report. We perform empirical analysis to measure the effectiveness of the proposed method on a dataset containing ground-truth and present our insights. We present the result of a survey (of Google Chromium Developers) that we conducted to understand practitioner's perspective and experience. © 2013 IEEE.},
  Affiliation              = {Indraprastha Institute of Information Technology, Delhi (IIITD), New Delhi, India},
  Art_number               = {6601296},
  Author_keywords          = {Community Driven Q&amp;A Website; Empirical Software Engineering and Measurements (ESEM); Mining Bug Reports; Mining Software Repositories (MSR); Social Media for Software Engineering; Software Maintenance},
  Document_type            = {Conference Paper},
  Doi                      = {10.1109/ASWEC.2013.20},
  Journal                  = {Proceedings of the Australian Software Engineering Conference, ASWEC},
  Source                   = {Scopus},
  Url                      = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84885228502&partnerID=40&md5=2f9bfff2c74787b05d515477e1b3bd18}
}

@Article{Cosentino2015329,
  Title                    = {Gitana: A SQL-Based Git Repository Inspector},
  Author                   = {Cosentino, V.a and Izquierdo, J.L.C.a b and Cabot, J.b c },
  Journal                  = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  Year                     = {2015},
  Note                     = {cited By 0},
  Pages                    = {329-343},
  Volume                   = {9381},

  Abstract                 = {Software development projects are notoriously complex and difficult to deal with. Several support tools such as issue tracking, code review and Source Control Management (SCM) systems have been introduced in the past decades to ease development activities. While such tools efficiently track the evolution of a given aspect of the project (e.g., bug reports), they provide just a partial view of the project and often lack of advanced querying mechanisms limiting themselves to command line or simple GUI support. This is particularly true for projects that rely on Git, the most popular SCM system today. In this paper, we propose a conceptual schema for Git and an approach that, given a Git repository, exports its data to a relational database in order to (1) promote data integration with other existing SCM tools and (2) enable writing queries on Git data using standard SQL syntax. To ensure efficiency, our approach comes with an incremental propagation mechanism that refreshes the database content with the latest modifications. We have implemented our approach in Gitana, an open-source tool available on GitHub. © Springer International Publishing Switzerland 2015.},
  Affiliation              = {AtlanMod Team, Inria, Mines Nantes, LINA, Nantes, France; UOC, Barcelona, Spain; ICREA, Barcelona, Spain},
  Author_keywords          = {Conceptual schema; Git; SQL},
  Document_type            = {Conference Paper},
  Doi                      = {10.1007/978-3-319-25264-3_24},
  Source                   = {Scopus},
  Url                      = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84951821696&partnerID=40&md5=9056566e7599cccb1cb618764dc10429}
}

@Conference{Davies2014,
  Title                    = {What's in a bug report?},
  Author                   = {Davies, S. and Roper, M.},
  Year                     = {2014},
  Note                     = {cited By 1},

  Abstract                 = {Context: Bug reports are the primary means by which users of a system are able to communicate a problem to the developers, and their contents are important - not only to support developers in maintaining the system, but also as the basis of automated tools to assist in the challenging tasks of finding and fixing bugs. Goal: This paper aims to investigate how users report bugs in systems: what information is provided, how frequently, and the consequences of this. Method: The study examined the quality and quantity of information provided in 1600 bugs reports drawn from four open-source projects (Eclipse, Firefox, Apache HTTP, and Facebook API), recorded what information users actually provide, how and when users provide the information, and how this affects the outcome of the bug. Results: Of the recorded sources of information, only observed behaviour and expected results appeared in more than 50% of reports. Those sources deemed highly useful by developers and tools such as stack traces and test cases appeared very infrequently. However, no strong relationship was observed between the provided information and the outcome of the bug. Conclusions: The paper demonstrates a clear mismatch between the information that developers would wish to appear in a bug report, and the information that actually appears. Furthermore, the quality of bug reports has an important impact on research which might rely on extracting this information automatically. © 2014 ACM.},
  Affiliation              = {Dept. Computer and Information Sciences, University of Strathclyde, Glasgow, United Kingdom},
  Art_number               = {a26},
  Author_keywords          = {bug report; bug repository; software maintenance},
  Document_type            = {Conference Paper},
  Doi                      = {10.1145/2652524.2652541},
  Journal                  = {International Symposium on Empirical Software Engineering and Measurement},
  Source                   = {Scopus},
  Url                      = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84907858877&partnerID=40&md5=521e74972da9fa20de459d9a8b6e896a}
}

@Article{Davies2014107,
  Title                    = {Comparing text-based and dependence-based approaches for determining the origins of bugs},
  Author                   = {Davies, S. and Roper, M. and Wood, M.},
  Journal                  = {Journal of software: Evolution and Process},
  Year                     = {2014},
  Note                     = {cited By 1},
  Number                   = {1},
  Pages                    = {107-139},
  Volume                   = {26},

  Abstract                 = {Identifying bug origins - the point where erroneous code was introduced - is crucial for many software engineering activities, from identifying process weaknesses to gathering data to support bug detection tools. Unfortunately, this information is not usually recorded when fixing bugs, and recovering it later is challenging. Recently, the text approach and the dependence approach have been developed to tackle this problem. Respectively, they examine textual and dependence-related changes that occurred prior to a bug fix. However, only limited evaluation has been carried out, partially because of a lack of available implementations and of datasets linking bugs to origins. To address this, origins of 174 bugs in three projects were manually identified and compared to a simulation of the approaches. Both approaches were partially successful across a variety of bugs - achieving 29-79% precision and 40-70% recall. Results suggested the precise definition of program dependence could affect performance, as could whether the approaches identified a single or multiple origins. Some potential improvements are explored in detail and identify pragmatic strategies for combining techniques along with simple modifications. Even after adopting these improvements, there remain many challenges: large commits, unrelated changes and long periods between origins and fixes all reduce effectiveness. Copyright © 2013 John Wiley & Sons, Ltd.},
  Affiliation              = {Computer and Information Sciences, University of Strathclyde, Glasgow, United Kingdom},
  Author_keywords          = {Bug origins; Bug tracking systems; Mining software repositories; Program dependence graph; Software maintenance; Version control},
  Document_type            = {Conference Paper},
  Doi                      = {10.1002/smr.1619},
  Source                   = {Scopus},
  Url                      = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84899098981&partnerID=40&md5=f5dbcb1edc925116a78fe547989d800f}
}

@Article{DeCastroNetto2016239,
  Title                    = {An Automated Approach for Scheduling Bug Fix Tasks},
  Author                   = {De Castro Netto, F. and De Oliveira Barros, M. and Alvim, A.C.F.},
  Journal                  = {International Journal of Software Engineering and Knowledge Engineering},
  Year                     = {2016},
  Note                     = {cited By 0},
  Number                   = {2},
  Pages                    = {239-271},
  Volume                   = {26},

  Abstract                 = {Software projects usually maintain bug repositories where both developers and end users can report and track the resolution of software defects. These defects should be fixed and new versions of the software incorporating the patches that solve them must be released. The project manager must schedule a set of error correction tasks with different priorities in order to minimize the time required to accomplish these tasks and guarantee that the more important issues have been fixed. This problem is recurrent for most software organizations and, given the enormous number of potential schedules, a tool that searches for good schedules may be helpful to project managers. In this work we propose a genetic algorithm using information captured from bug repositories to find near optimal schedules. We evaluated our approach using a subset of the Eclipse bug repository and the results suggested better schedules than the schedule followed by the developers and schedules proposed by a simpler search procedure. © 2016 World Scientific Publishing Company.},
  Affiliation              = {Postgraduate Information Systems Program - UNIRIO, Federal University of Rio de Janeiro State, Av. Pasteur 458, Urca - Rio de Janeiro, RJ, Brazil},
  Author_keywords          = {bug fix tasks scheduling; bug tracking systems; genetic algorithm; software maintenance; Software project management},
  Document_type            = {Article},
  Doi                      = {10.1142/S021819401650011X},
  Source                   = {Scopus},
  Url                      = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84966270943&partnerID=40&md5=476a2827b2c7085a2ddaef2464675816}
}

@Article{Feng2013709,
  Title                    = {Practical duplicate bug reports detection in a large web-based development community},
  Author                   = {Feng, L.a and Song, L.a and Sha, C.b and Gong, X.a },
  Journal                  = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  Year                     = {2013},
  Note                     = {cited By 0},
  Pages                    = {709-720},
  Volume                   = {7808 LNCS},

  Abstract                 = {Most of large web-based development communities require a bug tracking system to keep track of various bug reports. However, duplicate bug reports tend to result in waste of resources, and may cause potential conflicts. There have been two types of works focusing on this problem: relevant bug report retrieval [8][11][10][13] and duplicate bug report identification [5][12]. The former methods can achieve high accuracy (82%) in the top 10 results in some dataset, but they do not really reduce the workload of developers. The latter methods still need further improvement on the performance. In this paper, we propose a practical duplicate bug reports detection method, which aims to help project team to reduce their workload by combining existing two categories of methods. We also propose some new features extracted from comments, user profiles and query feedback, which are useful for improving the detection performance. Experiments on real dataset show that our method improves the accuracy rate by 23% compared to state-of-the-art work in duplicate bug report identification, and improves the recall rate by up to 8% in relevant bug report retrieval. © 2013 Springer-Verlag.},
  Affiliation              = {Software Engineering Institute, East China Normal University, China; School of Computer Science, Fudan University, China},
  Author_keywords          = {Bug Report; Classification; Duplicate Detection},
  Document_type            = {Conference Paper},
  Doi                      = {10.1007/978-3-642-37401-2_69},
  Source                   = {Scopus},
  Url                      = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84875826407&partnerID=40&md5=3f8fd101894173ea1031268c5865fb36}
}

@Conference{Ghezzi201193,
  Title                    = {SOFAS: A lightweight architecture for software analysis as a service},
  Author                   = {Ghezzi, G. and Gall, H.C.},
  Year                     = {2011},
  Note                     = {cited By 7},
  Pages                    = {93-102},

  Abstract                 = {Access to data stored in software repositories by systems such as version control, bug and issue tracking, or mailing lists is essential for assessing the quality of a software system. A myriad of analyses exploiting that data have been proposed throughout the years: source code analysis, code duplication analysis, co-change analysis, bug prediction, or detection of bug fixing patterns. However, easy and straight forward synergies between these analyses rarely exist. To tackle this problem we have developed SOFA S, a distributed and collaborative software analysis platform to enable a seamless interoperation of such analyses. In particular, software analyses are offered as RESTful web services that can be accessed and composed over the Internet. SOFA S services are accessible through a software analysis catalog where any project stakeholder can, depending on the needs or interests, pick specific analyses, combine them, let them run remotely and then fetch the final results. That way, software developers, testers, architects, or quality assurance experts are given access to quality analysis services. They are shielded from many peculiarities of tool installations and configurations, but SOFA S offers them sophisticated and easy-to-use analyses. This paper describes in detail our SOFAS architecture, its considerations and implementation aspects, and the current set of implemented and offered RESTful analysis services. © 2011 IEEE.},
  Affiliation              = {S.e.a.l. - Software Evolution and Architecture Lab., Department of Informatics, University of Zurich, Switzerland},
  Art_number               = {5959723},
  Document_type            = {Conference Paper},
  Doi                      = {10.1109/WICSA.2011.21},
  Journal                  = {Proceedings - 9th Working IEEE/IFIP Conference on Software Architecture, WICSA 2011},
  Source                   = {Scopus},
  Url                      = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-80051965439&partnerID=40&md5=6e9553a580b709d2114c87bed9f4ae76}
}

@Book{Gunderloy20051,
  Title                    = {Painless project management with FogBugz},
  Author                   = {Gunderloy, M.},
  Year                     = {2005},
  Note                     = {cited By 0},

  Abstract                 = {A very well put together manual about how and why things work the way they do within FogBugz 4.0. - Matt Hawley, eWorld.UI This book is an almost perfect introduction and end user manual for FogBugz version 4. - Dean Wilson, London.pm I recommend this book if you do plan to use FogBugz. - Greg Robinson's Blog & well written and easy to get through & - .farshid sedghi Blog I quickly realized that FogBugz could single-handedly manage my support requests, sales requests, bug tracking and project management for CodeSmith. I bought my copy about a week ago and I could not be more happy with my purchase! - Eric J. Smith's Weblog Many programs purport to help a development team manage a projectbut most of them aren't very good. Enter FogBugz. This dynamic tool is based on keeping track of a database of cases. At any given time, cases are assigned to one person, who must resolve or forward them to someone else. With FogBugz, cases can be prioritized, documented, sorted, discussed, edited, assigned, estimated, searched, and tracked. And because FogBugz is web-based, everyone on a development team has access to the whole picture, at any given moment. That picture may include everything from customer feature requests, to high-level design discussions, to tiny bug fix details. This book (written under the guidance of the entire FogBugz team) completely describes the ins and outs of the latest version of FogBugz. Copyright © 2005 by Mike Gunderloy. All rights reserved.},
  Document_type            = {Book},
  Doi                      = {10.1007/978-1-4302-0008-6},
  Journal                  = {Painless Project Management with FogBugz},
  Pages                    = {1-184},
  Source                   = {Scopus},
  Url                      = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84892242200&partnerID=40&md5=e490d1477155b0ba1db73d2b9583ad4c}
}

@Conference{Gupta2014,
  Title                    = {Nirikshan: Mining bug report history for discovering process maps, inefficiencies and inconsistencies},
  Author                   = {Gupta, M. and Sureka, A.},
  Year                     = {2014},
  Note                     = {cited By 0},

  Abstract                 = {Issue tracking systems such as Bugzilla, Mantis and JIRA are Process Aware Information Systems to support business process of issue (defect and feature enhancement) reporting and resolution. The process of issue reporting to resolution consists of several steps or activities performed by various roles (bug reporter, bug triager, bug fixer, developers, and quality assurance manager) within the software maintenance team. Project teams define a workflow or a business process (design time process model and guidelines) to streamline and structure the issue management activities. However, the runtime process (reality) may not conform to the design time model and can have imperfections or inefficiencies. We apply business process mining tools and techniques to analyze the event log data (bug report history) generated by an issue tracking system with the objective of discovering runtime process maps, inefficiencies and inconsistencies. We conduct a case-study on data extracted from Bugzilla issue tracking system of the popular open-source Firefox browser project. We present and implement a process mining framework, Nirikshan, consisting of various steps: data extraction, data transformation, process discovery, performance analysis and conformance checking. We conduct a series of process mining experiments to study self-loops, back-andforth, issue reopen, unique traces, event frequency, activity frequency, bottlenecks and present an algorithm and metrics to compute the degree of conformance between the design time and the runtime process. Copyright 2014 ACM.},
  Affiliation              = {Indraprastha Institute of Information Technology, Delhi (IIITD), New Delhi, India},
  Author_keywords          = {Empirical software engineering and measurements; Issue tracking system; Mining software repositories; Open-Source software; Process mining; Software maintenance},
  Document_type            = {Conference Paper},
  Doi                      = {10.1145/2590748.2590749},
  Journal                  = {ACM International Conference Proceeding Series},
  Source                   = {Scopus},
  Url                      = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84902603190&partnerID=40&md5=48d36a99fac9fd346bd3f9d68466c639}
}

@Conference{Gupta2014239,
  Title                    = {Process cube for software defect resolution},
  Author                   = {Gupta, M. and Sureka, A.},
  Year                     = {2014},
  Note                     = {cited By 0},
  Pages                    = {239-246},
  Volume                   = {1},

  Abstract                 = {Online Analytical Processing (OLAP) cube is a multi-dimensional dataset used for analyzing data in a Data Warehouse (DW) for the purpose of extracting actionable intelligence. Process mining consists of analyzing event log data produced from Process Aware Information Systems (PAIS) for the purpose of discovering and improving business processes. Process cube is a concept which falls at the intersection of OLAP cube and process mining. Process cube facilitates process mining from multiple-dimensions and enables comparison of process mining results across various dimensions. We present an application of process cube to software defect resolution process to analyze and compare process data from a multi-dimensional perspective. We present a framework, a novel perspective to mine software repositories using process cube. Each cell of process cube is defined by metrics from multiple process mining perspectives like control flow, time, conformance and organizational perspective. We conduct a case-study on Google Chromium project data in which the software defect resolution process spans three software repositories: Issue Tracking System (ITS), Peer Code Review System (PCR) and Version Control System (VCS). We define process cube with 9 dimensions as issue report timestamp, priority, state, closed status, OS, component, bug type, reporter and owner. We define hierarchies along various dimensions and cluster members to handle sparsity. We apply OLAP cube operations such as slice, dice, roll-up and drill-down, and create materialized sublog for each cell. We demonstrate the solution approach by discovering process map and compare process mining results from control flow and time perspective for Performance and Security issues. © 2014 IEEE.},
  Affiliation              = {Indraprastha Institute of Information Technology, Delhi (IIITD), New Delhi, India},
  Art_number               = {7091316},
  Author_keywords          = {Empirical Software Engineering; Issue Tracking System; Mining Software Repositories; OLAP; Peer Code Review System; Process Cube; Process Mining; Version Control System.},
  Document_type            = {Conference Paper},
  Doi                      = {10.1109/APSEC.2014.45},
  Journal                  = {Proceedings - Asia-Pacific Software Engineering Conference, APSEC},
  Source                   = {Scopus},
  Url                      = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84951277134&partnerID=40&md5=b6dbb08c0bf69c83d7536667adbd9379}
}

@Article{Gyimesi201547,
  Title                    = {Characterization of source code defects by data mining conducted on GitHub},
  Author                   = {Gyimesi, P. and Gyimesi, G. and Tóth, Z. and Ferenc, R.},
  Journal                  = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  Year                     = {2015},
  Note                     = {cited By 0},
  Pages                    = {47-62},
  Volume                   = {9159},

  Abstract                 = {In software systems the coding errors are unavoidable due to the frequent source changes, the tight deadlines and the inaccurate specifications. Therefore, it is important to have tools that help us in finding these errors. One way of supporting bug prediction is to analyze the characteristics of the previous errors and identify the unknown ones based on these characteristics. This paper aims to characterize the known coding errors. Nowadays, the popularity of the source code hosting services like GitHub are increasing rapidly. They provide a variety of services, among which the most important ones are the version and bug tracking systems. Version control systems store all versions of the source code, and bug tracking systems provide a unified interface for reporting errors. Bug reports can be used to identify the wrong and the previously fixed source code parts, thus the bugs can be characterized by static source code metrics or by other quantitatively measured properties using the gathered data. We chose GitHub for the base of data collection and we selected 13 Java projects for analysis. As a result, a database was constructed, which characterizes the bugs of the examined projects, thus can be used, inter alia, to improve the automatic detection of software defects. © Springer International Publishing Switzerland 2015.},
  Affiliation              = {Department of Software Engineering, University of Szeged, Szeged, Hungary},
  Author_keywords          = {Bug database; Data mining; GitHub},
  Document_type            = {Conference Paper},
  Doi                      = {10.1007/978-3-319-21413-9_4},
  Source                   = {Scopus},
  Url                      = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84949035043&partnerID=40&md5=ba165cfec7835e69230732297c5f7f39}
}

@Article{Hindle2016368,
  Title                    = {A contextual approach towards more accurate duplicate bug report detection and ranking},
  Author                   = {Hindle, A. and Alipour, A. and Stroulia, E.},
  Journal                  = {Empirical Software Engineering},
  Year                     = {2016},
  Note                     = {cited By 0},
  Number                   = {2},
  Pages                    = {368-410},
  Volume                   = {21},

  Abstract                 = {The issue-tracking systems used by software projects contain issues, bugs, or tickets written by a wide variety of bug reporters, with different levels of training and knowledge about the system under development. Typically, reporters lack the skills and/or time to search the issue-tracking system for similar issues already reported. As a result, many reports end up referring to the same issue, which effectively makes the bug-report triaging process time consuming and error prone. Many researchers have approached the bug-deduplication problem using off-the-shelf information-retrieval (IR) tools. In this work, we extend the state of the art by investigating how contextual information about software-quality attributes, software-architecture terms, and system-development topics can be exploited to improve bug deduplication. We demonstrate the effectiveness of our contextual bug-deduplication method at ranking duplicates on the bug repositories of the Android, Eclipse, Mozilla, and OpenOffice software systems. Based on this experience, we conclude that taking into account domain-specific context can improve IR methods for bug deduplication. © 2015, Springer Science+Business Media New York.},
  Affiliation              = {Department of Computing Science, University of Alberta, Edmonton, AB, Canada},
  Author_keywords          = {Bug deduplication; Bug-tracing systems; Duplicate bug reports; Information retrieval; Issue-tracking systems; Software context; Triaging},
  Document_type            = {Article},
  Doi                      = {10.1007/s10664-015-9387-3},
  Source                   = {Scopus},
  Url                      = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84933576492&partnerID=40&md5=dfd3386ead96b944aac17e24198bb08f}
}

@Conference{Jalbert200852,
  Title                    = {Automated duplicate detection for bug tracking systems},
  Author                   = {Jalbert, N. and Weimer, W.},
  Year                     = {2008},
  Note                     = {cited By 70},
  Pages                    = {52-61},

  Abstract                 = {Bug tracking systems are important tools that guide the maintenance activities of software developers. The utility of these systems is hampered by an excessive number of duplicate bug reports-in some projects as many as a quarter of all reports are duplicates. Developers must manually identify duplicate bug reports, but this identification process is time-consuming and exacerbates the already high cost of software maintenance. We propose a system that automatically classifies duplicate bug reports as they arrive to save developer time. This system uses surface features, textual semantics, and graph clustering to predict duplicate status. Using a dataset of 29,000 bug reports from the Mozilla project, we perform experiments that include a simulation of a real-time bug reporting environment. Our system is able to reduce development cost by filtering out 8% of duplicate bug reports while allowing at least one report for each real defect to reach developers. © 2008 IEEE.},
  Affiliation              = {University of Virginia, Charlottesville, VA 22904, United States},
  Art_number               = {4630070},
  Document_type            = {Conference Paper},
  Doi                      = {10.1109/DSN.2008.4630070},
  Journal                  = {Proceedings of the International Conference on Dependable Systems and Networks},
  Source                   = {Scopus},
  Url                      = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-53349154094&partnerID=40&md5=f433542303407393fb9d35ea432f497c}
}

@Conference{Jeong2009111,
  Title                    = {Improving bug triage with bug tossing graphs},
  Author                   = {Jeong, G.a and Kim, S.b and Zimmermann, T.c },
  Year                     = {2009},
  Note                     = {cited By 95},
  Pages                    = {111-120},

  Abstract                 = {A bug report is typically assigned to a single developer who is then responsible for fixing the bug. In Mozilla and Eclipse, between 37%-44% of bug reports are "tossed" (reassigned) to other developers, for example because the bug has been assigned by accident or another developer with additional expertise is needed. In any case, tossing increases the time-to-correction for a bug. In this paper, we introduce a graph model based on Markov chains, which captures bug tossing history. This model has several desirable qualities. First, it reveals developer networks which can be used to discover team structures and to find suitable experts for a new task. Second, it helps to better assign developers to bug reports. In our experiments with 445,000 bug reports, our model reduced tossing events, by up to 72%. In addition, the model increased the prediction accuracy by up to 23 percentage points compared to traditional bug triaging approaches. Copyright 2009 ACM.},
  Affiliation              = {Seoul National University, South Korea; Hong Kong University of Science and Technology, Hong Kong; Microsoft Research, India},
  Author_keywords          = {Bug report assignment; Bug tossing; Bug triage; Issue tracking; Machine learning; Problem tracking},
  Document_type            = {Conference Paper},
  Doi                      = {10.1145/1595696.1595715},
  Journal                  = {ESEC-FSE'09 - Proceedings of the Joint 12th European Software Engineering Conference and 17th ACM SIGSOFT Symposium on the Foundations of Software Engineering},
  Source                   = {Scopus},
  Url                      = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-77949344285&partnerID=40&md5=120d5bbdc482da4becbd3242c103500a}
}

@Conference{Lal2012517,
  Title                    = {Comparison of seven bug report types: A case-study of Google chrome browser project},
  Author                   = {Lal, S.a and Sureka, A.b },
  Year                     = {2012},
  Note                     = {cited By 4},
  Pages                    = {517-526},
  Volume                   = {1},

  Abstract                 = {Bug reports submitted to an issue tracking system can belong to different categories such as crash, regression, security, cleanup, polish, performance and usability. A deeper understanding of the properties and features of various categories of bug reports can have implications in improving software maintenance processes, tools and practices. We identify several metrics and characteristics serving as dimensions on which various types of bug reports can be compared. We perform a case-study on Google Chromium Browser open-source project and conduct a series of experiments to calculate various metrics. We present a characterization study comparing different types of bug reports on metrics such as: statistics on close-time, number of stars, number of comments, discriminatory and frequent words for each class, entropy across reporters, entropy across component, opening and closing trend, continuity and debugging efficiency performance characteristics. The calculated metrics shows the similarities and differences on various dimensions for seven different types of bug reports. © 2012 IEEE.},
  Affiliation              = {Jaypee Institute of Information Technology, Noida, India; Indraprastha Institute of Information Technology (IIIT-D), New Delhi, India},
  Art_number               = {6462705},
  Author_keywords          = {Issue Tracking Systems; Mining Bug Archives; Mining Software Repositories; Software Maintenance},
  Document_type            = {Conference Paper},
  Doi                      = {10.1109/APSEC.2012.54},
  Journal                  = {Proceedings - Asia-Pacific Software Engineering Conference, APSEC},
  Source                   = {Scopus},
  Url                      = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84874610852&partnerID=40&md5=a5f647ca062dfcaf6e2a4a66bedafb54}
}

@Conference{Lerch201369,
  Title                    = {Finding duplicates of your yet unwritten bug report},
  Author                   = {Lerch, J. and Mezini, M.},
  Year                     = {2013},
  Note                     = {cited By 3},
  Pages                    = {69-78},

  Abstract                 = {Software projects often use bug-tracking tools to keep track of reported bugs and to provide a communication platform to discuss possible solutions or ways to reproduce failures. The goal is to reduce testing efforts for the development team. However, often, multiple bug reports are committed for the same bug, which, if not recognized as duplicates, can result in work done multiple times by the development team. Duplicate recognition is, in turn, tedious, requiring to examine large amounts of bug reports. Previous work addresses this problem by employing natural-language processing and text similarity measures to automate bug-report duplicate detection. The downside of these techniques is that, to be applicable, they require a reporting user to go through the time-consuming process of describing the problem, just to get informed that the bug is already known. To address this problem, we propose an approach that only uses stack traces and their structure as input to machine-learning algorithms for detecting bug-report duplicates. The key advantage is that stack traces are available without a written bug report. Experiments on bug reports from the Eclipse project show that our approach performs as good as state-of-the-art techniques, but without requiring the whole text corpus of a bug report to be available. © 2013 IEEE.},
  Affiliation              = {Technische Universität Darmstadt, Darmstadt, Germany},
  Art_number               = {6498456},
  Author_keywords          = {bug report; duplicate detection; stack trace},
  Document_type            = {Conference Paper},
  Doi                      = {10.1109/CSMR.2013.17},
  Journal                  = {Proceedings of the European Conference on Software Maintenance and Reengineering, CSMR},
  Source                   = {Scopus},
  Url                      = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84877296572&partnerID=40&md5=15d728dec3a96cd0044ee390b6c2db76}
}

@Conference{Lotufo20122,
  Title                    = {Towards improving bug tracking systems with game mechanisms},
  Author                   = {Lotufo, R. and Passos, L. and Czarnecki, K.},
  Year                     = {2012},
  Note                     = {cited By 0},
  Pages                    = {2-11},

  Abstract                 = {Low bug report quality and human conflicts pose challenges to keep bug tracking systems productive. This work proposes to address these issues by applying game mechanisms to bug tracking systems. We investigate the use of game mechanisms in Stack Overflow, an online community organized to resolve computer programming related problems, for which the improvements we seek for bug tracking systems also turn out to be relevant. The results of our Stack Overflow investigation show that its game mechanisms could be used to address these issues by motivating contributors to increase contribution frequency and quality, by filtering useful contributions, and by creating an agile and dependable moderation system. We proceed by mapping these mechanisms to open-source bug tracking systems, and find that most benefits are applicable. Additionally, our results motivate tailoring a reward and reputation system and summarizing bug reports as future directions for increasing the benefits of game mechanisms in bug tracking systems. © 2012 IEEE.},
  Affiliation              = {University of Waterloo, Canada},
  Art_number               = {6224293},
  Document_type            = {Conference Paper},
  Doi                      = {10.1109/MSR.2012.6224293},
  Journal                  = {IEEE International Working Conference on Mining Software Repositories},
  Source                   = {Scopus},
  Url                      = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84865142761&partnerID=40&md5=001e3ff8659af56ee87a377095221940}
}

@Conference{Michail2005107,
  Title                    = {Helping users avoid bugs in GUI applications},
  Author                   = {Michail, A.a and Xie, T.b },
  Year                     = {2005},
  Note                     = {cited By 10},
  Pages                    = {107-116},

  Abstract                 = {In this paper, we propose a method to help users avoid bugs in GUI applications. In particular, users would use the application normally and report bugs that they encounter to prevent anyone - including themselves - from encountering those bugs again. When a user attempts an action that has led to problems in the past, he/she will receive a warning and will be given the opportunity to abort the action thus avoiding the bug altogether and keeping the application stable. Of course, bugs should be fixed eventually by the application developers, but our approach allows application users to collaboratively help each other avoid bugs - thus making the application more usable in the meantime. We demonstrate this approach using our "Stabilizer" prototype. We also include a preliminary evaluation of the Stabilizer's bug prediction. Copyright 2005 ACM.},
  Affiliation              = {School of Computer Science and Engineering, University of New South Wales, Sydney, NSW 2052, Australia; Dept. of Computer Science and Engineering, University of Washington, Seattle, WA 98195, United States},
  Author_keywords          = {Bug prediction; Bug tracking system; Fault evasion; Gui applications; Software testing; Software tools},
  Document_type            = {Conference Paper},
  Journal                  = {Proceedings - 27th International Conference on Software Engineering, ICSE05},
  Source                   = {Scopus},
  Url                      = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-33244477851&partnerID=40&md5=4f91a116b40003ab05d09728883da438}
}

@Conference{Murgia2014262,
  Title                    = {Do developers feel emotions? An exploratory analysis of emotions in software artifacts},
  Author                   = {Murgia, A.a and Tourani, P.b and Adams, B.b and Ortu, M.c },
  Year                     = {2014},
  Note                     = {cited By 9},
  Pages                    = {262-271},

  Abstract                 = {Software development is a collaborative activity in which developers interact to create and maintain a complex software system. Human collaboration inevitably evokes emotions like joy or sadness, which can affect the collaboration either positively or negatively, yet not much is known about the individual emotions and their role for software development stakeholders. In this study, we analyze whether development artifacts like issue reports carry any emotional information about software development. This is a first step towards verifying the feasibility of an automatic tool for emotion mining in software development artifacts: if humans cannot determine any emotion from a software artifact, neither can a tool. Analysis of the Apache Software Foundation issue tracking system shows that developers do express emotions (in particular gratitude, joy and sadness). However, the more context is provided about an issue report, the more human raters start to doubt and nuance their interpretation of emotions. More investigation is needed before building a fully automatic emotion mining tool. Copyright is held by the author/owner(s). Publication rights licensed to ACM.},
  Affiliation              = {University of Antwerp, Belgium; Polytechnique Montréal, Canada; University of Cagliari, Italy},
  Author_keywords          = {Emotion mining; Empirical software engineering; Issue report},
  Document_type            = {Conference Paper},
  Doi                      = {10.1145/2597073.2597086},
  Journal                  = {11th Working Conference on Mining Software Repositories, MSR 2014 - Proceedings},
  Source                   = {Scopus},
  Url                      = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84938816347&partnerID=40&md5=4026a33b8ade87144c7273a64c4d4cfa}
}

@Conference{Netto201080,
  Title                    = {An automated approach for scheduling bug fix tasks},
  Author                   = {Netto, F. and Barros, M. and Alvim, A.C.F.},
  Year                     = {2010},
  Note                     = {cited By 1},
  Pages                    = {80-89},

  Abstract                 = {Even if a development team uses the best Software Engineering practices to produce high-quality software, end users may find defects that were not previously identified during the software development life-cycle. These defects must be fixed and new versions of the software incorporating the patches that solve them must be released. The project manager must schedule a set of error correction tasks with different priorities in order to minimize the time required to accomplish these tasks and guarantee that the more important issues have been fixed. Given the large number of distinct schedules, an automatically tool to find good schedules may be helpful to project managers. This work proposes a method which captures relevant information from bug repositories and submits them to a genetic algorithm to find near optimal bug correction task schedules. We have evaluated the approach using a subset of the Eclipse bug repository and it suggested better schedules than the actual schedules followed by Eclipse developers. © 2010 IEEE.},
  Affiliation              = {Departamento de Informática Aplicada, Universidade Federal do Estado do Rio de Janeiro (UNIRIO), Brazil},
  Art_number               = {5631516},
  Document_type            = {Conference Paper},
  Doi                      = {10.1109/SBES.2010.16},
  Journal                  = {Proceedings - 24th Brazilian Symposium on Software Engineering, SBES 2010},
  Source                   = {Scopus},
  Url                      = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-79952056393&partnerID=40&md5=24c54212217ce8d08383b88f66584a61}
}

@Conference{OcarizaJr.201355,
  Title                    = {An empirical study of client-side JavaScript bugs},
  Author                   = {Ocariza Jr., F. and Bajaj, K. and Pattabiraman, K. and Mesbah, A.},
  Year                     = {2013},
  Note                     = {cited By 16},
  Pages                    = {55-64},

  Abstract                 = {Context: Client-side JavaScript is widely used in web applications to improve user-interactivity and minimize client-server communications. Unfortunately, web applications are prone to JavaScript faults. While prior studies have demonstrated the prevalence of these faults, no attempts have been made to determine their root causes and consequences. Objective: The goal of our study is to understand the root causes and impact of JavaScript faults and how the results can impact JavaScript programmers, testers and tool developers. Method: We perform an empirical study of 317 bug reports from 12 bug repositories. The bug reports are thoroughly examined to classify and extract information about the fault's cause (the error) and consequence (the failure and impact). Result: The majority (65%) of JavaScript faults are DOM-related, meaning they are caused by faulty interactions of the JavaScript code with the Document Object Model (DOM). Further, 80% of the highest impact JavaScript faults are DOM-related. Finally, most JavaScript faults originate from programmer mistakes committed in the JavaScript code itself, as opposed to other web application components such as the server-side or HTML code. Conclusion: Given the prevalence of DOM-related faults, JavaScript programmers need development tools that can help them reason about the DOM. Also, testers should prioritize detection of DOM-related faults as most high impact faults belong to this category. Finally, developers can use the error patterns we found to design more powerful static analysis tools for JavaScript. © 2013 IEEE.},
  Affiliation              = {University of British Columbia, Vancouver, BC, Canada},
  Art_number               = {6681338},
  Author_keywords          = {Document Object Model (DOM); empirical study; JavaScript},
  Document_type            = {Conference Paper},
  Doi                      = {10.1109/ESEM.2013.18},
  Journal                  = {International Symposium on Empirical Software Engineering and Measurement},
  Source                   = {Scopus},
  Url                      = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84893300715&partnerID=40&md5=0d4a67c3b8bd3fc60a3ad5ac9479f310}
}

@Conference{Ortu2015,
  Title                    = {The JIRA repository dataset: Understanding social aspects of software development},
  Author                   = {Ortu, M.a and Destefanis, G.b and Adams, B.d and Murgia, A.c and Marchesi, M.a and Tonelli, R.a },
  Year                     = {2015},
  Note                     = {cited By 0},
  Volume                   = {2015-October},

  Abstract                 = {Issue tracking systems store valuable data for testing hypotheses concerning maintenance, building statistical prediction models and recently investigating developers "affectiveness". In particular, the Jira Issue Tracking System is a proprietary tracking system that has gained a tremendous popularity in the last years and offers unique features like the project management system and the Jira agile kanban board. This paper presents a dataset extracted from the Jira ITS of four popular open source ecosystems (as well as the tools and infrastructure used for extraction) the Apache Software Foundation, Spring, JBoss and CodeHaus communities. Our dataset hosts more than 1K projects, containing more than 700K issue reports and more than 2 million issue comments. Using this data, we have been able to deeply study the communication process among developers, and how this aspect affects the development process. Further-more, comments posted by developers contain not only technical information, but also valuable information about sentiments and emotions. Since sentiment analysis and human aspects in software engineering are gaining more and more importance in the last years, with this repository we would like to encourage further studies in this direction. © 2015 ACM.},
  Affiliation              = {DIEE, University of Cagliari, Italy; CRIM, Computer Research Institute of Montreal, Canada; University of Antwerp, Belgium; École Polytechnique de Montréal, Canada},
  Author_keywords          = {Affective Analysis; Issue Report; Mining software repository},
  Document_type            = {Conference Paper},
  Doi                      = {10.1145/2810146.2810147},
  Journal                  = {ACM International Conference Proceeding Series},
  Source                   = {Scopus},
  Url                      = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84947571324&partnerID=40&md5=b745a5ff018ff8c5f9f3827219f7fcd5}
}

@Conference{Prifti2011,
  Title                    = {Detecting bug duplicate reports through local references},
  Author                   = {Prifti, T. and Banerjee, S. and Cukic, B.},
  Year                     = {2011},
  Note                     = {cited By 0},

  Abstract                 = {Background: Bug Tracking Repositories, such as Bugzilla, are designed to support fault reporting for developers, testers and users of the system. Allowing anyone to contribute finding and reporting faults has an immediate impact on software quality. However, this benefit comes with at least one side-effect. Users often file reports that describe the same fault. This increases the maintainer's triage time, but important information required to fix the fault is likely contributed by different reports. Aim: The objective of this paper is twofold. First, we want to understand the dynamics of bug report filing for a large, long duration open source project, Firefox. Second, we present a new approach that can reduce the number of duplicate reports. Method: The novel element in the proposed approach is the ability to concentrate the search for duplicates on specific portions of the bug repository. Our system can be deployed as a search tool to help reporters query the repository. Results: When tested as a search tool our system is able to detect up to 53% of duplicate reports. Conclusion: The performance of Information Retrieval techniques can be significantly improved by guiding the search for duplicates. This approach results in higher detection rates and constant classification runtime. Copyright © 2011 ACM.},
  Affiliation              = {West Virginia University, Lane Department of Computer Science and Electrical Engineering, Morgantown, WV, United States},
  Art_number               = {2020398},
  Author_keywords          = {Bug tacking systems; Duplicate Bug reports; Software Maintenance; Software quality},
  Document_type            = {Conference Paper},
  Doi                      = {10.1145/2020390.2020398},
  Journal                  = {ACM International Conference Proceeding Series},
  Source                   = {Scopus},
  Url                      = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-80054061878&partnerID=40&md5=3bd80f1b296cccd5801f38757f6ac71f}
}

@Conference{Saha2015258,
  Title                    = {Are these bugs really 'normal'?},
  Author                   = {Saha, R.K.a and Lawall, J.b and Khurshid, S.a and Perry, D.E.a },
  Year                     = {2015},
  Note                     = {cited By 0},
  Pages                    = {258-268},
  Volume                   = {2015-August},

  Abstract                 = {Understanding the severity of reported bugs is important in both research and practice. In particular, a number of recently proposed mining-based software engineering techniques predict bug severity, bug report quality, and bug-fix time, according to this information. Many bug tracking systems provide a field 'severity' offering options such as 'severe', 'normal', and 'minor', with 'normal' as the default. However, there is a widespread perception that for many bug reports the label 'normal' may not reflect the actual severity, because reporters may overlook setting the severity or may not feel confident enough to do so. In many cases, researchers ignore 'normal' bug reports, and thus overlook a large percentage of the reports provided. On the other hand, treating them all together risks mixing reports that have very diverse properties. In this study, we investigate the extent to which 'normal' bug reports actually have the 'normal' severity. We find that many 'normal' bug reports in practice are not normal. Furthermore, this misclassification can have a significant impact on the accuracy of mining-based tools and studies that rely on bug report severity information. © 2015 IEEE.},
  Affiliation              = {University of Texas at Austin, United States; Inria, LIP6, UPMC, Sorbonne University, France},
  Art_number               = {7180085},
  Author_keywords          = {Bug Severity; Bug Tracking System; Mining Software Repositories},
  Document_type            = {Conference Paper},
  Doi                      = {10.1109/MSR.2015.31},
  Journal                  = {IEEE International Working Conference on Mining Software Repositories},
  Source                   = {Scopus},
  Url                      = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84957107517&partnerID=40&md5=1d0fefdfc0cd2a2fdc3d0a816212bbf6}
}

@Article{Singh201117,
  Title                    = {Bug tracking and reliability assessment system (BTRAS)},
  Author                   = {Singh, V.B.a and Chaturvedi, K.K.b },
  Journal                  = {International Journal of Software Engineering and its Applications},
  Year                     = {2011},
  Note                     = {cited By 3},
  Number                   = {4},
  Pages                    = {17-30},
  Volume                   = {5},

  Abstract                 = {Tracking of a reported bug for fixing is a fascinating area of research in software engineering. Many open source, free and commercial bug tracking tools have been developed and are currently under development. The industry needs criteria to select the best tool among the available set of tools that will help in fixing and tracking the progress of bug fixes. In this paper, we use BugZilla, Jira, Trac, Mantis, BugTracker.Net, Gnats and Fossil for comparative study. We present a comprehensive classification criteria to review the available tools and propose a new tool named Bug Tracking and Reliability Assessment System (BTRAS) for the bug tracking/reporting and reliability assessment. BTRAS helps in reporting the bug, assigning the bug to the developer for fixing, monitoring the progress of bug fixing by various graphical/charting facility and status updates, providing reliability bug prediction and bug complexity measurements, and distributing fixes to users/developers.},
  Affiliation              = {Delhi College of Arts and Commerce, University of Delhi, Delhi, India; Indian Agricultural Statistics Research Institute, Delhi, India},
  Author_keywords          = {Bug/issue tracking system; Classification criteria; Comparison of tools; Machine learning techniques; Reliability assessment; Resolution of bugs},
  Document_type            = {Article},
  Source                   = {Scopus},
  Url                      = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84859810820&partnerID=40&md5=9dad3d0476ada67a76c7a7782b694c1a}
}

@Conference{Song2010315,
  Title                    = {JDF: Detecting duplicate bug reports in Jazz},
  Author                   = {Song, Y.a and Wang, X.b c and Xie, T.a and Zhang, L.b c and Mei, H.b c },
  Year                     = {2010},
  Note                     = {cited By 3},
  Pages                    = {315-316},
  Volume                   = {2},

  Abstract                 = {Both developers and users submit bug reports to a bug repository. These reports can help reveal defects and improve software quality. As the number of bug reports in a bug repository increases, the number of the potential duplicate bug reports increases. Detecting duplicate bug reports helps reduce development efforts in fixing defects. However, it is challenging to manually detect all potential duplicates because of the large number of existing bug reports. This paper presents JDF (representing Jazz Duplicate Finder), a tool that helps users to find potential duplicates of bug reports on Jazz, which is a team collaboration platform for software development and process management. JDF finds potential duplicates for a given bug report using natural language and execution information. © 2010 ACM.},
  Affiliation              = {Department of Computer Science, North Carolina State University, Raleigh, NC, United States; Institute of Software, School of Electronics Engineering and Computer Science, China; Key Laboratory of High Confidence Software Technologies (Peking University), Ministry of Education, Peking University, Beijing, 100871, China},
  Author_keywords          = {bug report; execution information; information retrieval},
  Document_type            = {Conference Paper},
  Doi                      = {10.1145/1810295.1810368},
  Journal                  = {Proceedings - International Conference on Software Engineering},
  Source                   = {Scopus},
  Url                      = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-77954739345&partnerID=40&md5=2f9daab38496dfe301765ef9af67519d}
}

@Article{Tappolet2010225,
  Title                    = {Semantic web enabled software analysis},
  Author                   = {Tappolet, J. and Kiefer, C. and Bernstein, A.},
  Journal                  = {Journal of Web Semantics},
  Year                     = {2010},
  Note                     = {cited By 12},
  Number                   = {2-3},
  Pages                    = {225-240},
  Volume                   = {8},

  Abstract                 = {One of the most important decisions researchers face when analyzing software systems is the choice of a proper data analysis/exchange format. In this paper, we present EvoOnt, a set of software ontologies and data exchange formats based on OWL. EvoOnt models software design, release history information, and bug-tracking meta-data. Since OWL describes the semantics of the data, EvoOnt (1) is easily extendible, (2) can be processed with many existing tools, and (3) allows to derive assertions through its inherent Description Logic reasoning capabilities. The contribution of this paper is that it introduces a novel software evolution ontology that vastly simplifies typical software evolution analysis tasks. In detail, we show the usefulness of EvoOnt by repeating selected software evolution and analysis experiments from the 2004-2007 Mining Software Repositories Workshops (MSR). We demonstrate that if the data used for analysis were available in EvoOnt then the analyses in 75% of the papers at MSR could be reduced to one or at most two simple queries within off-the-shelf SPARQL tools. In addition, we present how the inherent capabilities of the Semantic Web have the potential of enabling new tasks that have not yet been addressed by software evolution researchers, e.g., due to the complexities of the data integration. © 2010 Elsevier B.V.},
  Affiliation              = {Dynamic and Distributed Information Systems, University of Zurich, Switzerland},
  Author_keywords          = {Bug prediction; Software comprehension framework; Software evolution; Software release similarity},
  Document_type            = {Article},
  Doi                      = {10.1016/j.websem.2010.04.009},
  Source                   = {Scopus},
  Url                      = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-77955230399&partnerID=40&md5=b93313ee75158ed39f6354a2a0a3efe2}
}

@Conference{Thung2014871,
  Title                    = {DupFinder: Integrated tool support for duplicate bug report detection},
  Author                   = {Thung, F. and Kochhar, P.S. and Lo, D.},
  Year                     = {2014},
  Note                     = {cited By 0},
  Pages                    = {871-874},

  Abstract                 = {To track bugs that appear in a software, developers often make use of a bug tracking system. Users can report bugs that they encounter in such a system. Bug reporting is inherently an uncoordinated distributed process though and thus when a user submits a new bug report, there might be cases when another bug report describing exactly the same problem is already present in the system. Such bug reports are duplicate of each other and these duplicate bug reports need to be identified. A number of past studies have proposed a number of automated approaches to detect duplicate bug reports. However, these approaches are not integrated to existing bug tracking systems. In this paper, we propose a tool named DupFinder, which implements the state-of-theart unsupervised duplicate bug report approach by Runeson et al., as a Bugzilla extension. DupFinder does not require any training data and thus can easily be deployed to any project. DupFinder extracts texts from summary and description fields of a new bug report and recent bug reports present in a bug tracking system, uses vector space model to measure similarity of bug reports, and provides developers with a list of potential duplicate bug reports based on the similarity of these reports with the new bug report. We have released DupFinder as an open source tool in GitHub, which is available at: uhttps://github.com/smagsmu/dupfinder. © 2014 ACM.},
  Affiliation              = {School of Information Systems, Singapore Management University, Singapore},
  Author_keywords          = {Bugzilla; Duplicate bug reports; Integrated tool support},
  Document_type            = {Conference Paper},
  Doi                      = {10.1145/2642937.2648627},
  Journal                  = {ASE 2014 - Proceedings of the 29th ACM/IEEE International Conference on Automated Software Engineering},
  Source                   = {Scopus},
  Url                      = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84908618742&partnerID=40&md5=e5a6bc1465b1ae05c0f10dec9c6ae212}
}

@Conference{Tian2012385,
  Title                    = {Improved duplicate bug report identification},
  Author                   = {Tian, Y.a and Sun, C.b and Lo, D.a },
  Year                     = {2012},
  Note                     = {cited By 22},
  Pages                    = {385-390},

  Abstract                 = {Bugs are prevalent in software systems. To improve the reliability of software systems, developers often allow end users to provide feedback on bugs that they encounter. Users could perform this by sending a bug report in a bug report management system like Bugzilla. This process however is uncoordinated and distributed, which means that many users could submit bug reports reporting the same problem. These are referred to as duplicate bug reports. The existence of many duplicate bug reports may cause much unnecessary manual efforts as often a triager would need to manually tag bug reports as being duplicates. Recently, there have been a number of studies that investigate duplicate bug report problem which in effect answer the following question: given a new bug report, retrieve k other similar bug reports. This, however, still requires substantive manual effort which could be reduced further. Jalbert and Weimer are the first to introduce the direct detection of duplicate bug reports; it answers the question: given a new bug report, classify if it as a duplicate bug report or not. In this paper, we extend Jalbert and Weimer's work by improving the accuracy of automated duplicate bug report identification. We experiments with bug reports from Mozilla bug tracking system which were reported between February 2005 to October 2005, and find that we could improve the accuracy of the previous approach by about 160%. © 2012 IEEE.},
  Affiliation              = {School of Information Systems, Singapore Management University, Singapore; School of Computing, National University of Singapore, Singapore},
  Art_number               = {6178884},
  Author_keywords          = {Bugzilla; Duplicate bug reports; Relative similarity},
  Document_type            = {Conference Paper},
  Doi                      = {10.1109/CSMR.2012.48},
  Journal                  = {Proceedings of the European Conference on Software Maintenance and Reengineering, CSMR},
  Source                   = {Scopus},
  Url                      = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84860522295&partnerID=40&md5=4c519ee7a6e662e0364258aedcad5260}
}

@Conference{Tong201516,
  Title                    = {Characterizing and Predicting Bug Assignment in OpenStack},
  Author                   = {Tong, J.a and Ying, L.a b and Xiaoyong, Y.a and Hongyan, T.a and Zhonghai, W.a },
  Year                     = {2015},
  Note                     = {cited By 0},
  Pages                    = {16-23},

  Abstract                 = {Open source software is becoming increasingly important in cloud computing. However, many cloud computing systems suffer from software bugs that cause significant dependability issues. Bug assignment and fixing are crucial parts of software maintenance to improve dependability. In this paper, we conduct an empirical study of 42,880 bug reports from OpenStack bug repository. We study the characteristics (e.g., distribution of bugs, distribution of assignees) of bug assignments in OpenStack and find the bug assignment pattern which we call as long tail. The findings can support the follow-up research on improving efficiency of bug assignment, that is, we propose a prediction method based on long tail model, and experimentally evaluate this method by applying it to OpenStack bug assignment. © 2015 IEEE.},
  Affiliation              = {School of Software and Microelectronics, Peking University, Beijing, China; National Engineering Center of Software Engineering, Peking University, Beijing, China},
  Art_number               = {7335939},
  Author_keywords          = {bug assignment; cloud computing; long tail; open source},
  Document_type            = {Conference Paper},
  Doi                      = {10.1109/TSA.2015.14},
  Journal                  = {Proceedings - 2nd International Conference on Trustworthy Systems and Their Applications, TSA 2015},
  Source                   = {Scopus},
  Url                      = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84961837662&partnerID=40&md5=cd59b3ed2bdb3597432de912851f14da}
}

@Article{Tran201557,
  Title                    = {Fault data analytics using decision tree for fault detection},
  Author                   = {Tran, H.M. and Nguyen, S.V. and Le, S.T. and Vu, Q.T.},
  Journal                  = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  Year                     = {2015},
  Note                     = {cited By 0},
  Pages                    = {57-71},
  Volume                   = {9446},

  Abstract                 = {Monitoring events on communication and computing systems becomes more and more challenging due to the increasing complexity and diversity of these systems. Several supporting tools have been created to assist system administrators in monitoring an enormous number of events daily. The main function of these tools is to filter as many as possible events and present non-trivial events to the administrators for fault analysis and detection. However, non-trivial events never decrease on large systems, such as cloud computing systems, while investigating events is time consuming. This paper proposes an approach for evaluating the severity level of an event using a classification and regression decision tree. The approach aims to build a decision tree based on the features of old events, then use this tree to decide the severity level of new events. The administrators take advantages of this decision to determine proper actions for the non-trivial events. We have implemented and experimented the approach for software bug datasets obtained from bug tracking systems. The experimental results reveal that the accuracy scores for different decision trees are above 70% and some detailed analyses are provided. © Springer International Publishing Switzerland 2015.},
  Affiliation              = {Computer Science and Engineering, International University - Vietnam National University, Ho Chi Minh City, Viet Nam},
  Author_keywords          = {CART decision tree; Event monitoring; Fault data analytics; Fault detection; Software bug report},
  Document_type            = {Conference Paper},
  Doi                      = {10.1007/978-3-319-26135-5_5},
  Source                   = {Scopus},
  Url                      = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84951958354&partnerID=40&md5=56a4854532a002cb873039536decb0a4}
}

@Conference{Vahabzadeh2015101,
  Title                    = {An empirical study of bugs in test code},
  Author                   = {Vahabzadeh, A. and Fard, A.M. and Mesbah, A.},
  Year                     = {2015},
  Note                     = {cited By 0},
  Pages                    = {101-110},

  Abstract                 = {Testing aims at detecting (regression) bugs in production code. However, testing code is just as likely to contain bugs as the code it tests. Buggy test cases can silently miss bugs in the production code or loudly ring false alarms when the production code is correct. We present the first empirical study of bugs in test code to characterize their prevalence and root cause categories. We mine the bug repositories and version control systems of 211 Apache Software Foundation (ASF) projects and find 5,556 test-related bug reports. We (1) compare properties of test bugs with production bugs, such as active time and fixing effort needed, and (2) qualitatively study 443 randomly sampled test bug reports in detail and categorize them based on their impact and root causes. Our results show that (1) around half of all the projects had bugs in their test code; (2) the majority of test bugs are false alarms, i.e., test fails while the production code is correct, while a minority of these bugs result in silent horrors, i.e., test passes while the production code is incorrect; (3) incorrect and missing assertions are the dominant root cause of silent horror bugs; (4) semantic (25%), flaky (21%), environment-related (18%) bugs are the dominant root cause categories of false alarms; (5) the majority of false alarm bugs happen in the exercise portion of the tests, and (6) developers contribute more actively to fixing test bugs and test bugs are fixed sooner compared to production bugs. In addition, we evaluate whether existing bug detection tools can detect bugs in test code. © 2015 IEEE.},
  Affiliation              = {University of British Columbia, Vancouver, BC, Canada},
  Art_number               = {7332456},
  Author_keywords          = {Bugs; empirical study; test code},
  Document_type            = {Conference Paper},
  Doi                      = {10.1109/ICSM.2015.7332456},
  Journal                  = {2015 IEEE 31st International Conference on Software Maintenance and Evolution, ICSME 2015 - Proceedings},
  Source                   = {Scopus},
  Url                      = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84961640892&partnerID=40&md5=dc9efaadb82d1e47ca337178cf645f6c}
}

@Conference{Wang201176,
  Title                    = {Which bug should I fix: Helping new developers onboard a new project},
  Author                   = {Wang, J. and Sarma, A.},
  Year                     = {2011},
  Note                     = {cited By 0},
  Pages                    = {76-79},

  Abstract                 = {A typical entry point for new developers in an open source project is to contribute a bug fix. However, finding an appropriate bug and an appropriate fix for that bug requires a good understanding of the project, which is nontrivial. Here, we extend Tesseract - an interactive project exploration environment - to allow new developers to search over bug descriptions in a project to quickly identify and explore bugs of interest and their related resources. More specifically, we extended Tesseract with search capabilities that enable synonyms and similar-bugs search over bug descriptions in a bug repository. The goal is to enable users to identify bugs of interest, resources related to that bug, (e.g., related files, contributing developers, communication records), and visually explore the appropriate socio-technical dependencies for the selected bug in an interactive manner. Here we present our search extension to Tesseract. © 2011 ACM.},
  Affiliation              = {Computer Science and Engineering, University of Nebraska-Lincoln, Lincoln, NE 68588-0115, United States},
  Author_keywords          = {bug search; new developer; socio-technical dependency},
  Document_type            = {Conference Paper},
  Doi                      = {10.1145/1984642.1984661},
  Journal                  = {Proceedings - International Conference on Software Engineering},
  Source                   = {Scopus},
  Url                      = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-79959401355&partnerID=40&md5=bcc511367bfd1dd131bf3c8c90707388}
}

@Conference{White201548,
  Title                    = {Generating Reproducible and Replayable Bug Reports from Android Application Crashes},
  Author                   = {White, M. and Linares-Vásquez, M. and Johnson, P. and Bernal-Cárdenas, C. and Poshyvanyk, D.},
  Year                     = {2015},
  Note                     = {cited By 0},
  Pages                    = {48-59},
  Volume                   = {2015-August},

  Abstract                 = {Manually reproducing bugs is time-consuming and tedious. Software maintainers routinely try to reproduce unconfirmed issues using incomplete or no informative bug reports. Consequently, while reproducing an issue, the maintainer must augment the report with information - such as a reliable sequence of descriptive steps to reproduce the bug - to aid developers with diagnosing the issue. This process encumbers issue resolution from the time the bug is entered in the issue tracking system until it is reproduced. This paper presents Crash Droid, an approach for automating the process of reproducing a bug by translating the call stack from a crash report into expressive steps to reproduce the bug and a kernel event trace that can be replayed on-demand. Crash Droid manages trace ability links between scenarios' natural language descriptions, method call traces, and kernel event traces. We evaluated Crash Droid on several open-source Android applications infected with errors. Given call stacks from crash reports, Crash Droid was able to generate expressive steps to reproduce the bugs and automatically replay the crashes. Moreover, users were able to confirm the crashes faster with Crash Droid than manually reproducing the bugs or using a stress-testing tool. © 2015 IEEE.},
  Affiliation              = {Department of Computer Science, College of William and Mary, Williamsburg, VA, United States},
  Art_number               = {7181432},
  Author_keywords          = {Android; crash and bug reports; reproducibility},
  Document_type            = {Conference Paper},
  Doi                      = {10.1109/ICPC.2015.14},
  Journal                  = {IEEE International Conference on Program Comprehension},
  Source                   = {Scopus},
  Url                      = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84956502609&partnerID=40&md5=2fde4018bb605b18eba307cb3a0a1f2a}
}

@Conference{White201548,
  Title                    = {Generating Reproducible and Replayable Bug Reports from Android Application Crashes},
  Author                   = {White, M. and Linares-Vásquez, M. and Johnson, P. and Bernal-Cárdenas, C. and Poshyvanyk, D.},
  Year                     = {2015},
  Note                     = {cited By 0},
  Pages                    = {48-59},
  Volume                   = {2015-August},

  Abstract                 = {Manually reproducing bugs is time-consuming and tedious. Software maintainers routinely try to reproduce unconfirmed issues using incomplete or no informative bug reports. Consequently, while reproducing an issue, the maintainer must augment the report with information - such as a reliable sequence of descriptive steps to reproduce the bug - to aid developers with diagnosing the issue. This process encumbers issue resolution from the time the bug is entered in the issue tracking system until it is reproduced. This paper presents Crash Droid, an approach for automating the process of reproducing a bug by translating the call stack from a crash report into expressive steps to reproduce the bug and a kernel event trace that can be replayed on-demand. Crash Droid manages trace ability links between scenarios' natural language descriptions, method call traces, and kernel event traces. We evaluated Crash Droid on several open-source Android applications infected with errors. Given call stacks from crash reports, Crash Droid was able to generate expressive steps to reproduce the bugs and automatically replay the crashes. Moreover, users were able to confirm the crashes faster with Crash Droid than manually reproducing the bugs or using a stress-testing tool. © 2015 IEEE.},
  Affiliation              = {Department of Computer Science, College of William and Mary, Williamsburg, VA, United States},
  Art_number               = {7181432},
  Author_keywords          = {Android; crash and bug reports; reproducibility},
  Document_type            = {Conference Paper},
  Doi                      = {10.1109/ICPC.2015.14},
  Journal                  = {IEEE International Conference on Program Comprehension},
  Source                   = {Scopus},
  Url                      = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84961344972&partnerID=40&md5=51c93058dc5279f309a5c69a2cb7ac88}
}

@Conference{Wu201195,
  Title                    = {BugMiner: Software reliability analysis via data mining of bug reports},
  Author                   = {Wu, L. and Xie, B. and Kaiser, G. and Passonneau, R.},
  Year                     = {2011},
  Note                     = {cited By 4},
  Pages                    = {95-100},

  Abstract                 = {Software bugs reported by human users and automatic error reporting software are often stored in some bug tracking tools (e.g., Bugzilia and Debbugs). These accumulated bug reports may contain valuable information that could be used to improve the quality of the bug reporting, reduce the quality assurance effort and cost, analyze software reliability, and predict future bug report trend. In this paper, we present BugMiner, a tool that is able to derive useful information from historic bug report database using data mining, use these information to do completion check and redundancy check on a new or given bug report, and to estimate the bug report trend using statistical analysis. Our empirical studies of the tool using several real-world bug report repositories show that it is effective, easy to implement, and has relatively high accuracy despite low quality data.},
  Affiliation              = {Department of Computer Science, Columbia University, New York, NY 10027, United States},
  Document_type            = {Conference Paper},
  Journal                  = {SEKE 2011 - Proceedings of the 23rd International Conference on Software Engineering and Knowledge Engineering},
  Source                   = {Scopus},
  Url                      = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84855528831&partnerID=40&md5=c6b995a94d2f115ed80794957b3c9536}
}

@Article{Zhang20141756,
  Title                    = {A novel technique for duplicate detection and classification of bug reports},
  Author                   = {Zhang, T. and Lee, B.},
  Journal                  = {IEICE Transactions on Information and Systems},
  Year                     = {2014},
  Note                     = {cited By 0},
  Number                   = {7},
  Pages                    = {1756-1768},
  Volume                   = {E97-D},

  Abstract                 = {Software products are increasingly complex, so it is becoming more difficult to find and correct bugs in large programs. Software developers rely on bug reports to fix bugs; thus, bug-tracking tools have been introduced to allow developers to upload, manage, and comment on bug reports to guide corrective software maintenance. However, the very high frequency of duplicate bug reports means that the triagers who help software developers in eliminating bugs must allocate large amounts of time and effort to the identification and analysis of these bug reports. In addition, classifying bug reports can help triagers arrange bugs in categories for the fixers who have more experience for resolving historical bugs in the same category. Unfortunately, due to a large number of submitted bug reports every day, the manual classification for these bug reports increases the triagers' workload. To resolve these problems, in this study, we develop a novel technique for automatic duplicate detection and classification of bug reports, which reduces the time and effort consumed by triagers for bug fixing. Our novel technique uses a support vector machine to check whether a new bug report is a duplicate. The concept profile is also used to classify the bug reports into related categories in a taxonomic tree. Finally, we conduct experiments that demonstrate the feasibility of our proposed approach using bug reports extracted from the large-scale open source project Mozilla. Copyright © 2014 The Institute of Electronics, Information and Communication Engineers.},
  Affiliation              = {Department of Computer Science, University of Seoul, South Korea},
  Author_keywords          = {Bug report classification; Concept profile; Duplicate detection; Software maintenance; Support vector machine},
  Document_type            = {Article},
  Doi                      = {10.1587/transinf.E97.D.1756},
  Source                   = {Scopus},
  Url                      = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84903701013&partnerID=40&md5=b2fbabe4eb85c94c1ba645bc2672f4ba}
}

@Article{Zimmermann2010618,
  Title                    = {What makes a good bug report?},
  Author                   = {Zimmermann, T.a and Premraj, R.b and Bettenburg, N.c and Just, S.d and Schröter, A.e and Weiss, C.f },
  Journal                  = {IEEE Transactions on Software Engineering},
  Year                     = {2010},
  Note                     = {cited By 51},
  Number                   = {5},
  Pages                    = {618-643},
  Volume                   = {36},

  Abstract                 = {In software development, bug reports provide crucial information to developers. However, these reports widely differ in their quality. We conducted a survey among developers and users of APACHE, ECLIPSE, and MOZILLA to find out what makes a good bug report. The analysis of the 466 responses revealed an information mismatch between what developers need and what users supply. Most developers consider steps to reproduce, stack traces, and test cases as helpful, which are, at the same time, most difficult to provide for users. Such insight is helpful for designing new bug tracking tools that guide users at collecting and providing more helpful information. Our CUEZILLA prototype is such a tool and measures the quality of new bug reports; it also recommends which elements should be added to improve the quality. We trained CUEZILLA on a sample of 289 bug reports, rated by developers as part of the survey. The participants of our survey also provided 175 comments on hurdles in reporting and resolving bugs. Based on these comments, we discuss several recommendations for better bug tracking systems, which should focus on engaging bug reporters, better tool support, and improved handling of bug duplicates. © 2010 IEEE.},
  Affiliation              = {Microsoft Research, One Microsoft Way, Redmond, WA 98052, United States; Computer Science Department, Vrije Universiteit Amsterdam, De Boelelaan 1081a, 1081 HV Amsterdam, Netherlands; Software Analysis and Intelligence Lab (SAIL), School of Computing, Queen's University, 156 Barrie St, Kingston, ON K7L 3N6, Canada; Saarland UniversityComputer Science, Campus E1 1, 66123 Saarbruecken, Germany; University of Victoria, Engineering/Computer Science Building, PO Box 3055, STN CSC, Victoria, BC V8W3P6, Canada; Department of Informatics, University of Zurich, Binzmühlestrasse 14, CH-8050, Zürich, Switzerland},
  Art_number               = {5487527},
  Author_keywords          = {and enhancement; distribution; human factors; maintenance; management; measurement; Testing and debugging},
  Document_type            = {Article},
  Doi                      = {10.1109/TSE.2010.63},
  Source                   = {Scopus},
  Url                      = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-77957746467&partnerID=40&md5=7d811170a0573afceb8d33b05713792e}
}

@Conference{Zimmermann2009247,
  Title                    = {Improving bug tracking systems},
  Author                   = {Zimmermann, T.a b and Premraj, R.b and Sillito, J.c and Breu, S.d },
  Year                     = {2009},
  Note                     = {cited By 11},
  Pages                    = {247-250},

  Abstract                 = {It is important that information provided in bug reports is relevant and complete in order to help resolve bugs quickly. However, often such information trickles to developers after several iterations of communication between developers and reporters. Poorly designed bug tracking systems are partly to blame for this exchange of information being stretched over time. Our paper addresses the concerns of bug tracking systems by proposing four broad directions for enhancements. As a proof-of-concept, we also demonstrate a prototype interactive bug tracking system that gathers relevant information from the user and identifies files that need to be fixed to resolve the bug. © 2009 IEEE.},
  Affiliation              = {Microsoft Research, Redmond, WA, United States; Department of Computer Science, University of Calgary, Canada; Vrije Universiteit, Amsterdam, Netherlands; Computer Laboratory, University of Cambridge, United Kingdom},
  Art_number               = {5070993},
  Document_type            = {Conference Paper},
  Doi                      = {10.1109/ICSE-COMPANION.2009.5070993},
  Journal                  = {2009 31st International Conference on Software Engineering - Companion Volume, ICSE 2009},
  Source                   = {Scopus},
  Url                      = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-70349694449&partnerID=40&md5=be7a1ad461d14b326b5eb0459983cc56}
}

@Article{NoAuthor20151,
  Title                    = {7th International Symposium on Search-Based Software Engineering, SSBSE 2015},
  Journal                  = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  Year                     = {2015},
  Note                     = {cited By 0},
  Pages                    = {1-354},
  Volume                   = {9275},

  Abstract                 = {The proceedings contain 38 papers. The special focus in this conference is on Search-Based Software Engineering. The topics include: Genetic improvement of software for multiple objectives; amortised optimisation of non-functional properties in production environments; metrics are not enough; searching for useful parallelism in functional programs; an improved beam-search for the test case generation for formal verification systems; combining multiple coverage criteria in search-based unit test generation; epistatic genetic algorithm for test case prioritization; a scala combinator toolkit for semi-automated composition of metaheuristics; hypervolume-based search for test case prioritization; optimizing aspect-oriented product line architectures with search-based algorithms; adaptive neighbourhood search for the component deployment problem; transformed search based software engineering; regression test case prioritisation for guava; continuous test generation on guava; generating readable unit tests for guava; testing django configurations using combinatorial interaction testing; synthesis of equivalent method calls in guava; object-oriented genetic improvement for improved energy consumption in google guava; automated transplantation of call graph and layout features into kate; growing django citation services using SBSE; multi-objective module clustering for kate; search based component selection for budget hardware; search-based bug report prioritization for kate editor bugs repository; inferring test models from kate’s bug reports using multi-objective search; introducing learning mechanism for class responsibility assignment problem; transformed vargha-delaney effect size; optimizing software product line architectures with OPLA-tool; exploring the landscape of non-functional program properties using spatial analysis and interactive software release planning with preferences base.},
  Document_type            = {Conference Review},
  Source                   = {Scopus},
  Url                      = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84951276529&partnerID=40&md5=2ddd99abeb9b2d0bb59d68811edc6a6b}
}

@Conference{NoAuthor2012,
  Title                    = {2012 9th IEEE Working Conference on Mining Software Repositories, MSR 2012 - Proceedings},
  Year                     = {2012},
  Note                     = {cited By 0},

  Abstract                 = {The proceedings contain 38 papers. The topics discussed include: towards improving bug tracking systems with game mechanisms; a linked data platform for mining software repositories; how distributed version control systems impact open source software projects; an empirical study of supplementary bug fixes; incorporating version histories in information retrieval based bug localization; think locally, act globally: improving defect and effort prediction models; are faults localizable?; green mining: a methodology of relating software change to power consumption; analysis of customer satisfaction survey data; mining usage data and development artifacts; bug introducing changes: a case study with android; trendy bugs: topic trends in the android bug reports; do the stars align? multidimensional analysis of android's layered architecture; and the build dependency perspective of android's concrete architecture.},
  Document_type            = {Conference Review},
  Journal                  = {IEEE International Working Conference on Mining Software Repositories},
  Page_count               = {261},
  Source                   = {Scopus},
  Url                      = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84865136454&partnerID=40&md5=4d20f0cb5d009f5004265a2c43dccc42}
}

